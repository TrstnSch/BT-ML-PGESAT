Understand GCN/GraphConv in PyG
 - DONE: Validate params

DONE: Implement + understand DataLoader   80/10/10 split 
 - Create Dataset classes from scratch (with logic from ExplainerDataset?) OR use from PyG    PROBABLY NOT NEEDED
 - loading masks from dataset??? => Node masks vor train/val/test are created from RandomSplit
 - DONE: visualize Dataset, 
 - DONE: color node classes (optional)
 - DONE: Validate creation of datasets!!
 - DONE: Datasets for Node classification need to be generated once, saved and loaded to be static. OR take original ones and transform?
 - DONE: BA-Graph Generator not correct -> Use and transform original datasets?? Generate own dataset??
 - DONE: Combine graphs for BA-Community

training loop
 - params
 - DONE: optimizer Adam
 - DONE: initalization Xavier
 - DONE: train/test split
 - DONE: accuracy
 - DONE: plot!
 - ...
=> GNN models for different Datasets
  TODO: Models are overfitting!

Clean up
Create structure for different datasets/training loops. How to load/save parameters for each task? => One notebook/script per explainer training
TRY GraphSage and GATConv for GNN

NodeGNN
 - DONE: PyG transform random node split for train/val/test
 - TODO: Model for every dataset
 - TODO: Test different architectures: BN, Norm, Dropout...

-------------- implement Explainer/MLP ---------------------
 - ADD, GNNExplainer, PGExplainer ?!?!


Explainer training loop
 - Done: GNN explainer training loop
 - DONE: edge_index is bidirectional, topk edges contain duplicates => Average edge weights for both directions when calculating weights
 - Done: Batching
 - TODO: Loss regularization implemented but not working as expected. PROBLEM: Model learns lowest edge weights instead of highest?!

TODO: BA-Community gt!
TODO: BA-Community performance!!




TODO: VALIDAT MUTAG GT!!! SEEMS TO BE MESSED UP!





TODO: PROBLEMs
 - DONE: When examining use topK(5/6 for BA2Motif) weights/mlp outputs instead of reparam values? => Paper states to use latent variables, but code uses probabilites!
 - DONE: Sampling during eval() only Sigmoid, no randomness, therefore use preds instead of weights
 - TODO: Model learns minimal weights??? Only for BA2Motif?
 - DONE: Edges are duplicate because of undirected representation in PyG => Remove edges beforehand? => Not good

1. Remove duplicate edges BEFORE => Did not work well
2. Vorzeichenfehler loss? => Unlikely
3. DONE: Computational Graph(hidden graph layers) representation (k-hop neighbourhood)
4. TODO: Node classification - Weights are 1 for complete subgraph, no differentiation between motif and non motif
5. DONE: BATCHING: Loss for each graph, not across batch!


Learning minimal weight Problems:
 - not fault of regularization, architecture 20 instead 64, 

TODO: Clear up structure
implement utils


DONE:
  - DONE: Try to use original datasets -> Transform for pyg
  - AUC: take ground truth from dataset, predictions from graph? Try with topK predictions?
  - DONE: Node training: Extract only first node from motifs and train on these! Use same for evaluation
  - THEN try to mess around with weights and how to normalize them...


Select one paper to go by !!
DONE: set up BA template in Latex
 - change Lehrstuhl, Fachgruppe, Logo on title page

DONE: Presentation 1
DONE: Abstract

Presentation 2:

Presentation 2:
  - Entropie alleine sorgt nicht ausschließlich für minimale graphen -> Zusätzlich Budget oder connectivity constraint um graphen zu minimieren




Content:
 - Theoretical:
   - GNN/GCN
   - Explainabilty methods(taxonomy)
   - Expand on chosen method (perturbation)
   - 
   - SAT
   - Bipartite Graphs

 - Reimplementation:
   - PGExlpainer
   - GNNExplainer?
   - Results comparison
   - optimization

 - Benchmarking PGExplainer?

 - SAT Problem in PGExplainer?