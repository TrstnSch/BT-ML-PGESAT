Understand GCN/GraphConv in PyG
 - DONE: Validate params

DONE: Implement + understand DataLoader   80/10/10 split 
 - Create Dataset classes from scratch (with logic from ExplainerDataset?) OR use from PyG    PROBABLY NOT NEEDED
 - loading masks from dataset??? => Node masks vor train/val/test are created from RandomSplit
 - DONE: visualize Dataset, 
 - DONE: color node classes (optional)
 - DONE: Validate creation of datasets!!
 - DONE: Datasets for Node classification need to be generated once, saved and loaded to be static. OR take original ones and transform?
 - DONE: BA-Graph Generator not correct -> Use and transform original datasets?? Generate own dataset??
 - DONE: Combine graphs for BA-Community

training loop
 - params
 - DONE: optimizer Adam
 - DONE: initalization Xavier
 - DONE: train/test split
 - DONE: accuracy
 - DONE: plot!
 - ...
=> GNN models for different Datasets
  TODO: Models are overfitting!

Clean up
Create structure for different datasets/training loops. How to load/save parameters for each task? => One notebook/script per explainer training
TRY GraphSage and GATConv for GNN: GraphSage/SageConv does not allow to pass edge_weights

NodeGNN
 - DONE: PyG transform random node split for train/val/test
 - DONE: Model for every dataset
 - TODO: Test different architectures: BN, Norm, Dropout...

-------------- implement Explainer/MLP ---------------------
 - ADD, GNNExplainer, PGExplainer ?!?!


Explainer training loop
 - Done: GNN explainer training loop
 - DONE: edge_index is bidirectional, topk edges contain duplicates => Average edge weights for both directions when calculating weights
 - Done: Batching
 - DONE?: Loss regularization implemented but not working as expected

DONE: BA-Community gt!
TODO: BA-Community performance!!

DONE: VALIDAT MUTAG GT!!! SEEMS TO BE MESSED UP! Fixed by changing data type/loading full data from original



DONE: Try GPU training for all models
DONE: Retrain Downstream task on GPU? Write down accuracies!
TODO: Hyperparameter search for all datasets. Sweeps are really slow and have to be run on GPU(?!) -> MUTAG 4 min/model
 -> Performance/Optimization of my model/training loop might be lacking; Node batches, parallelization?
 TODO: Try NodeLoader




TODO: Apply on NeuroSAT



TODO: PROBLEMs
 - DONE: When evaluating use topK(5/6 for BA2Motif) weights/mlp outputs instead of reparam values? => Paper states to use latent variables, but code uses probabilites!
 - DONE: Problem with topK when ground_truth contains multiple motifs or partial motifs -> Better to calc auc all with edge_prob instead of topk!
 - DONE: Sampling during eval() only Sigmoid, no randomness, therefore use preds instead of weights
 - TODO: Model learns minimal weights??? Only for BA2Motif?
 - DONE: Edges are duplicate because of undirected representation in PyG => Remove edges beforehand? => Not good

1. Remove duplicate edges BEFORE => Did not work well
2. Vorzeichenfehler loss? => Unlikely
3. DONE: Computational Graph(hidden graph layers) representation (k-hop neighbourhood)
4. TODO: Node classification - Weights are 1 for complete subgraph, no differentiation between motif and non motif
5. DONE: BATCHING: Loss for each graph, not across batch!


Learning minimal weight Problems:
 - not fault of regularization, architecture 20 instead 64, 

TODO: Clear up structure
implement utils


DONE:
  - DONE: Try to use original datasets -> Transform for pyg
  - AUC: take ground truth from dataset, predictions from graph? Try with topK predictions?
  - DONE: Node training: Extract only first node from motifs and train on these! Use same for evaluation
  - THEN try to mess around with weights and how to normalize them...


Select one paper to go by !!
DONE: set up BA template in Latex
 - change Lehrstuhl, Fachgruppe, Logo on title page

DONE: Presentation 1
DONE: Abstract

Presentation 2:

Presentation 2:
  - Entropie alleine sorgt nicht ausschließlich für minimale graphen -> Zusätzlich Budget oder connectivity constraint um graphen zu minimieren




Content:
 - Theoretical:
   - GNN/GCN
   - Explainabilty methods(taxonomy)
   - Expand on chosen method (perturbation)
   - 
   - SAT
   - Bipartite Graphs

 - Reimplementation:
   - PGExlpainer
   - GNNExplainer?
   - Results comparison
   - optimization

 - Benchmarking PGExplainer?

 - SAT Problem in PGExplainer?