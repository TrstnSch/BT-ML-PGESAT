To compare baseline methods GRAD, ATT, Gradient: reimplement as well or take values from paper => Don't reimplement, take from somewhere

Accuracys of Model from best accuracy over all epochs, mean or last epoch => Last epoch, or go back to earlier stage of model

How to create datasets on a singular graph => Simply use one data object(graph)

Use dropout => Sure, as long as eval() is used when not training




MLP learning lowest weights!! -> "Fixed" by setting ADAM to max or calculating reparam trick with -w_ij
 -> This is crucial, possible to "hotfix" with -1?

Performance on MUTAG?

How do I calc AUC? Different results for three different metrics

Apply constraints => size+entropy done
Budget and Connectivity only for node?

Mirror edge weights during training? Fix efficient method!

Graph order determines whether learns highest or lowest?!?!
First 10 epochs learns to maximize, after minimizes? Only on some architectures/hyperparams => TRY!

Triple bonds are detect as double bonds, predicted edge should be there?



WEIGHTS TEND TO BE WAY TOO HIGH FOR TREE-CYCLES. -> PROBABILITIES OF EDGES ARE ALL 1.
CAN BE REDUCED VIA L2NORM, ALTHOUGH APPARENTLY NOT USED IN ORIGINAL!
NORMALIZATION ERROR IN MY MODEL? WHERE? POSSIBLE CAUSES?