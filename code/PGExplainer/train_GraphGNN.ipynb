{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from 'c:\\\\Users\\\\trist\\\\Git_repos\\\\BT-ML-PGESAT\\\\code\\\\PGExplainer\\\\evaluation.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "import networks\n",
    "import datasetLoader\n",
    "import evaluation\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "from typing import Literal\n",
    "\n",
    "importlib.reload(datasetLoader)\n",
    "importlib.reload(networks)\n",
    "importlib.reload(evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64                 # 64 used for Graphs in PGE (PGExplainer/codes/forgraph/config.py)      1 takes forever in current model\n",
    "\n",
    "learning_rate_gnn = 0.001        #0.001 on ADAM\n",
    "epochs_gnn = 1000\n",
    "early_stopping = 500\n",
    "\n",
    "loss = nn.CrossEntropyLoss()           # cross entropy loss?!\n",
    "\n",
    "datasetName: Literal['BA2Motif','MUTAG'] = 'BA2Motif'\n",
    "\n",
    "# lr scheduler? => not used in orig\n",
    "# softmax after linear layer?       -> Not really needed since kinda used in CEL; PyTorch best practice to just use Linear in final layer\n",
    "\n",
    "# DONE: Xavier uniform distr used for init in PGExplainer\n",
    "# DONE: dropout     NOT USED IN OG\n",
    "# DONE: early stopping with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(module):\n",
    "    # TODO: GraphConv has no attribute weight!!\n",
    "    #if isinstance(module, gnn.GraphConv):\n",
    "    #    nn.init.xavier_normal_(module.weight.data)\n",
    "    #    if module.bias is not None:\n",
    "     \n",
    "    # This only initializes weight for lin layer, not GraphConv\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight.data)\n",
    "        #if module.bias is not None:            # Xavier not usable for bias?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuS0lEQVR4nO3deViUVf8G8PuZGUFBNIEwt3EDzJDcAzFQVMwtckvNpTK3NE1RNKNFtHIvzSWXNC03NJWiRHNDwVTEHTFZNBnMlBcwZVFwZp7fHwY/NReGeZ7ZuD/X1dXbO8M5X1Dh9jznfI8giqIIIiIiIqIyUpi7ACIiIiKybgyURERERGQUBkoiIiIiMgoDJREREREZhYGSiIiIiIzCQElERERERmGgJCIiIiKjMFASERERkVEYKImIiIjIKAyURERERGQUBkoiIiIiMgoDJREREREZhYGSiIiIiIzCQElERERERmGgJCIiIiKjMFASERERkVEYKImIiIjIKAyURERERGQUBkoiIiIiMgoDJREREREZhYGSiIiIiIzCQElERERERmGgJCIiIiKjMFASERERkVEYKImIiIjIKAyURERERGQUBkoiIiIiMgoDJREREREZhYGSiIiIiIzCQElERERERmGgJCIiIiKjMFASERERkVEYKImIiIjIKAyURERERGQUBkoiIiIiMgoDJREREREZhYGSiIiIiIyiMncBRERE9KD8Qi0uZ+ejSKuHnUqBei6OcLTnj2yyXPzdSUREZAFSr+diQ7wGMcmZ0OQUQLzvNQGA2tkBgY3cMMhHDY/qTuYqk+iRBFEUxae/jYiIiOSQkVOAsMhExKVlQakQoNM//sdy8ev+7q6Y2csbdZwdTFgp0eMxUBIREZlJRIIG06KSoNWLTwySD1MqBKgUAqYHe2FAa7WMFRKVDgMlERGRGSyJScX83SlGjxPa2RNjAz0kqIio7HjKm4iIyMQiEjSShEkAmL87BZsTNJKMRVRWDJREREQmlJFTgGlRSZKO+WlUEjJyCiQdk8gQDJREREQmFBaZCK0B+yVLQ6sXERaZKOmYRIZgoCQiIjKR1Ou5iEvLMugATmno9CLi0rKQlpkr6bhEpcVASUREZCIb4jVQKgRZxlYqBKw/yr2UZB4MlERERCYSk5wp+epkMZ1eRExKpixjEz0NAyUREZEJ5BVqoZH54IwmuwD5hVpZ5yB6FAZKIiIiE0jPzofcjZ9FAJez82Wehei/GCiJiIhMoEirt6l5iO7HQElERGQCdirT/Mg11TxE9+PvOiIiIhOo5+IIec53/z/h33mITE1l7gKIiIjKA0d7FdTODkiX8WCO2sUBjvaW9aM9v1CLy9n5KNLqYadSoJ6Lo8XVSMbjrygREZGJBDZyw7r4dFlaBykVAgI93SQftyxSr+diQ7wGMcmZ0OQUPHAYSQCgdnZAYCM3DPJRw6O6k7nKJAkJoijKfeiMiIiIcC9oBS2MlW38vSEBcHczX0DLyClAWGQi4tKyoFQITwzOxa/7u7tiZi9v1HF2MGGlJDXuoSQiIjIRj+pO8Hd3lfy2HKVCgL+7q1nDZESCBp0WHMThS9kA8NRV2OLXD1/KRqcFBxGRwFt+rBkDJRERkQnN7OUNlcSBUqUQMLOXt6RjGmJJTCqmbk9EoVZv8ON8nV5EoVaPqdsTsSQmVaYKSW4MlERERCZUx9kB04O9JB1zRrCX2R4ZRyRoMH93iiRjzd+dgs1cqbRKDJREREQmNqC1GqGdPSUZa3LnRujfWi3JWIbKyCnAtKgkScf8NCoJGTJfUUnSY6AkIiIyg7GBHpjd2xv2KoXBeyqVCgH2KgXm9PbGe4HuMlX4dGGRidBKfGJdqxcRFpko6ZgkPwZKIiIiMxnQWo29Ie3g18AFACA85bbv4uDp18AFe0PamW1lErh3Yj0uLUvyFkg6vYi4tCykZeZKOi7Ji22DiIiILEDq9VwET5wHsUZjFFao8t/ejS4OCPR0w2BftVlPcxcLj0qStafmEJ+6CJd4rynJh43NiYiILICzqgjJmz7HqlWr0H/Q6xZ/u0xMcqYsYRK4t0oZk5KJcDBQWgvL+t1JRERUTu3fvx+iKCIoKAiO9ip41axq7pIeK69QC43MB2c02QXIL9RaXJCmR+MeSiIiIguwe/duPP/886hTp465S3mq9Oz8p+z2NJ4I4HJ2vsyzkFQYKImIiMxMFEXs2bMHQUFB5i6lVIq0epuah4zHQElERGRmaWlpSE9Pt5pAaacyTXww1TxkPP5KERERmdmePXugUqnQvn17c5dSKvVcHCHt5ZH/Jfw7D1kHBkoiIiIz2717N9q0aQMnJ/O3AyoNR3sV1DJf9ah2ceCBHCvCQElERGRGWq0WMTExVvO4u1g7T1coZDqao1QICPR0k2VskgcDJRERkRkdO3YMt27dsppAKYoifv31V2ybEwK9TA++dXoRg33NdwsQGY6BkoiIyIz27NmDZ555Bq1atTJ3KU916NAh+Pv749VXX8Wzdlp4P1vB4HvIn0apEODv7moRtwFR6TFQEhERmdHu3bvRoUMHqFSWu1/w7Nmz6NGjB/z9/VFQUIBdu3YhJiYG37z9MlQSB0qVQsDMXt6SjknyY6AkIiIyk5s3byI+Pt5iH3dfunQJgwcPRrNmzZCcnIyIiAgcP34cr7zyCgRBQB1nB0yX+L7tGcFeqCPzgR+SHgMlERGRmRw4cAA6nc7iAuW1a9cwduxYPP/889i/fz+WLVuG8+fPo3///lAoHowOA1qrEdrZU5J5J3duhP6tuXfSGlnu+joREZGN27NnDxo0aICGDRuauxQA91ZM582bhwULFsDOzg6fffYZxo0bBweHJ68Yjg30gGtle0yLSoJWL0KnL/3pb6VCgEohYEawF8OkFRNEUZT7Ok4iIiJ6BE9PT3To0AHLly83ax23b9/G0qVLMWvWLNy+fRvjx4/HlClTUK1aNYPGycgpQFhkIuLSsqBUCE8MlsWv+7u7YmYvbz7mtnIMlERERGaQnp6OevXqYevWrejTp49ZatBqtfj+++8RHh6Ov//+GyNGjMAnn3yCmjVrGjVu6vVcbIjXICYlE5rsgge6VQq417Q80NMNg33VPM1tIxgoiYiIzGDVqlUYNWoUsrKyDF4JNJYoiti+fTs++ugjJCcnY8CAAZgxYwY8PDwknyu/UIvL2fko0uphp1Kgnosjb8CxQfwVJSIiMoM9e/agdevWJg+T+/btw9SpU3H8+HF06dIFmzZtQvPmzWWbz9FeBa+aVWUbnywDT3kTERGZmE6nw969e016ujshIQFBQUHo1KkTVCoVYmJisHPnTlnDJJUfDJREREQmdurUKeTk5JgkUCYnJ+P111/HSy+9hKtXr+Knn37C4cOH0b59e9nnpvKDgZKIiMjE9uzZA0dHR/j6+so2x5UrVzBixAh4eXnh2LFjWLNmDc6ePYvXXnsNgiDPHdxUfnEPJRERkYnt2bMHgYGBsLOzk3zs7OxszJ49G4sXL4aTkxPmz5+Pd999FxUrVpR8LqJiDJREREQmlJ+fj0OHDmH+/PmSjpuXl4evv/4ac+fOhV6vx9SpUzFx4kRUqVJF0nmIHoWBkoiIyIRiY2Nx9+5dyfZPFhUV4dtvv8Vnn32GGzduYMyYMQgLC8Ozzz4ryfhEpcFASUREJKOH+zDu3LMftWrVwvPPP2/UuHq9Hps2bcInn3yCy5cv480330R4eDjq1asnTeFEBmBjcyIiIomV3BSTnAlNzoM3xUAUUUmXj/7+TTDIRw2P6obdFCOKIqKjoxEWFlZyyObzzz9HkyZNJP0ciAzBQElERCQRue+yPnToED788EMcOnQIAQEBmD17Ntq0aSPlp0BUJmwbREREJIGIBA06LTiIw5eyAeCJYfL+1w9fykanBQcRkaB57HvPnj2LV199Ff7+/sjLy8POnTtx4MABhkmyGAyURERERloSk4qp2xNRqNU/NUg+TKcXUajVY+r2RCyJSX3gtUuXLmHIkCFo1qwZ/vjjD2zatAknTpxAly5d2EuSLAoP5RARERkhIkGD+btTJBlr/u4UPFvZHu3V9vj888+xYsUKuLi44JtvvsGwYcNQoUIFSeYhkhr3UBIREZVRRk4BOi04iEKtXrIxldDhf9+Ph6LgBqZOnYpx48bB0dFRsvGJ5MBASUREVEZDVsfj8KVsgx9zP4mo1+E54RZ2TukGZ2dnycYlkhP3UBIREZVB6vVcxKVlSRomAUBQKHFdqIYcLR9vk/VgoCQiIiqDDfEaKBXyHIxRKgSsP/r4U99EloaBkoiIqAxikjMlX50sptOLiEnJlGVsIjkwUBIRERkor1ALTU6BrHNosguQX6iVdQ4iqTBQEhERGSg9Ox9yn2gVAVzOzpd5FiJpMFASEREZqEjCNkGWMA+RsRgoiYiIDGSnMs2PT1PNQ2Qs/k4lIiIyUD0XR8h98aHw7zxE1oCBkoiIyECO9iqonR1knUPt4gBHe96QTNaBgZKIiKgMAhu5ydqHMtDTTZaxieTAQElERFQGg3zUsvahHOyrlmVsIjkwUBIREZWBR3Un+Lu7Sr5KqVQI8Hd3hbubk6TjEsmJgZKIiKiMZvbyhkohABJ2pVQpBMzs5S3ZeESmwEBJRERURnWcHRBcqxCQ8Mz3jGAv1JH5wA+R1BgoiYiIyig6Ohpfv98PdW6clmS8yZ0boX9r7p0k68NASUREVAYxMTHo06cPunbtiv2Lp2B2b2/YqxQG76lUKgTYqxSY09sb7wW6y1QtkbwEURTlvo6UiIjIphw5cgRBQUHw8/NDVFQUKlasCADIyClAWGQi4tKyoFQITzwFXvy6v7srZvby5mNusmoMlERERAY4deoUAgMD8eKLL2LXrl1wcPhvEEy9nosN8RrEpGRCk13wwJEdAfealgd6umGwr5qnuckmMFASERGV0vnz59GuXTvUq1cP+/btQ5UqVZ76MfmFWlzOzkeRVg87lQL1XBx5Aw7ZHAZKIiKiUrh48SL8/f3h6uqKAwcOwNnZ2dwlEVkMBkoiIqKnyMjIgL+/P+zt7REbG4vq1aubuyQii8JASURE9ATXrl1DQEAA7t69i7i4ONSuXdvcJRFZHG7iICIieozs7GwEBQUhPz8fsbGxDJNEj8FASURE9Ag3b97EK6+8gmvXriE2NhYNGzY0d0lEFouBkoiI6CH5+fno0aMHLl68iJiYGDRu3NjcJRFZNAZKIiKi+9y5cwc9e/bE6dOnsWfPHjRr1szcJRFZPAZKIiKif929exf9+vXDoUOHsHPnTvj6+pq7JCKrwEBJREQEQKfTYciQIdi1axd+/vlntG/f3twlEVkNBkoiIir39Ho9RowYga1bt2LLli3o2rWruUsisioMlEREVK6Joojx48dj7dq1+OGHH9C7d29zl0RkdRgorQDvgSUikocoivjwww+xZMkSrFixAoMHDzZ3SURWianEQqVez8WGeA1ikjOhySnA/dcZCQDUzg4IbOSGQT5qeFR3MleZRERWbebMmZgzZw6++uorjBw50tzlEFktXr1oYTJyChAWmYi4tCwoFQJ0+sf/8hS/7u/uipm9vFHH2cGElRIRWbeFCxciJCQEM2bMwCeffGLucoisGgOlBYlI0GBaVBK0evGJQfJhSoUAlULA9GAvDGitlrFCIiLb8O2332LkyJH44IMPMGvWLAiCYO6SiKwaA6WFWBKTivm7U4weJ7SzJ8YGekhQERGRbdqwYQOGDBmCMWPGYPHixQyTRBJgoLQAEQkaTN2eKNl4c3p7oz9XKomI/iMyMhKvv/46hgwZgtWrV0OhUJi7JCKbwEBpZhk5Bei04CAKtXrJxrRXKbA3pB33VBIR3WfXrl0IDg5Gr169sHHjRiiVSnOXRGQz+FczMwuLTITWgP2SpaHViwiLlG7Fk4jI2h08eBC9evVCly5dsH79eoZJIokxUJpR6vVcxKVlGXQApzR0ehFxaVlIy8yVdFwiImsUHx+PHj16oG3bttiyZQsqVKhg7pKIbA4DpRltiNdAqZBnM7hSIWD9UY0sYxMRWYszZ86gS5cuaNq0KX7++WdUrFjR3CUR2SQGSjOKSc6UfHWymE4vIiYlU5axiYiswYULFxAUFISGDRtix44dcHR0NHdJRDaLgdJM8gq10OQUyDqHJrsA+YVaWecgIrJEly5dQseOHVG9enX89ttvqFq1qrlLIrJpDJRmkp6dD7mP14sALmfnyzwLEZFluXLlCjp27AgHBwfs2bMHLi4u5i6JyOYxUJpJkYRtgixhHiIiS3D9+nV07NgRer0e+/btw3PPPWfukojKBZW5Cyiv7FSmyfKmmoeIyNxycnLQuXNn5ObmIjY2Fmo1L3ggMhUGSjOp5+IIAZD1sbfw7zxERLbu1q1b6Nq1K/766y/ExsbC3d3d3CURlStcvjITR3sV1DLfZKN2cYCjPf/OQES2raCgAD169EBycjJ2796NF154wdwlEZU7DJRmFNjITdY+lIGebrKMTURkKQoLC9GrVy+cPHkS0dHRaNGihblLIiqXGCjNaJCPWtY+lIN9uX+IiGzX3bt30b9/fxw8eBBRUVHw8/Mzd0lE5RYDpRl5VHeCv7ur9KuUoh63/zyJCe+8gZSUFGnHJiKyADqdDm+//Taio6Oxbds2dOjQwdwlEZVrDJRmNrOXN1QSB0r7Cip8FuyFpKQkeHl5YdKkSfjnn38knYOIyFxEUcS7776LiIgIbNy4Ed27dzd3SUTlHgOlmdVxdsD0YC9Jx5wR7IWRA3vj/PnzCA8Px4oVK+Dp6YmVK1dCp9NJOhcRkSmJoogJEyZg1apVWLNmDfr27WvukogIDJQWYUBrNUI7e0oy1uTOjdC/9b29k5UqVcJHH32E5ORkdOnSBaNGjULLli1x4MABSeYiIjK1Tz75BIsWLcI333yDN99809zlENG/GCgtxNhAD8zu7Q17lcLgPZVKhQB7lQJzenvjvcD/9l6rVasWfvjhBxw9ehQVK1ZEYGAgXn/9dVy+fFmi6omI5Ddr1ix88cUXmDdvHkaPHm3ucojoPoIoinJfKU0GyMgpQFhkIuLSsqBUCE88BV78ur+7K2b28kadUvS11Ov12LhxIz744ANkZ2cjNDQUU6dOReXKlaX8NIiIJLVo0SKMHz8e4eHhmDZtmrnLIaKHMFBaqNTrudgQr0FMSiY02QUP3Kgj4F7T8kBPNwz2VcPdzcng8fPy8jBnzhzMmzcPLi4umD17NgYNGgSFgovWRGRZVq9ejeHDhyM0NBRz586FIMjTv5fIEPmFWlzOzkeRVg87lQL1XBzL9WUiDJRWQM7ftJcvX8aUKVPw448/wsfHBwsXLoSvr68kYxMRGWvTpk0YNGgQRo0ahW+++YZhksyqZLEnOROanEcs9jg7ILCRGwb5qOFR3fDFHmvGQEkAgIMHD2L8+PE4c+YMBg8ejNmzZ6NWrVrmLouIyrGff/4Zffr0waBBg7BmzRo+QSGzkXs7mi1goKQSOp0O3333HT766CPk5+fjww8/xKRJk1CpUiVzl0ZE5czu3bvx6quvIjg4GJs2bYJKVX4fJZJ5RSRoMC0qCVq9aNDtdkqFAJVCwPRgLwxobfs31zFQ0n/cvHkTn332Gb7++mvUqlUL8+fPR58+ffioiYhMIi4uDq+88goCAwMRGRkJOzs7c5dkk7gH8OmWxKRi/m7jb5wL7eyJsYEeElRkuRgo6bFSUlIwadIk/PrrrwgICMDXX3+NZs2ambssIrJhCQkJ6NixI1q1aoUdO3bwCYnEuAew9CISNJi6PVGy8eb09i7pE22LGCjpqX777TeEhITgwoULGD58OD7//HO4ubmZuywisjFnz55F+/bt8fzzz2P37t1sZyYh7gE0TEZOATotOIhCrV6yMe1VCuwNaWezX08GSiqVu3fvYtmyZZg2bRr0ej0+/fRTjBs3jo+iiOiRDH2cmpycjICAANSqVQv79+/HM888Y7pibRz3ABpuyOp4HL6UbdDX62mUCgF+DVywbpiPZGNaEgZKMkhWVhamTZuG5cuXo2HDhvjqq6/QvXt37q8kojI/Tv3zzz/h7++PqlWr4uDBg3B1dTV57baKewANl3o9F0ELY2Ubf29IQJn6R1s6Bkoqk8TERISEhGDfvn145ZVXsGDBAjRu3NjcZRGRGRjzOFVx+wYCAgIgCAJiY2NRs2ZNE1Zu27gHsGzCo5KwLj5d0tXJYkqFgCE+dREe7CX52ObGpl5UJt7e3tizZw9++uknpKamwtvbG+PHj8eNGzfMXRoRmVBEggadFhzE4UvZAPDUH8LFrx++lI1OXx1A+2FhuHv3Lvbt28cwKaGMnAJMi0qSdMxPo5KQkVMg6ZiWKCY5U5YwCdz7/R+TkinL2ObGQEllJggCXnvtNZw/fx4zZ87Ed999Bw8PD3zzzTfQarXmLo+IZLYkJhVTtyeiUKs3+AewTi+iUKvH3eb98M6XW1C3bl2ZqiyfwiIToZU4FGn1IsIipVvxtER5hVpoZA7NmuwC5Bfa3s9IBkoymr29PaZMmYLU1FQEBwdj7NixaN68Ofbt22fu0ohIJhEJGuP35v2793rtyWxsTtBIUBUB9/YAxqVlSb7KptOLiEvLQlpmrqTjWgK9Xo+8vDycTNFA7n2AIoDL2fkyz2J63ENJkjt+/DjGjx+Pw4cPo2fPnpg/fz4aNmxo7rLIxNg02XaxpYpls+U9gFqtFvn5+cjPz0deXt5//v2o/680/y4ouLcqaVfDEzXe+kr2zyNytB+aq6vJPo8pMVCSLERRxObNmzF58mRkZmYiJCQEH330EZycjDvZxpBi2dg0uXxgSxXL1m5eDNJlfGxb18UBB0MDn/ieoqIiyUNfXl4eCgsLn1qfnZ0dHB0dUbly5cf++3Gv/YPKmH1G/q4lO8a9DK+aVWWfx5QYKElWBQUFmDdvHubMmYMqVapg1qxZeOutt6BQlH63BUOK5WPT5PKDLVUsW16hFt7hv8n72FYU0fLPjbiTd/Ox4e/u3btPHaZixYplCn1P+3eFChXK/KnlF2rRROavnwDgXPgrNrcYwkBJJpGRkYEPPvgAmzZtQsuWLfH111+jbdu2T/4YhhSrwKbJ5YstP041F1EUcffuXdy5cwe3b9/G7du3H/jfhvz3/7T2OFW9i+w1q89vgIvidplDn6OjI5RKpex1loUlrPBaIwZKMqlDhw5hwoQJOHHiBAYMGIA5c+ZArf5vmGBIsQ5smlz+2PoPW1EUUVhYaFSoK8t/6/WG7UetWLEiKlWqhEqVKj3wvxXPNsD1pm/K9NX5f7a4B7AY/9JUNra13koW7+WXX8axY8fw/fff48MPP8Tzzz+PKVOmYMqUKXBwuLeqaExI0f0bQKduT0RWXiFDiowkOeX7r/m7U/BsZfty0TTZmpmypYqjvQp6vd6koe7OnTu4c+cODFlnUSgU/wl1j/rvatWqPfF1Q/7b3t7+sbeTJV29ie6LD0n1y/FYdirbbRIzyEeNtUcuyzK2Ti9isK9tfp9joCSTUygUGDp0KPr06YOZM2di1qxZ+O677zB37lyIDfwYUqyAXE2T/Rq6cruCBUvPzjdJSxX1Cy2Rd+UCioqKDPpYlUr11FDm5OQENzc3o0Nd8X9XqFDBoq6erefiCAGQfQ9gPRdHGWcwL4/qTvB3d5Xt4Jmt7hHmI28yu4sXLyI0NBS/xhxBrZHLAWXZN1Q/zJZakVjSCXee8i2fTmluoNeyw7LP06fKn6jvhKeGuof/t0rFNRLA9rclmAJbYxmOf/rI7Bo2bIjIyEh0mxeN81nS3h5QfLODtYYUSzzhXtw0WWr3N0221b/BWztTPeZ8560hNtdSxZQCG7nJugcw0NNN8nEtTR1nB0wP9pL0LvQZwV42GyYB3pRDFiL1ei7O54iAQtpTf9Z6s0NGTgGGrI5H0MJYrItPR/pDYRK490grPacA6+LTEbQwFkNWx5vknt0N8RooFfI84lMqBKw/yhtTLFXx41Q52frjVFMY5KOW9S5qW90D+LABrdUI7ewpyViTOzey+e1XDJRkERhS/l9EggadFhzE4UvZAPDUHwzFrx++lI1OCw4iQuYr7GKSM2X9YRWTkinL2GQ8R3sV1DKvsKhdHGyuP5+pFe8BlPp7qlIhwN/dtVw9QRgb6IHZvb1hr1IY/PVUKgTYqxSY09sb7wW6y1Sh5WCgJIvAkHLPkphUTN2eiEKt3uCvh04volCrx9TtiVgSkypLfaY85UuWR6vVorbyJqDXyTJ+eXmcagoze3lDJXGgVCkEzOzlLemY1mBAazX2hrSDXwMXAHhqsCx+3a+BC/aGtLP5lcliDJRkdgwp90jdhmezDCuVpjrlezk7X+ZZyBAFBQX45ptv0KhRI/w4833Jt6YUK0+PU+VWvAdQSra+B/BJ6jg7YN0wH+yZEIAhPnVR18XhP9s/BNw7sDTEpy72hgRg3TCfcvX14nMFMjtThhRL3ehvLW14iiQ88WgJ89CTZWdn45tvvsGiRYuQk5OD119/HVsmT8bC01q2VLECA1qrkZVXKMlfVMvDHsDS8KjuhPBgL4TDy6I6b1gCrlCS2TGkAGGRidBK/Mi/+IS7lEx1yteWmyZbg/T0dIwfPx5qtRozZ85E//79kZqaioiICLRs2ZKPU60I9wDKx9FeBa+aVdFcXQ1eNauW6zAJMFCSBSjvIaW4DY/Ue0jlOOHOU7627cyZMxg8eDAaNmyI9evXIzQ0FBqNBkuWLEGDBg1K3sfHqdaFewDJFMp3nCaLUN5vdig+4S5Xz7j1RzWS3RtbfMpXzqbJPOVrWqIoIiYmBnPnzsVvv/2GunXrYsGCBXjnnXfg6Pj4PzN8nGpdivcAlvS2TcmEJvsRvW1dHBDo6YbBvmpuPyCD8Ls2mV15DymmOOEeDulWk9g02TbodDps374dc+fOxfHjx9G0aVNs2LAB/fr1K/WNM2MDPeBa2R7TopKg1YsG/Z5QKgSoFAJmBHsxTJoQ9wCSXCzzGSCVO4GN3GTtQ2mpIcUaT7izabJ1u337NpYtWwZPT0/069cPVatWxW+//YZTp05h4MCBBl9fyMep1ot7AElK/N1DFmGQjxprj1yWZWydXkTPJi6yjG0sazzhXtw0mad8rUtOTk7Jie3s7Gz07dsXW7ZsQcuWLY0em49TiYiBkiyCXCFFgIg76WfRte1wzJ07F4MGDYJCYTkL89Z6wn1mL290WnBQ0l8rnvKVR3p6OhYsWIBVq1ZBp9PhnXfewcSJE9GwYUPJ5+LjVKLyy3J+slK5J0crEjuVEpFh/RAQEIA333wTL7/8Mk6cOCHpHMaw1hPuPOVr+c6ePVtyYnvdunWYNGkSNBoNli5dKkuYfBgfpxKVLwyUZDHkCim+TdyxefNm7N+/H7m5uWjdujVGjhyJ//3vf5LOVRbW3IZnQGs1Qjt7SjIWT/lKo/jEdteuXdG0aVPExcXhq6++Qnp6OqZPn45nn33W3CUSkY1ioCSLImdICQwMxKlTp/D111/jxx9/hKenJxYvXgyt1nxXMhafcJeTnCfcrblpcn6hFklXb+KU5gaSrt60+Ks5n0Sn02Hr1q3w8fFBhw4d8Pfff2PDhg1IS0vD+++/j8qVK5u7RCKycYIoinKfCSAyWESCRtZWJP/73//w0UcfYdWqVfDy8sLixYvRvn17CSo3XHhUkqxteIb41JWsD+XjZOQUICwyEXFpWU/tqVn8ur+7K2b28jbpY+6SQyPJmdDkPOLQiLMDAhu5YZCPGh7VLf/QyO3bt/H9999j/vz5uHjxIjp06IApU6agc+fOEAS5176JiP4fAyVZLFOElBMnTmDcuHE4cuQI+vXrh3nz5kGtNu2j19TruQhaGCvb+HtDAkx2orY4sG08cAZFdlWA+0KNOU/5WkvgLa1HndiePHkyWrVqZe7SiKicYqAkiyd3KxK9Xo8NGzZgypQpuHnzJsLCwhAaGoqKFStK9jk8zZDV8bK14Vk3zEeyMUurfv366Nm3P4aHfGj2U77GrnZPD/bCAAvZ36nRaLBgwQJ8++230Ol0GDp0KCZOnAh3d96zTETmxUBJVkXOViS3bt3C559/joULF6J27dpYsGABgoODTfLoMCOnAJ0WHEShhO197FUK7A1pZ/IVtry8PDg5OWHt2rV46623TDr3w5bEpEpyNWBoZ0+MDfSQoKKyOXv2LObNm4dNmzahSpUqGDt2LMaOHQs3N8ts2E9E5Q8P5ZBVkbMVSZUqVTB37lwkJibC09MTPXv2RJcuXXDhwgXJ5ngcW2rDc/78eQBAkyZNTD73/SISNJKESQCYvzsFmxM0koxVWqIo4sCBA+jWrRuaNm2K2NhYfPnll9BoNJgxYwbDJBFZFAZKooc0atQIO3fuxM8//4y0tDR4e3sjNDQUt27dknVeSU64//vAwZxteM6dOwdBENC4cWOzzA/cW/GdFpUk6ZifRiUhQ+ZrMoEHT2wHBgbir7/+wvr165GWlobx48fzxDYRWSQGSqJHEAQBwcHBSEpKQnh4eMndx99//z30evlutzGmDY8AEXptEUY2czRLG55iSUlJaNCgARwczHeYJSwyEVqJT81r9SLCIhMlHfN+t2/fxooVK/D888/j9ddfR+XKlbFr1y6cPn0agwYNQoUKFWSbm4jIWAyURE9QsWJFfPTRR7hw4QLat2+Pt99+G23btsXx48dlm3NAazX2hrSDX4N7948/LVgWv+7X0BVuCSvww7R3cfv2bdnqe5pz586Z9XF36vVcxKVlSd6GSacXEZeWhbTMXEnHzcnJwRdffIF69ephzJgxaN68OY4dO4b9+/fjlVdeYfsfIrIKDJREpVCnTh1ERETgwIEDyM/Px0svvYThw4cjMzNTnvmcHbBumA/2TAjAEJ+6qOvi8J8bdQQAdV0cMMSnLvaGBGDDcF+sW74Qly9fxqeffipLXaVx7tw5eHnJ2/fySTbEawxe3S0tpULA+qPS7KXUaDQICQmBWq3G559/jj59+iA5ORlbtmxB69atJZmDiMhUeMqbyEBarRbLly/HJ598AlEUMWPGDIwZMwYqlbwtcUp7wn3evHn44IMPcOjQIfj5+cla08Nu3LgBZ2dnbNy4EW+88YZJ5y7Wbl4M0mXc61jXxQEHQwPL/PGJiYklJ7adnJzw3nvvYdy4cTxkQ0RWjYGSqIyysrLw8ccfY+XKlXjhhRewaNEidOjQwdxlQafT4eWXX0Z2djZOnz5t0r2Mhw4dgr+/P86ePQtvb2+TzVssr1AL7/DfIOc3NQHAufBXDOowIIoiYmNjMWfOHOzcuRN16tTBpEmTMGzYMB6yISKbwEfeRGXk6uqK5cuX4/jx46hatSo6duyI119/HRqNadvLPEypVGLt2rXIyMjAxx9/bNK5z507B6VSCU9Pae5jN1R6dr6sYRIARACXs/NL9V6dTodt27bB19cX7du3x5UrV7Bu3TpcvHiRJ7aJyKYwUBIZqUWLFjh06BDWrVuH33//Hc8//zxmzJhh1oMxjRo1KmnSfujQIZPNm5SUBE9PT9jb25tszvsVSdgY3ph57ty5g5UrV6Jx48bo27cvHB0dsXPnTpw5cwaDBw/miW0isjkMlESPkV+oRdLVmziluYGkqzeRX6h97HsFQcDgwYORnJyMcePG4fPPP8cLL7yAyMhImGtXyYQJE9CmTRsMHToUBQXy908EzH/C205lmm9pj5vnxo0bmDlzJurWrYt3330XTZs2RXx8PPbv348uXbrwxDYR2SzuoSS6T8m94cmZ0OQ84t5wZwcENnLDIB81PKo//t7wlJQUTJgwATt37kRQUBC+/vprszT6TklJQdOmTTFq1CgsXLhQ9vmeffZZjB07FtOmTZN9rkfJL9SiiRn2UGZkZGDBggVYuXIltFothg4dikmTJvGObSIqN7hCSYR7N6sMWR2PoIWxWBefjvSHwiRwb+9cek4B1sWnI2hhLIasjn/szSmenp7YsWMHfvnlF1y6dAkvvvgiJk2ahJs3b8r+uTxcx6xZs7Bo0SLExsbKOldmZiaysrLMukLpaK+CWubrJtUuDiVh8ty5c3jrrbfQoEEDrFmzBhMmTEB6ejqWLVvGMElE5QpXKKnci0jQYFpUErR60aBm2EqFAJVCwPRgLwx4wjWHd+7cwYIFC/D555/DyckJs2fPxptvvgmFwjR/n9Pr9WjXrh2uXr2Ks2fPwtHRUZZ59u/fj44dO+KPP/7A888/L8scpREelYR18emSNzYH7v2aD/ZRo0PVbMydOxfR0dGoU6cOJk6ciGHDhsHJ6fGr1kREtowrlFSuLYlJxdTtiSjU6g0OIDq9iEKtHlO3J2JJTOpj31exYkV8+OGHSE5ORocOHTB06FD4+fkhISHB2PJLRaFQYM2aNfj777/x4YcfyjbPuXPnYGdnZ/aVuUE+alnCJHDv13zHwqlo3749NBoNfvjhB1y8eBETJkxgmCSico2BksqtiAQN5u9OkWSs+btTsDnhye2CateujY0bN+LgwYO4ffs2XnrpJQwbNgzXr1+XpIYncXd3x+zZs7F48WIcOHBAljmSkpLQuHFj2Ru8P41HdSc8X1WEqNdJO7Beh9t/noSTmI/o6GicPXsWQ4YM4YltIiLwkTeVUxk5Bei04CAKJWwzY69SYG9IO9QpxR4+rVaLlStX4uOPP4ZOp8P06dPx3nvvyRpO9Ho9AgMDkZGRgbNnz0reA7Ft27aoV68eNmzYIOm4hsjNzcXEiROx9sdfUHvUCogKacKtKIpQiDos7uKGHoFtJBmTiMiWcIWSyqWwyERoJX4sqtWLCItMLNV7VSoVxowZg9TUVAwcOBATJ05Es2bNsG/fPklrup9CocB3332H69ev44MPPpB0bFEUzd4y6Pfff0ezZs2wadMmLJ07AzP7NJdsbEEQMLtvc4ZJIqLHYKCkcif1ei7i0rIk32en04uIS8tCWmZuqT/GxcUFy5Ytw4kTJ+Ds7IxOnTqhb9++uHz5sqS1FWvYsCHmzJmDb775Bvv375ds3L/++gu3bt0yS6AsKipCWFgYAgICUL16dZw5cwYjR47EGy+pEdpZmht7JnduhP5POHhFRFTeMVBSubMhXgOlQp4G00qFgPVHDb96sXnz5oiNjcWGDRtw5MgRNG7cGNOnT5fltp0xY8agffv2eOedd5CbW/rw+yTnzp0DAHh5eUkyniHz+vj4YN68efjss88QGxuLhg0blrw+NtADs3t7w16lMPjXXKkQYK9SYE5vb7wXyBZARERPwkBJ5U5Mcqasp4BjUjLL9LGCIGDgwIFITk7GhAkT8MUXX6Bx48bYvn27pLftFD/6zsrKwpQpUyQZ89y5c3BwcEC9evUkGe9p9Ho9vvrqK7Rs2RJFRUU4duwYwsLCHnkgaEBrNfaGtINfAxcAeGqwLH7dr4EL9oa048okEVEpMFBSuZJXqIXmMc3IpaLJLnjiNY1PU7lyZcyaNQtJSUlo0qQJ+vTpg6CgIJw/f16yGuvXr4958+Zh+fLl2Lt3r9HjJSUlwcvLyyS9NdPT09GxY0dMmjQJY8eOxYkTJ9C8+ZP3S9ZxdsC6YT74dYwPmlfOBfL+95+QLgCo6+KAIT51sTckAOuG+ZTqgBUREfGUN5UzSVdvovviQ7LPs2Pcy/CqWVWasXbswIQJE/Dnn39i3LhxCA8PR9Wqxo+t1+sRFBSEtLQ0JCYmokqVKmUeq3Xr1mjSpAnWrFljdF2PI4oi1q1bh3HjxqFq1ar4/vvvERgYWKqP/eeff7B8+XJ8/fXXuH79Onr37o1xIaFwrd8YRVo97FQK1HNxfOA6RSIiKj2uUFK5UiRhmyBTzdO9e3ecO3cOn3/+Ob799lt4enriu+++g15v3BwKhQKrV69GTk4OJk+eXOZx9Ho9zp8/L+uBnKysLPTt2xdvvfUWevbsicTExFKFyStXriA0NBR16tRBeHg4goODkZycjK1bt6JdW1941ayK5upq8KpZlWGSiMgIDJRUrtipTPNbXup57O3tMXXqVCQnJ6NTp04YNmwYfH19ER8fb9S49erVw/z587Fy5Urs3r27TGNcvnwZBQUFsgXKHTt2oEmTJjh48CC2bt2K77///qkrtElJSXj77bdRv359rF69Gu+//z4uX76MFStWwMPDQ5Y6iYjKMwZKKlfquThCnvPd/0/4dx451KpVCxs2bEBcXBzu3r0LX19fDB061KjbdkaOHIlOnTph+PDhuHnzpsEfL9cJ77y8PIwaNQo9evRAy5YtkZiYiD59+jz2/aIoIi4uDq+++iqaNGmCffv2Ye7cudBoNPjiiy/w3HPPSVofERH9PwZKKlcc7VVQy33QIi8L4R9/iJiYGNy9e1eWKV5++WUcP34cy5YtQ1RUFDw9PbFgwYIyzScIAlatWoV//vkHkyZNMvjjz507h6pVq6JWrVoGf+zjHD58GM2aNcP69euxfPly/Prrr6hRo8Yj36vX6xEZGQk/Pz8EBATgzz//xPfff4+LFy8iJCSEd2wTEZkAAyWVO4GN3GTrQ6mAiFqKf7B+/Xp06NABrq6u6Nu3L9asWYNr165JOpdSqcS7776LlJQUDB48GKGhoWjatCn27Nlj8Fh169bFl19+idWrV2PXrl0GfWzxaXRBMP5rWlRUhI8++gj+/v5wc3PDmTNnMGrUqEeOfefOHaxatQqNGzdG7969YW9vjx07diAxMRFvvvkm7OzsjK6HiIhKh4GSyp1BPmrZ+lDqIWDtR+/gr7/+wokTJzB58mT89ddfGDZsGGrUqIFWrVrh008/RXx8PHQ6nSRzuri4YOnSpThx4gRcXV3RuXNn9O7d2+DbdoYPH47OnTtj+PDh+Oeff0r9cefOnZPkcXdSUhJ8fX0xd+7ckibl7u7/bSj+zz//YPbs2ahfvz5GjhyJJk2a4OjRozhw4AC6desmSbAlIiLDMFBSueNR3Qn+7q6Sr1IqFQL83V3h7uYEhUKBFi1a4OOPP8aRI0eQmZmJdevWwdPTE0uWLIGvry+ee+45vPnmm4iIiEBOTo7R8zdr1gwHDx7Exo0bcezYMTRu3BjTpk1DQUHp+m4WP/rOzc3FxIkTS/UxWq0WFy5cMOpAjl6vx4IFC9CyZUsUFhYiPj7+kU3K//rrL0yePBlqtRrTpk3Dq6++igsXLmDbtm3w8fEp8/xERGQ89qGkcikjpwCdFhxEoYTtfexVCuwNaffUZtharRbx8fHYsWMHoqOjcebMGSgUCvj5+aFbt27o3r07vL29jVppy8vLw8yZM/Hll1/iueeew5dffok+ffqUaszvvvsOw4YNw6+//oru3bs/8b0XLlxA48aNsX///lL3hLyfRqPB22+/jZiYGEyYMAEzZ85EpUqVHnjP+fPnMW/ePGzYsAEODg4YM2YM3n//fR6yISKyIAyUVG5FJGgwdXuiZOPN6e1dpmv6rly5gp07d2LHjh3Yu3cv8vPzUbt2bXTr1g3dunVDx44dUbly5TLVlJaWhpCQEPz666/o0KEDFi1a9NTH06Ioonv37jhz5gzOnTuHatWqPfB6fqEWl7PzUaTVI/bAfoQMH4xrV9Lh5uZW6roeblK+du1adOjQ4YHXf//9d8yZMwe//voratWqhYkTJ2LEiBE8ZENEZIEYKKlcWxKTivm7U4weZ3LnRngv8L/7/QxVWFiI2NhYREdHY8eOHUhNTYWdnR3atWuH7t27o1u3bmXqoxgdHY0JEybg0qVLGDt2LMLDw/HMM8889v1XrlxBkyZN8Nprr+H7779H6vVcbIjXICY5E5qcAtz/TUMURdRzcURgIzcM8lHDo/qTA19WVhbeffddbNu2DYMHD8bixYtLatHr9YiKisLcuXNx5MgReHl5YfLkyXjjjTd4yIaIyIIxUFK5F5GgwbSoJGj1okGHdZQKASqFgBnBXmVamSyN1NRUREdHIzo6GgcOHEBRURE8PDxKHo0HBATA3t6+VGMVFRVh4cKF+Oyzz1CpUiXMmjULQ4cOfez922vXrsWICVPRceoqXLgpQKkQnvj1KX7d390VM3t5P/LRf3R0NIYNG4aioiKsWLECffv2BXAvSK9fvx7z5s1DcnIyAgICMGXKFHTt2tUk94MTEZFxGCiJcG9PZVhkIuLSsiQJTnLIy8vD/v37S1Yvr1y5AkdHR3Tq1Knk8Xjt2rWfOs7Vq1fxwQcfYP369WjVqhUWL14MX1/f/7xv0zENwradgh4CBIWy1HUWB+3pwV4Y8G/QzsvLQ2hoKFasWIGuXbti9erVqFGjBm7evInly5dj4cKFuH79Onr16oXJkyc/sh4iIrJcDJRE9yl5tJuSCU32g492BQBqFwcEerphsK8a7m7m28sniiISExNLwuXhw4eh1+vx4osvlqxe+vr6/uek9P1+//13jBs3DqdOncJbb72F2bNnlxx0kWorQGhnT7SsmIUhQ4bg77//xpdffolRo0bh6tWr+Prrr7F8+XIUFhbirbfewqRJk9CoUSOj57QE9+8ztVMpUM/FkXeFE5FNY6AkegxrCgU3btzAb7/9hujoaOzcuRNZWVmoVq0aXnnlFXTr1g1dunTBs88++5+P0+l0WL16NcLCwlBUVIRp06ahul8vfBz1h2S15excjBcq/oN169bh7t27mD9/PtavXw8HBweMHj0a77///mNvwbEmT9pnKgBQOzuUep8pEZG1YaAksjE6nQ7Hjx8vWb08ceIEBEGAj49Pyepls2bNHtibmJOTg08//RQrN25HzeHfAMoKktQiiiJUgog5AZXxw7IF+OWXX1CrVi2EhIRgxIgRqFKliiTzmJM1bJcgIpIbAyWRjbt27Rp27tyJ6Oho7N69G7du3cJzzz2Hrl27onv37ggKCioJdj2/3ovTfxcAQun3TD6VXofb6WfgmhiBKVOm2NSJbWMPdN2/z5SIyJoxUBKVI3fv3sXvv/9e0lT9/PnzUKlU8Pf3h2/nnth4s6Fsc+8e7w/P56x/RbKYlPtMxwYa3gqKiMiSMFASlWN//vlnSVP1BF09VGr6ikEnuktLqRAwxKcuwoONv/PbElhKU3wiIkvBQElEAAD/ufuRceO2bOPXdXHAwVDDr2e0NOa8tpOIyFKxYzARIa9QiysyhkkA0GQXIL9QK+scphAWmQitAfslS0OrFxEWKd2KJxGRqTFQEhHSs/Mh96MKEcAvB47ijz/+wNWrV5Gfnw9re0CSej0XcWlZBh3AKQ2dXkRcWhbSMnMlHZeIyFQss6kekQWwpj6UxiqS8PHtk7w1dBiK/v7/gyxKpRJVq1Y16h9HR0cIgmCS+jfEa57aGqislAoB649qbGafKRGVL7b505GojMpTc+r8/HwkJibi+PHjiIo7CTToI/ucWyI2wkVxGzdv3nziP3/++ecD/33r1q3HrmYqlUpUqVLFqFBauXLlUoXSmORMWcIkcG+VMiYlE+FgoCQi68NDOUSw/ebU169fx+nTp3Hy5En8/vvvOHnyJP7++++S14UKFVFn4o+yrvQJAM6Fv1KmVV69Xo+8vLynBtEn/XPr1i3o9Y9eiVUoFE8NpZWqVMPqm43//UzkYczXiIjInBgoqdyzpebUOp0OaWlpOH36NE6fPo3jx4/j5MmTyMnJAQAIglCy0vfss8+iVatWCAoKgr+/PybuvwWNDZ/yFkXRqFCaq6qKyn2/kL3OHeNehlfNqrLPQ0QkJf41mMo1Y5pT6/4NoFO3JyIrr9DkzakLCgpw7ty5kvB46tQpnDlzBrdv3wuFKpUKWu29U9WVKlVC8+bNERgYiDZt2uCll176z93eHa4mYV18umz7AwM93SQf1xCCIMDJyQlOTk6oXbu2wR9/SnMDvZYdlqGyB5lqPysRkZQYKKncikjQSHLTCQDM352CZyvby9ac+n//+19JcCwOj8nJydDr9RAEAQ4ODigsLIRWq4UgCGjcuDHatm0LX19f+Pr64vnnn3/g7u5HGeSjxtojl2WpX6cXMdjXMlZxy8pOZZqmGKaah4hISgyUVC5l5BRgWlSSpGN+GpUEv4auRu2p1Ov1uHTp0gPB8fTp07h69SoAwM7ODlWqVEFRUVHJfkBXV1e0adOmJDy2atUKTk6GHxjyqO4Ef3dXHL6ULekqpVIhwK+BC9zdrPsQUz0XRwiArO2VhH/nISKyNgyUVC7J2Zx63TCfUr3/zp07SEpKKgmNp0+fxpkzZ5CXlwcAqFatGqpWrQpBEEoeX4uiCHd3d/j4+JQEyLp160p2mCa8x/MIWnAAIpSSjCmKIgRRxMxe3hJUZ16O9iqonR2QnlMg2xxqFwceyCEiq8TvXFTuFDenltr9zakfXo3Lzs5+4JH16dOn8ccff0Cn00GhUKBOnTp45plnoFar8ffff+PGjRu4ceMGnnnmGQQEBJQEyGbNmsHe3l7y2gHg5s2bGDWoD3Ju2OOZzmMkGVMQBFzf8TU2Vk3ClClTTNYvUi6Bjdxsep8pEVFZMVBSuSN3c+qluxPh73DtgfCYkZEBAHBwcICHhwdcXV3h5+eHa9euIS0tDenp6cjOzsZLL72Enj17wsfHBz4+PqhevbrkNT5KRkYGunXrhitXruDnn35Cor6mUftLRVGEIAiYFOSJ/1XwxdSpU/Hnn39iyZIlUKms99sO95kSET2a9X5nJyojuZtTb4lLwsKVI1G9enU0adIEvr6+aN26Na5du4Zz587hzJkzEAQBL7zwAgICAjBlyhT4+vqicePGUCqVstT1JGfOnEH37t2hVCrx+++/44UXXkA7AK6V7cvcTkkQRVzf8TX0z3XHjBkzUL9+fYwcORIajQabN28u0x5PS8B9pkREj8Y+lFSu5BVq4R3+m7z3Vosiml9cj3OnTyAtLQ3AvYMzxXseiwNmlSpV5KyiVPbs2YM+ffrA3d0dO3bsQI0aNR543ZiG7wu/+ASLFi1CbGws2rRpg71796JPnz5o0KABduzYgZo1a8r96ckiI6cAnRYcRKGE7X3sVQrsDWlnFU3yiYgehYGSypWkqzfRffEh2eepFr8c/k3qlwTI+vXrW9z+wbVr12LEiBEICgrCli1bULly5ce+t/hKyu1HL+Cm3v6Bz0XAvcMkgZ5uGOyrLlllu3v3Ltq3bw+NRoOTJ0/i2WefRWJiIrp16wYAiI6Ohre3dR7WiUjQYOr2RMnGm9PbW7aWU0REpsBASZLJL9TicnY+irR62KkUqOfiaHEnVk3VnDpytB+aq6vJPk9ZiKKIGTNmIDw8HMOHD8eyZctKva/xjTfeQMbfmVixcXupfp3/+usvNG/eHM2bN0d0dDSUSiWuXr2K7t2749KlS9i2bRs6deok5adnMsY0xb/f5M6N8F6guwQVERGZj2X9tCerU7xyFZOcCU1OwQOPkgUAamcHBDZywyAfNTyqm39/WHlvTn337l2MGjUKa9aswRdffIEPP/zQoJXT8+fPo02bNqW+GrBWrVrYuHEjOnfujM8//xzTpk1DzZo1ERsbi379+qFr16749ttv8fbbb5fxMzKfsYEeRu0zVSkEzAj24sokEdkEy/ypRxYvI6cAQ1bHI2hhLNbFpyP9oTAJ3GsAnZ5TgHXx6QhaGIshq+ORIWMPv9Iobk4tJ0ttTn3r1i10794d69evx7p16xAWFmZQmNTpdEhOTsYLL7xg0LydOnXC9OnTMX36dOzevRsA4OTkhF9++QXvvPMOhg4dimnTpsEaH5YMaK3G3pB28GvgAuBeUHyS4tf9Grhgb0g7hkkishl85E0Gi0jQGLUqMz3YCwPM9INUq9Xi5dl7cS1fJ9scdV0ccDA0ULbxy+Kvv/5C9+7d8eeffyIyMhIdOnQweIy0tDR4eHhg9+7dCAoKMuhj9Xo9unXrhuPHj+PUqVOoU6cOgHuP3+fOnYupU6diyJAhWLVqFezs7AyuzRKUrNanZEKT/YjV+kfsMyUishUMlGQQqfaNhXb2xNhADwkqerKrV6/i6NGjOHr0KOLj43H8+HHY+w2GU4vuEBTSt+hRKgQM8amL8GAvyccuq/sPwuzcuRNNmjQp0zhRUVF47bXXcOXKFdSqVcvgj8/KykKLFi1Qu3ZtHDhw4IHgGBERgbfeegtt27bF9u3b8cwzz5SpRkthDfuJiYikxEBJpWbpJ1tv376NkydPPhAgixuK165du+TEde0XWuGD2DzJ5n3Y3pAAi1mB2r9/P3r16oX69etjx44dZQqCxWbPno1Zs2bhn3/+KfOJ9aNHjyIgIADvvfceFixY8MBrcXFxeO2111CjRg1ER0ejbt26Za6ViIhMi4GSSsXSeu+JooiLFy+WhMejR4/izJkz0Gq1qFSpElq1alUSIH18fP4TpIasjpetOXVp7/KW27p16zBs2DAEBgbixx9/NLrv5VtvvYXk5GQcPXrUqHEWL16M999/Hz/++CP69u37wGvJycno2rUrbt++jV9//RUtW7Y0ai4iIjINBkoqFXMHsJs3b+LYsWMPrD5mZ2cDADw9PR9oGt6kSRNUqFDhieNZWkCWkiiKmDlzJj7++GMMHToUK1aseOrXozRat24Nb29vfPfdd0bXN2DAAOzcuRPHjx+Hp6fnA69nZmbi1Vdfxblz57B582b06NHDqPmIiEh+DJT0VKnXcxG0MFa28R9+RKzVapGUlIT4+PiSAHnhwgWIoohnnnkGPj4+JeHxpZdegrOzc5nmtfRH+GVx9+5djBkzBqtWrcKMGTPw8ccfS9JQXa/Xo0qVKggPD0doaKjR4+Xm5qJ169aws7PD0aNH4eDwYAgvKCjAoEGDEBUVhSVLlmD06NFGz0lERPLhLnF6qg3xmqdeu1dWSoWAFfv/wMuV/i4JjwkJCcjPz4dSqYS3tzfatWuHDz74AL6+vvDw8IBCIU23qwGt1cjKK5SsObW5w2Rubi769euHvXv3Yu3atXjrrbckG/vKlSvIz883uGXQ4zg5OWHr1q146aWXMGbMGKxZs+aB4Ovg4ICtW7ciNDQUY8aMwaVLlzBnzhzJfu2JiEhaDJT0VDHJmbKESQDQ6UVsjDmD+StHokaNGvD19cWnn34KX19ftGzZEo6O8vZztJXm1H///Te6d++OtLQ07Ny5U/LbZ86fPw8AaNy4sWRjNmnSBCtWrMCbb74Jf39/DBs27IHXlUolFixYgPr162PChAm4fPkyfvjhB1SqVEmyGoiISBoMlPREeYVaaGRuRl7BuQYuXPwTnvXrmuW+6wGt1Wjb0BVhkYmIS8t66mps8et+DVwws5e32fdMnj9/Hl27doVOp8OhQ4fw4osvyjJHpUqVJD95PWTIEBw6dAjvvfceWrZsiWbNmv3nPe+//z7UajUGDhyITp064eeff4arq2upxmf7HiIi0+AeSnqipKs30X3xIdnn2THu5VJf5ycna2tOfeDAAfTs2RNqtRrR0dGoXbu2LPOMGDECJ0+exIkTJyQf+86dO/Dz88OtW7dw/Pjxx/agPHbsGF599VVUqVIFO3fuhLv7o++/trbrQImIbAEDJT3RKc0N9Fp2WPZ5Ikf7obm6muzzGMLSV7c2btyIoUOHIiAgAFu3bkXVqvIF8rZt26J+/fpYv369LONfunQJLVq0QGBgILZv3/7YlepLly6hW7duyMrKQlRUFPz8/Epey8gpMHiV2d/d1SJWmYmIrB13uNMT2alM81vEVPMYwtFeBa+aVdFcXQ1eNataTJgURRGzZ8/GoEGD8MYbb2DHjh2yhklRFHH+/HnJDuQ8SoMGDfDDDz/gp59+wldfffXE9x0+fBheXl7o0KEDtm7dCuDeif1OCw7i8KV7raSethe2+PXDl7LRacFBRCRoJPpMiIjKJ8v4CUkWJS8vD8ePH0d8fDx+jz8O0fMtWfc2CgDquch7+MZWaLVajBs3DsuXL8enn36K8PBw2fedXr9+Hf/884+sgRIAgoODMWXKFHzwwQfw8fHByy+//Mj3OTs7Y/fu3Rg6dCj69euHftO/w9GCZ8s0p+7fg1hTtyciK6/QJNeBEhHZIgbKck6n0+H8+fOIj48v+ScpKQl6vR6VK1dG69at4STcQR7kO1mrdnGwmNU/S5aXl4cBAwZg165dWL16Nd555x2TzCvHCe/H+eKLL3D06FH069cPp06dQvXq1R/5Pnt7e6xfvx66ej5lDpMPm787Bc9Wtjf7iX0iImvEn+LlzNWrVx8Ij8ePH0deXh4UCgW8vLzg4+OD999/Hz4+PnjhhRegVCoRHpWEdfHpsvWhDPR0k3xcW3Pt2jX06NEDycnJ2LFjB1555RWTzX3+/HlUqFABDRs2lH0ulUqFiIgING/eHAMHDsTu3buhVCof+d6//rmD00pPQKvDvXVu430alQS/hq7cU0lEZKByHygt/eCFMQoKCnDixImSG2fi4+Nx5coVAEDNmjXh4+ODjz/+GD4+PmjVqhUqV678yHEG+aix9shlWWrU6UUM9uWK0JNcuHABXbt2RWFhIeLi4h7ZWkdOf/zxBxo1agSVyjR/LmrUqIFNmzahU6dOCA8Px2efffbI94VFJkKrFyFVmAQArV5EWGSixdzHTkRkLWwjORnIFtuK6PV6XLhw4YHVx8TEROh0Ojg4OKBly5YYMGAAfH194ePjY1B7GY/qTvB3d5XtLm9LaL9jqeLi4vDaa6+hZs2aOHjwINRq04fv8+fPm+Rx9/0CAwPx+eefIywsDH5+fujatesDr6dez0VcWpbk8+r0IuLSspCWmcvfl0REBihXbYNsqa3I9evXHwiPCQkJuHXrFgRBQOPGjeHj41PyT5MmTYxeXcrIKUCnBQdRqNVL9BkA9ioF9oa0s7ivraXYvHkz3nzzTbRt2xbbt29/bH9GuVWvXh2jR49GeHi4SefV6/UIDg7GkSNHcPLkyQeaqsu9DWOIT12EB3tJPjYRka0qN4EyIkFj1PV604O9MMBMm/Vv376NU6dOPRAgL1++DODeD/v7w2OrVq1kayETkaDB1O2Jko03p7e3zR+AKMuWClEU8eWXX2Ly5MkYPHgwVq9eDTs7OxNV/KDs7Gy4urpi8+bN6Nevn8nnz8nJQYsWLVC9enXExsbC3t4eANBuXgzSZbzBqa6LAw6GBso2PhGRrSkXj7yXxKRi/u6UMn2sqduK6PV6pKamPhAez5w5A61Wi4oVK6JFixbo1atXyaNrtVptsusKB7RWIyuvsMxfy/tN7tzIZsOkMVsqdDodxo8fj6VLl+Kjjz7CZ599ZpbrKIv98ccfAExzwvtRnJ2dsXXrVrRt2xahoaFYvHixSa4D1WQXIL9QazP7qYmI5Gbz3y0jEjSSBCBAnrYiWVlZD4THY8eO4Z9//gEANGrUCD4+PnjnnXfg4+ODF198ERUqVJBs7rIYG+gB18r2Rq32zgj2sskwWZotFSKA9JwCrItPx9ojlx/YUlFQUFDSqHzFihUYOXKk6T+Jh5w/fx4KhQKenp5mq6FVq1ZYuHAhxowZg7Zt28I7oCvkfqwiAricnW8R14ESEVkDm37kbWn7/goLC3H69OkHAuTFixcBAK6urg88um7dujWqVbOsqwjvZ0v7UaVg7JaKSe3VWB32DpKSkvDjjz/+5xCKuYSEhCA6OhrJyclmrUMURQwePBg///wz1kXHIWTnVdnntMTrQImILJVNB8ohq+NlO5n8tLYioiji4sWLD4TH06dPo6ioCHZ2dmjevHlJePT19UX9+vXN+mizrEoe76ZkQpP9iMe7Lg4I9HTDYF+1zZ6aNWZLxf20JyMRNWsMWrRoIUFV0njllVdQqVIl/PTTT+YuBXl5eXjppZegr1oTd9qHyD7fjnEvc4WSiKiUbPaRt6nbiuTk5ODYsWMPPLrOzr53r7C7uzt8fHwwePBg+Pj4oGnTpiWHC6ydR3UnhAd7IRxeNt3T83Gk3FKhatELqTpXWE6cvPfIe8iQIeYuAwBQuXJlbNu2Da39XoZrOxHgdaBERBbDZn/ab4jXPPVRbFkpFQK+jEpAk8I/SgJkSsq9UFGtWjX4+Phg7Nix8PHxwUsvvQQXFxfJa7BEjvaqcrWik5FTgGlRSZKOaUk3tdy6dQtXrlyR/Q5vQzRu3Bgrly7G5Ni/UaFaTdnm4XWgRESGsdnvmDHJmbKESeDeKmVUwkWsXhOCpk2bIigoqOTGGQ8PD6t8dE2G+/+bWqRj7pta7l9lTr3wB4QKFc12wvtxBg4ciJXHl+JPvQ6C4tHXMhqD14ESERnOJgOlKdqKVHCuib+zcuBS5dHXFZJts6WbWp7U5qjOxB8xYd8/6PhXkkXdHLU0ZAC6f3NUlrF5HSgRkeEU5i5ADunZ+bK3FQGAa3k6E8xClqh4S4UclAoB649qZBn7fhk5BRiyOh5BC2OxLj4d6Q+FSQAQBAEZN+5gXXw6ghbGYsjqeGTI/Je10vCq44JWtRwh6qX9M6hUCPB3d7XZA2RERHKxyUBZJGGbIEuYhyyP3FsqYlIyZRm7WESCBp0WHMThS9klcz6tJgA4fCkbnRYcRESC/IH3aRYMfAl2KiWkbFShUgiY2ctbsvGIiMoLmwyUdirTfFqmmocsiylvapHDkphUTN2eiEKt3uBQrNOLKNTqMXV7IpbEpMpSX2nVcXbAZz29Jd2zPCPYyyIORBERWRubTET1XBwh97EYthUpv0yxpaL4phapSX1z1GYzr1QOaK3GxI7uAGD0SqUtXwdKRCQ3mwyUjvYqqGVeZWBbkfLLWrdUyNXmyNx7Kt/v1AgfdqwL6O4ComFfM6VCgL1KgTm9vfFeoLtMFRIR2T6bDJQAENjITdZDE2wrUn5Z65YKOdscmduoTk3wVcdquHP5DAA89c9+8et+DVywN6QdVyaJiIxks4FykI9a1kMTbCtSflnjloriNkdS/5m4v82RufXp0h6TWtrj6rej8XJ1Peq6OPzn10kAUNfFAUN86mJvSADWDfPhnkkiIgnY7DNbj+pO8Hd3le0ub7YVKb+Kt1Sky/ioV+otFXLfHLX+qAbhwV6Sj22o0NBQ/P7774iaNgQnT56EW8065e46UCIic7DZFUoAmNnLGyqJH3uzrQgB1relwtrbHJWWIAhYu3YtqlWrhtdffx0q6OBVsyqaq6vBq2ZVhkkiIpnYdKCs4+yA6RKvmrCtCAHWtaXC2tscGeqZZ57B1q1bce7cOYSEhJi7HCKicsGmAyVwr61IaGdPScZiWxEqVrylQupVSjluarHmNkdl1aJFCyxevBjLli3Dhg0bzF0OEZHNs/lACQBjAz0wu7c37FUKgwMA24rQ41jLlgprbXNkrOHDh+PNN9/EyJEjcf78eXOXQ0Rk08pFoATurVTuDWkHvwYuANhWhIxnLVsqrLXNkbEEQcA333yDBg0aoE+fPsjLyzN3SURENksQpbwI10qkXs/FhngNYlIyockueOBxoIB7J2wDPd0w2FfN09z0VEtiUiW5fWZy50ayrILnF2rRJPw3WR97CwDOhb9ikYdekpOT0apVK/To0QMbN26U9KpGIiK6p1wGyvvlF2rZVoSMFpGgwbSoJGj1okGHdZQKASqFgBnBXrKugrebFyNrm6O6Lg44GBoo2/jG2rJlC/r374+lS5dizJgx5i6HiMjmWNYzKjNwtFexrQgZzdK3VFhbmyOp9evXD++//z4mTJiAY8eOmbscIiKbU+5XKImkZolbKlKv5yJoYaxs4+8NCbD47SFFRUUICAjA33//jZMnT8LFxcXcJRER2QwGSiIZWdKWiiGr42W7OWrdMB/JxpSTRqNBixYt4OPjg19++QUKRbl/SENEJAl+NyWSkSVtqbCWNkdyUqvVWL9+PXbu3InZs2ebuxwiIpvBQElUTlhLmyO5denSBR9//DE++eQT7N+/39zlEBHZBD7yJipnLL3NkSnodDq88sorSExMxKlTp1CzZk1zl0REZNUYKInKIUtvc2QKmZmZaN68ORo0aID9+/ejQoUK5i6JiMhq8ZE3UTlk6W2OTMHNzQ1btmzBkSNH8NFHH5m7HCIiq8YVSqJyzhLbHJnSV199hUmTJiEyMhI9e/Y0dzlERFaJgZKISlhSmyNTEUURffr0wf79+3HixAk0bNjQ3CUREVkdBkoiKvdu3ryJli1bwsnJCYcPH0alSpXMXRIRkVXhHkoiKveqVq2KrVu34sKFCxg/fry5yyEisjoMlEREAJo1a4alS5fi22+/xffff2/ucoiIrAofeRMR3eedd95BREQE4uPj4e1tPbcAERGZEwMlEdF9CgoK0KZNG9y+fRvHjx9HlSpVzF0SEZHF4yNvIqL7ODg4YOvWrbh27RqGDx8O/p2biOjpGCiJiB7i4eGBNWvW4Mcff8TixYvNXQ4RkcXjI28ioseYOHEiFi9ejNjYWLRp08bc5RARWSwGSiKix7h79y7at28PjUaDU6dOwdXV1dwlERFZJD7yJiJ6jAoVKmDz5s24c+cOBg0aBJ1OZ+6SiIgsEgMlEdET1K5dGxs3bsSePXvwxRdfmLscIiKLxEBJRPQUQUFBCA8PR3h4OPbs2WPucoiILA73UBIRlYJer0e3bt1w4sQJnDp1CrVr1zZ3SUREFoOBkoiolLKystC8eXPUqVMHBw8eRIUKFcxdEhGRReAjbyKiUnJ1dcWPP/6IhIQEfPDBB+Yuh4jIYnCFkojIQIsWLcL48eOxdetW9OnT55HvyS/U4nJ2Poq0etipFKjn4ghHe5WJKyUiMg0GSiIiA4miiP79+2PXrl04ceIEPDw8AACp13OxIV6DmORMaHIKcP83VwGA2tkBgY3cMMhHDY/qTmapnYhIDgyURERlcOvWLbRu3RoVK1bEj9H78dmuNMSlZUGpEKDTP/7bavHr/u6umNnLG3WcHUxYNRGRPBgoiYjKKDExEe3e+RDPdBwJQal6YpB8mFIhQKUQMD3YCwNaq2WskohIfjyUQ0RURgezKqJKp9HQQWFQmAQAnV5EoVaPqdsTsSQmVaYKiYhMg4GSiKgMIhI0mL87BQAgCIJRY83fnYLNCRopyiIiMgsGSiIiA2XkFGBaVJKkY34alYSMnAJJxyQiMhUGSiIiA4VFJkJr4CPup9HqRYRFJko6JhGRqTBQEhEZIPV6LuLSsgzeM/k0Or2IuLQspGXmSjouEZEpMFASERlgQ7wGSoVxeyYfR6kQsP4o91ISkfVhoCQiMkBMcqbkq5PFdHoRMSmZsoxNRCQnBkoiolLKK9RCI/PBGU12AfILtbLOQUQkNQZKIqJSSs/Oh9w3QYgALmfnyzwLEZG0GCiJiEqpSKu3qXmIiKTCQElEVEp2KtN8yzTVPEREUuF3LSKiUqrn4gh5znf/P+HfeYiIrAkDJRFRKTnaq6B2dpB1DrWLAxztVbLOQUQkNQZKIiIDBDZyk7UPZaCnmyxjExHJiYGSiMgAg3zUsvahHOyrlmVsIiI5MVASERnAo7oT/N1dJV+lVEDEy+6ucHdzknRcIiJTYKAkIjLQzF7eUEkZKEUR2rtFuLlnGXJycqQbl4jIRBgoiYgMVMfZAdODvaQbUBDQ313A77uj8OKLL2L//v3SjU1EZAIMlEREZTCgtRqhnT0lGWty50aY924vnD17Fo0aNUKnTp0wZcoUFBYWSjI+EZHcBFEU5b5JjIjIZkUkaDAtKglavWjQYR2lQoBKIWBGsBf6t/7/gzh6vR5fffUVwsLC0KRJE2zYsAGNGzeWo3QiIskwUBIRGSkjpwBhkYmIS8uCUiE8OVjqdYBCCX93V8zs5Y06j+lreerUKQwcOBDp6en48ssv8e6770IQ5G6rTkRUNgyUREQSSb2eiw3xGsSkZEKTXYD7v7kKAFwrAhcPRWHdpyPR3b/lU8crKChAaGgoli1bhh49emD16tVwc2OfSiKyPAyUREQyyC/U4nJ2Poq0etipFKjn4gg7hYgaNWpg+PDhmD17dqnH+uWXXzBs2DAoFAqsWbMGXbt2lbFyIiLDMVASEZnQ6NGjER0djT///BMKRenPRV67dg1Dhw7Frl27MG7cOMyZMweVKlWSsVIiotLjKW8iIhMaOHAgNBoNDh8+bNDHPffcc4iOjsaiRYuwcuVKvPTSS0hMTJSpSiIiwzBQEhGZUNu2baFWq7Fx40aDP1YQBIwbNw7Hjx+HIAho1aoVFi5cCL1eL0OlRESlx0BJRGRCCoUCb7zxBrZs2YK7d++WaYwmTZrg2LFjeO+99xASEoKuXbvi77//lrhSIqLSY6AkIjKxgQMHIjs7G7t37y7zGBUrVsRXX32F3377DWfPnoW3tzd+/vlnCaskIio9BkoiIhPz9vaGl5dXmR57P6xz585ITEzEyy+/jJ49e2LUqFHIz8+XoEoiotJjoCQiMjFBEDBw4ED89NNPkoQ/V1dXREZGYsWKFVi/fj1atGiBEydOSFApEVHpMFASEZnBG2+8gYKCAkRFRUkyniAIGDlyJE6ePAknJyf4+vpizpw50Ol0koxPRPQk7ENJRGQmbdu2hbOzM3755RdJxy0qKsK0adMwZ84ctGvXDj/88APq1Kkj6RxERPfjCiURkZkMHDgQu3btQnZ2tqTj2tnZYdasWdi/fz/S0tLw4osvYsuWLZLOQUR0PwZKIiIzef311yGKIn788UdZxm/fvj3Onj2LoKAg9O/fH2+//TZyc3NlmYuIyjc+8iYiMqOuXbsiPz8fsbGxss0hiiJ++OEHjB07Fm5ubli/fj3atGkj23xEVP5whZKIyIwGDhyIuLg4aDQa2eYQBAFvvfUWTp8+DTc3N/j7+2PGjBnQarWyzUlE5QsDJRGRGfXs2ROVKlVCRESE7HM1bNgQcXFx+PjjjzF9+nS0a9cOf/75p+zzEpHtY6AkIjIjJycnBAcHS9LkvDRUKhXCw8MRFxeHq1evomnTpli3bh24+4mIjMFASURkZgMHDsSZM2eQlJRksjn9/Pxw5swZ9OzZE2+++SYGDhyIf/75x2TzE5FtYaAkIjKzLl26oFq1aiZbpSxWpUoV/PDDD9i0aRN27tyJpk2byno4iIhsFwMlEZGZ2dnZoW/fvti4caNZHj0PGDAAZ8+eRb169dC+fXt89NFHuHv3rsnrICLrxUBJRGQBBg4ciMuXL+Po0aNmmV+tVmP//v344osvMHfuXPj5+SE1NdUstRCR9WGgJCKyAAEBAahVq5bJH3vfT6lU4sMPP8SRI0dw8+ZNNGvWDKtWreKBHSJ6KgZKIiILoFAo8MYbb2Dz5s1m7w/ZqlUrnDx5EoMGDcKIESPQp08fya+HJCLbwkBJRGQhBg4ciP/973/Yu3evuUtB5cqVsXLlSmzfvh0HDx7Eiy++aBF1EZFlYqAkIrIQzZo1w/PPP2/Wx94P69WrFxITE/HCCy8gKCgIkyZNQmFhobnLIiILw0BJRGQhBEHAwIEDERkZiYKCAnOXU6JmzZr47bff8OWXX2LJkiXw8fHB+fPnzV0WEVkQBkoiIgvyxhtvIC8vD7/++qu5S3mAQqHAxIkTcezYMdy9exctW7bE0qVLy3RgJ79Qi6SrN3FKcwNJV28iv5B3ihNZO0Hk8T0iIovi6+uL5557Dj/99JO5S3mk27dvY8qUKViyZAm6deuG7777DtWrV3/ix6Rez8WGeA1ikjOhySnA/T94BABqZwcENnLDIB81PKo7yVo/EUmPgZKIyMIsWrQIoaGhuH79OqpVq2buch4rOjoaQ4cOBQCsWbMG3bp1+897MnIKEBaZiLi0LCgVAnT6x//IKX7d390VM3t5o46zg2y1E5G0+MibiMjC9OvXDzqdDlu3bjV3KU/UrVs3nD17Fq1atUL37t0xduxY3L59u+T1iAQNOi04iMOX7rUcelKYvP/1w5ey0WnBQUQkaOQrnogkxRVKIiIL1LlzZ9y9excxMTHmLuWpRFHEsmXLMGnSJDRo0AAbN25EXI4D5u9OMXrs0M6eGBvoIUGVRCQnBkoiIgu0du1avPPOO9BoNKhdu7a5yymV8+fP37tCUlkLz3QeI9m4c3p7o39rtWTjEZH0+MibiMgC9erVC3Z2dti8ebO5Sym1F154AVt3HYBz0ChJr2v8NCoJGTmW00aJiP6LgZKIyAJVrVoVr776qkU1OS+N6TuSIShVEARBsjG1ehFhkYmSjUdE0mOgJCKyUAMHDsTJkydx4cIFc5dSKqnXcxGXlvXUwzeG0ulFxKVlIS0zV9JxiUg6DJRERBaqa9euqFq1qtWsUm6I10CpkG5l8n5KhYD1R3nqm8hSMVASEVmoihUrok+fPti4caOkexLlEpOcKfnqZDGdXkRMSqYsYxOR8RgoiYgs2MCBA3Hx4kUkJCSYu5QnyivUQiPzwRlNdgGvaSSyUAyUREQWrH379qhRo4bFP/ZOz86H3GuoIoDL2fkyz0JEZcFASURkwZRKJQYMGICIiAjodDpzl/NYRVq9Tc1DRIZhoCQisnADBw7E9evXsX//fnOX8lh2KtP8ODHVPERkGP7JJCKycC1btoSHh4dFP/au5+IIec53/z/h33mIyPIwUBIRWThBEDBw4EBs27YNt2/fNnc5j+Ror4La2UHWOdQuDnC0V8k6BxGVDQMlEZEVeOONN5Cbm4vo6Ghzl/JYgY3cZO1DGejpJsvYRGQ8BkoiIivQqFEjtGzZsuSxd36hFklXb+KU5gaSrt60iHY6g3zUsvahHOyrlmVsIjIenx0QEVmJLv2HYsW+JLw8Zx/++ufOA216BABqZwcENnLDIB81PKo7mbw+j+pO8Hd3xeFL2ZIGS6VCgF8DF7i7mf5zIqLSEURruH6BiKgcy8gpQFhkIuLSsiDqdRAUyse+V6kQoNOL8Hd3xcxe3qgj877Gh2XkFKDTgoMolLC9j71Kgb0h7Uz+uRBR6fGRNxGRBYtI0KDTgoM4fCkbAJ4YJgGUrAwevpSNTgsOIiLBtPdf13F2wPRgL0nHnBHsxTBJZOEYKImILNSSmFRM3Z6IQq3e4EfIOr2IQq0eU7cnYklMqkwVPtqA1mqEdvY0bpB/H56NalMT/Vtz7ySRpeMjbyIiCxSRoMHU7YmSjTent7fJg1lEggbTopKg1YsGBWKlQoBKAPLj1qKu9i/ExMTAzs5OxkqJyFhcoSQisjAZOQWYFpUk6ZifRiUhI6dA0jGfZkBrNfaGtINfAxcAeGpLoeLX/Rq4YO/E9tg2dxKOHz+O999/X/Zaicg4XKEkIrIwQ1bHy3ZSet0wH8nGNETq9VxsiNcgJiUTmuyC/55Qd3FAoKcbBvuqHzjNvXr1agwfPhwrV67EiBEjTF43EZUOAyURkQVJvZ6LoIWxso2/NyTA7O138gu1uJydjyKtHnYqBeq5OD7xBpzRo0fju+++w8GDB+Hr62vCSomotBgoiYgsSHhUEtbFp8vSIFypEDDEpy7CJT6FLbeioiJ06NABly5dwokTJ1CjRg1zl0RED+EeSiIiCxKTnCnrbTMxKZmyjC0nOzs7bN26FYIg4PXXX0dRUZG5SyKihzBQEhFZiLxCLTQyH5zRZBdYxDWNhnruueewbds2JCQkYPz48eYuh4gewkBJRGQh0rPzIfceJBHA5ex8mWeRh6+vL5YuXYrly5dj1apV5i6HiO7Du7yJiCxEkYTXFVrCPHIYPnw4jh8/jvfeew9NmjThIR0iC8EVSiIiC2GnMs23ZFPNI5dFixahVatW6NOnD65du2bucogIDJRERBajnosjntz623jCv/NYs+JDOqIoom/fvjykQ2QBGCiJiCyEo70KamcHWedQuzg8seejtahRowa2bduGY8eOISQkxNzlEJV7DJRERBYksJHbU68oLCulQkCgp5ssY5tDmzZtsHTpUnzzzTf47rvvzF0OUbnGQElEZEEG+ahl7UM52Fcty9jmMmLECIwcORKjR49GfHy8ucshKrcYKImILIhHdSf4u7tKvkqpVAjwd3c1+7WLcli0aBFatmzJQzpEZsRASURkYWb28oZK4kCpUgiY2ctb0jEthb29PbZu3QqdTsebdIjMhIGSiMjC1HF2wHSJ79ueEeyFOjIf+DGnmjVrYtu2bYiPj8fEiRPNXQ5RucNASURkgQa0ViO0s6eRo9zbi9ne+Rb6t7atvZOP4ufnh8WLF2Pp0qVYs2aNucshKlcYKImILNTYQA/M7u0Ne5XC4D2VSoUAe5US3gVnsSHsTezbt0+mKi3LqFGjMGLECLz77rs4duyYucshKjcEURTlvjqWiIiMkJFTgLDIRMSlZUGpEJ54Crz4dX93V8zs5Y0aVezQvXt3xMfH48iRI2jcuLEJKzePwsJCtG/fHhkZGThx4gSqV69u7pKIbB4DJRGRlUi9nosN8RrEpGRCk12A+795C7jXtDzQ0w2DfdUPnOa+efMm2rZti9u3b+Po0aN49tlnTV67qV29ehUtW7aEh4cH9u7dCzs7O3OXRGTTGCiJiKxQfqEWl7PzUaTVw06lQD0XxyfegHP58mX4+PjA3d0d+/btQ8WKFU1YrXn8/vvvCAwMxKhRo7B48WJzl0Nk0xgoiYjKiaNHjyIwMBC9evXChg0bIAhy3xxufsuXL8fo0aOxZs0avP322+Yuh8hm8VAOEVE54evrix9++AGbNm3C9OnTzV2OSYwaNQrDhw/Hu+++i4SEBHOXQ2SzuEJJRFTOzJo1C2FhYVi/fj0GDRpk7nJkV1hYiHbt2uHKlSs8pEMkEwZKIqJyRhRFvPPOO9i4cSP27duHl19+2dwlye6vv/5Cq1at4Onpib1796JChQqPfJ+he1OJ6B4GSiKicqioqAidO3fGuXPnEB8fj4YNG5q7JNn9/vvvaN++PUaPHo1FixaV/P8lp+eTM6HJecTpeWcHBDZywyAfNTyq295d6ERSYKAkIiqncnJy4OvrC4VCgSNHjqBatWrmLkl2y5Ytw5gxY7BmzRp0DO5X5v6etnyNJVFZMFASEZVjqamp8PX1RdOmTbFr1y6b79coiiJGjBiBbaf/husrY6DHk4Pkw5QKASqFgOnBXhhQDq6zJCotnvImIirHPDw8EBkZiUOHDmH06NGw9TUGQRDQpN8kVA0agyKdaFCYBACdXkShVo+p2xOxJCZVpiqJrA8DJRFRORcQEIDVq1fju+++w9y5c81djqwiEjRYGHMJAIzuwzl/dwo2J2ikKIvI6vHoGhERYciQIUhNTcXUqVPRsGFD9O3b19wlSS4jpwDTopIkHfPTqCT4NXTlnkoq97hCSUREAIDp06djwIABGDJkCI4dO2buciQXFpkIrYGPuJ9GqxcRFpko6ZhE1oiBkoiIANx7BLxmzRo0b94cwcHB0Ghs53Fu6vVcxKVlGbxn8ml0ehFxaVlIy8yVdFwia8NASUREJSpWrIiffvoJlSpVQo8ePXDr1i1zlySJDfEaKBXy3F2uVAhYf9R2wjdRWTBQEhHRA9zc3LBjxw5oNBoMGDAAWq3W3CUZLSY5U/LVyWI6vYiYlExZxiayFgyURET0Hy+88AK2bt2K3bt3IyQkxNzlGCWvUAtNToGsc2iyC5BfaP3Bm6isGCiJiOiROnXqhGXLlmHJkiUPXFVobdKz8yF3d00RwOXsfJlnIbJcbBtERESPNWLECKSkpCAkJAQNGjRAjx49zF2SwYq0epuah8gScYWSiIieaPbs2QgODsaAAQNw5swZc5djMDuVaX7UmWoeIkvE3/1ERPRESqUS69evR6NGjdCjRw9cvXrV3CUZpJ6LI+Q53/3/hH/nISqvGCiJiOipHB0d8csvvwAAgoODkZ9vHfsF7969i992REFV+I+s86hdHOBoz11kVH4xUBIRUanUrFkTv/76K5KTkzF48GDo9U/eM5hfqEXS1Zs4pbmBpKs3TXoKOi0tDVOnTkWdOnXQp08fVPhfCgSZjuYoFQICPd1kGZvIWgiiKMp9+I2IiGzIjh07EBwcjEmTJmHu3LkPvJZ6PRcb4jWISc6EJqfggQgnAFA7OyCwkRsG+ajhUd1J0rru3LmD7du3Y9WqVYiJicEzzzyDIUOGYPjw4ahUvT6CFsZKOt/99oYEwN1N2s+HyJowUBIRkcEWLVqE8ePHY+XKlRgxYgQycgoQFpmIuLQsKBXCE5uIF7/u7+6Kmb28UcfZwahakpKS8O2332LdunXIyclBQEAARowYgT59+qBSpUol7xuyOh6HL2VL2uBcqRDg18AF64b5SDYmkTVioCQiIoOJoohx48Zh+fLlCFu9A5vT9NDqRYPCmlIhQKUQMD3YCwNaqw2aPz8/H1u2bMG3336LI0eO4Nlnn8Xbb7+N4cOHw9PT85Efk5FTgE4LDqJQwvY+9ioF9oa0MzoUE1k7BkoiIioTrVaLNsPD8b8abYweK7SzJ8YGejz1fSdOnMCqVauwceNG5ObmIigoCCNGjEBwcDDs7Oye+vERCRpM3Z5odL3F5vT2Rn8DwzCRLeKRNCIiKpOtp65KEiYBYP7uFDxb2f6R4ezmzZvYuHEjvv32W5w6dQo1a9bE+++/j2HDhqFevXoGzTOgtRpZeYWYvzvF6Jond27EMEn0L65QEhGRweR+fCyKIo4cOYJvv/0WW7ZswZ07d9C9e3eMGDECXbt2hUpl3HpIRIIG06KSyvyYfkawF8Mk0X0YKImIyGByHXBpVacK2tw5jm+//Rbnz59HvXr1MHz4cLz99tuoVauWZHMBMOtBIiJbw0BJREQGSb2eK2sLnsw149AjoBVGjBiBjh07QqGQt2VySaujlExosh/R6sjFAYGebhjsq2ZrIKLHYKAkIiKDhEclYV18uqSrk8UEiHi9WXXM7d9a8rFLI79Qi8vZ+SjS6mGnUqCeiyNvwCEqBf4pISIig8QkZ8oSJgFAhID4jDxZxi4NR3sVvGpWNdv8RNaKVy8SEVGp5RVqockpkHUOTXaBSa9pJCLjMVASEVGppWfny3Qj9v8TAVzOzpd5FiKSEgMlERGVWpGEbYIsYR4ikgYDJRERlZqdyjQ/Nkw1DxFJg39iiYio1Oq5OEKQeQ7h33mIyHowUBIRUak52quglrmpt9rFga16iKwMAyURERkksJEblAp51imVCgGBnm6yjE1E8mGgJCIigwzyUcvWh1KnFzHYl3dkE1kbBkoiIjKIR3Un+Lu7Sr5KqVQI8Hd35fWGRFaIgZKIiAw2s5c3VBIHSpVCwMxe3pKOSUSmwUBJREQGq+PsgOnBXpKOOSPYC3VkPvBDRPJgoCQiojIZ0FqN0M6ekow1uXMj9G/NvZNE1koQRVHuW7SIiMiGRSRoMC0qCVq9aNBhHaVCgEohYEawF8MkkZVjoCQiIqNl5BQgLDIRcWlZUCqEJwbL4tf93V0xs5c3H3MT2QAGSiIikkzq9VxsiNcgJiUTmuwC3P8DRsC9puWBnm4Y7KvmaW4iG8JASUREssgv1OJydj6KtHrYqRSo5+LIG3CIbBQDJREREREZhae8iYiIiMgoDJREREREZBQGSiIiIiIyCgMlERERERmFgZKIiIiIjMJASURERERGYaAkIiIiIqMwUBIRERGRURgoiYiIiMgoDJREREREZBQGSiIiIiIyCgMlERERERmFgZKIiIiIjMJASURERERGYaAkIiIiIqMwUBIRERGRURgoiYiIiMgoDJREREREZBQGSiIiIiIyCgMlERERERmFgZKIiIiIjMJASURERERGYaAkIiIiIqMwUBIRERGRURgoiYiIiMgoDJREREREZBQGSiIiIiIyCgMlERERERmFgZKIiIiIjMJASURERERGYaAkIiIiIqMwUBIRERGRURgoiYiIiMgoDJREREREZBQGSiIiIiIyCgMlERERERmFgZKIiIiIjPJ/H8Eshy5ZaGoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = datasetLoader.loadGraphDataset(datasetName)               # TODO: adjs matrix is not compatible with GraphConv. Needs to be converted to edge_index (see RE_PGE datasets/utils)\n",
    "\n",
    "# TODO: Color different classes? Problem: BA2Motif Graph datasets have no node labels?!\n",
    "g = torch_geometric.utils.to_networkx(train_dataset[0], to_undirected=True)\n",
    "nx.draw(g)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, True)\n",
    "test_loader = DataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop GraphGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3470 graphs with batch size 64\n",
      "\n",
      "------------------ EPOCH 1 -------------------\n",
      "average training loss: 0.6821305266374813, training acc: 0.5423631072044373\n",
      "validation loss: 0.6578071199803858, validation acc: 0.5714285969734192\n",
      "\n",
      "------------------ EPOCH 2 -------------------\n",
      "average training loss: 0.646632255738338, training acc: 0.6086455583572388\n",
      "validation loss: 0.6276274372905081, validation acc: 0.6658986210823059\n",
      "\n",
      "------------------ EPOCH 3 -------------------\n",
      "average training loss: 0.6191219399401365, training acc: 0.6648414731025696\n",
      "validation loss: 0.6054462911346541, validation acc: 0.6889401078224182\n",
      "\n",
      "------------------ EPOCH 4 -------------------\n",
      "average training loss: 0.5988462392809755, training acc: 0.6974063515663147\n",
      "validation loss: 0.5948159991321476, validation acc: 0.7073732614517212\n",
      "\n",
      "------------------ EPOCH 5 -------------------\n",
      "average training loss: 0.5830896740344484, training acc: 0.7048991322517395\n",
      "validation loss: 0.5958946836159525, validation acc: 0.7188940048217773\n",
      "\n",
      "------------------ EPOCH 6 -------------------\n",
      "average training loss: 0.5810033657021756, training acc: 0.7051873207092285\n",
      "validation loss: 0.5780633600076772, validation acc: 0.7004608511924744\n",
      "\n",
      "------------------ EPOCH 7 -------------------\n",
      "average training loss: 0.5733485553724965, training acc: 0.7118155360221863\n",
      "validation loss: 0.5754226381602925, validation acc: 0.7142857313156128\n",
      "\n",
      "------------------ EPOCH 8 -------------------\n",
      "average training loss: 0.5692058944221189, training acc: 0.7083573341369629\n",
      "validation loss: 0.5762412712870655, validation acc: 0.6751152276992798\n",
      "\n",
      "------------------ EPOCH 9 -------------------\n",
      "average training loss: 0.5638389738217554, training acc: 0.7221902012825012\n",
      "validation loss: 0.570658024280302, validation acc: 0.7165898680686951\n",
      "\n",
      "------------------ EPOCH 10 -------------------\n",
      "average training loss: 0.5604584082918139, training acc: 0.7210374474525452\n",
      "validation loss: 0.572996712774725, validation acc: 0.725806474685669\n",
      "\n",
      "------------------ EPOCH 11 -------------------\n",
      "average training loss: 0.5558766746211807, training acc: 0.7247838377952576\n",
      "validation loss: 0.5618470583093881, validation acc: 0.7211981415748596\n",
      "\n",
      "------------------ EPOCH 12 -------------------\n",
      "average training loss: 0.5531130182640009, training acc: 0.7239193320274353\n",
      "validation loss: 0.5635798565253684, validation acc: 0.7304147481918335\n",
      "\n",
      "------------------ EPOCH 13 -------------------\n",
      "average training loss: 0.5467968123962281, training acc: 0.7348703145980835\n",
      "validation loss: 0.5561607002113272, validation acc: 0.7304147481918335\n",
      "\n",
      "------------------ EPOCH 14 -------------------\n",
      "average training loss: 0.5440213594725222, training acc: 0.7328530550003052\n",
      "validation loss: 0.5480513528744746, validation acc: 0.7211981415748596\n",
      "\n",
      "------------------ EPOCH 15 -------------------\n",
      "average training loss: 0.544118133642488, training acc: 0.7337175607681274\n",
      "validation loss: 0.548905426730758, validation acc: 0.7396313548088074\n",
      "\n",
      "------------------ EPOCH 16 -------------------\n",
      "average training loss: 0.5309462517414038, training acc: 0.7368876338005066\n",
      "validation loss: 0.5340932942755211, validation acc: 0.7419354915618896\n",
      "\n",
      "------------------ EPOCH 17 -------------------\n",
      "average training loss: 0.5287502741779305, training acc: 0.7475504279136658\n",
      "validation loss: 0.5277526384125107, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 18 -------------------\n",
      "average training loss: 0.5216399931083151, training acc: 0.7484149932861328\n",
      "validation loss: 0.5253647922920192, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 19 -------------------\n",
      "average training loss: 0.5261423434922606, training acc: 0.7435158491134644\n",
      "validation loss: 0.5431360171137867, validation acc: 0.7465437650680542\n",
      "\n",
      "------------------ EPOCH 20 -------------------\n",
      "average training loss: 0.518721243404174, training acc: 0.7443804144859314\n",
      "validation loss: 0.5169222766902589, validation acc: 0.7442396283149719\n",
      "\n",
      "------------------ EPOCH 21 -------------------\n",
      "average training loss: 0.5190317936864298, training acc: 0.7469740509986877\n",
      "validation loss: 0.5201505245426283, validation acc: 0.725806474685669\n",
      "\n",
      "------------------ EPOCH 22 -------------------\n",
      "average training loss: 0.5208505116896945, training acc: 0.7495677471160889\n",
      "validation loss: 0.5142587390363491, validation acc: 0.7396313548088074\n",
      "\n",
      "------------------ EPOCH 23 -------------------\n",
      "average training loss: 0.5097658650847608, training acc: 0.7576369047164917\n",
      "validation loss: 0.5078777989484198, validation acc: 0.7465437650680542\n",
      "\n",
      "------------------ EPOCH 24 -------------------\n",
      "average training loss: 0.5158924554713521, training acc: 0.7510086297988892\n",
      "validation loss: 0.5093252249577078, validation acc: 0.7465437650680542\n",
      "\n",
      "------------------ EPOCH 25 -------------------\n",
      "average training loss: 0.5063452884683691, training acc: 0.7570605278015137\n",
      "validation loss: 0.5322676894302192, validation acc: 0.7488479018211365\n",
      "\n",
      "------------------ EPOCH 26 -------------------\n",
      "average training loss: 0.5098650509754588, training acc: 0.7507204413414001\n",
      "validation loss: 0.5096783867354766, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 27 -------------------\n",
      "average training loss: 0.5063200584749667, training acc: 0.7619596719741821\n",
      "validation loss: 0.4977845384777966, validation acc: 0.7511520981788635\n",
      "\n",
      "------------------ EPOCH 28 -------------------\n",
      "average training loss: 0.5076039696632957, training acc: 0.7605187296867371\n",
      "validation loss: 0.5049469995608528, validation acc: 0.7465437650680542\n",
      "\n",
      "------------------ EPOCH 29 -------------------\n",
      "average training loss: 0.5072526527756572, training acc: 0.7524495720863342\n",
      "validation loss: 0.49590542541670907, validation acc: 0.7511520981788635\n",
      "\n",
      "------------------ EPOCH 30 -------------------\n",
      "average training loss: 0.502497751551334, training acc: 0.7579250931739807\n",
      "validation loss: 0.49391810836330535, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 31 -------------------\n",
      "average training loss: 0.5071240379762237, training acc: 0.7579250931739807\n",
      "validation loss: 0.49342241814608945, validation acc: 0.7534562349319458\n",
      "\n",
      "------------------ EPOCH 32 -------------------\n",
      "average training loss: 0.5023629139411003, training acc: 0.7622478604316711\n",
      "validation loss: 0.48900963798646, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 33 -------------------\n",
      "average training loss: 0.5042018619325731, training acc: 0.7579250931739807\n",
      "validation loss: 0.5010648075886036, validation acc: 0.764976978302002\n",
      "\n",
      "------------------ EPOCH 34 -------------------\n",
      "average training loss: 0.49860541202149405, training acc: 0.7616714835166931\n",
      "validation loss: 0.5123992449676935, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 35 -------------------\n",
      "average training loss: 0.5003239472764369, training acc: 0.7608069181442261\n",
      "validation loss: 0.5025023348320464, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 36 -------------------\n",
      "average training loss: 0.4939867181461895, training acc: 0.759942352771759\n",
      "validation loss: 0.48420520696771857, validation acc: 0.7788018584251404\n",
      "\n",
      "------------------ EPOCH 37 -------------------\n",
      "average training loss: 0.5028392097791952, training acc: 0.7605187296867371\n",
      "validation loss: 0.48990884176047717, validation acc: 0.7580645084381104\n",
      "\n",
      "------------------ EPOCH 38 -------------------\n",
      "average training loss: 0.49513838067865507, training acc: 0.7651296854019165\n",
      "validation loss: 0.4856658959718344, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 39 -------------------\n",
      "average training loss: 0.4937779072038722, training acc: 0.7642651200294495\n",
      "validation loss: 0.5076007334867381, validation acc: 0.7557603716850281\n",
      "\n",
      "------------------ EPOCH 40 -------------------\n",
      "average training loss: 0.49258224435086206, training acc: 0.7691642642021179\n",
      "validation loss: 0.4862030291337571, validation acc: 0.7788018584251404\n",
      "\n",
      "------------------ EPOCH 41 -------------------\n",
      "average training loss: 0.49390183427835405, training acc: 0.7654178738594055\n",
      "validation loss: 0.4830991153343482, validation acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 42 -------------------\n",
      "average training loss: 0.49139191611355937, training acc: 0.769740641117096\n",
      "validation loss: 0.4831393855508022, validation acc: 0.7811059951782227\n",
      "\n",
      "------------------ EPOCH 43 -------------------\n",
      "average training loss: 0.4825615322040206, training acc: 0.770605206489563\n",
      "validation loss: 0.4832499646646087, validation acc: 0.7718893885612488\n",
      "\n",
      "------------------ EPOCH 44 -------------------\n",
      "average training loss: 0.49389643308408665, training acc: 0.7622478604316711\n",
      "validation loss: 0.48223950428896784, validation acc: 0.7811059951782227\n",
      "\n",
      "------------------ EPOCH 45 -------------------\n",
      "average training loss: 0.4875154234490408, training acc: 0.7720460891723633\n",
      "validation loss: 0.48255085615518456, validation acc: 0.7718893885612488\n",
      "\n",
      "------------------ EPOCH 46 -------------------\n",
      "average training loss: 0.4869162923149142, training acc: 0.7691642642021179\n",
      "validation loss: 0.48326676301143134, validation acc: 0.7718893885612488\n",
      "\n",
      "------------------ EPOCH 47 -------------------\n",
      "average training loss: 0.4846747624083967, training acc: 0.770605206489563\n",
      "validation loss: 0.478126995711832, validation acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 48 -------------------\n",
      "average training loss: 0.49035501225881, training acc: 0.7628241777420044\n",
      "validation loss: 0.479690032345908, validation acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 49 -------------------\n",
      "average training loss: 0.48642263567069766, training acc: 0.7734870314598083\n",
      "validation loss: 0.4989598236875051, validation acc: 0.7557603716850281\n",
      "\n",
      "------------------ EPOCH 50 -------------------\n",
      "average training loss: 0.4912811738441588, training acc: 0.7749279737472534\n",
      "validation loss: 0.48756984796392205, validation acc: 0.764976978302002\n",
      "\n",
      "------------------ EPOCH 51 -------------------\n",
      "average training loss: 0.486114000106064, training acc: 0.7740634083747864\n",
      "validation loss: 0.480468234982908, validation acc: 0.7695852518081665\n",
      "\n",
      "------------------ EPOCH 52 -------------------\n",
      "average training loss: 0.4818816412594545, training acc: 0.7775216102600098\n",
      "validation loss: 0.4780091893288397, validation acc: 0.7718893885612488\n",
      "\n",
      "------------------ EPOCH 53 -------------------\n",
      "average training loss: 0.48150842085008316, training acc: 0.7740634083747864\n",
      "validation loss: 0.4714155242465059, validation acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 54 -------------------\n",
      "average training loss: 0.4853558268086711, training acc: 0.771181583404541\n",
      "validation loss: 0.4777908283993945, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 55 -------------------\n",
      "average training loss: 0.4788775516002941, training acc: 0.7792507410049438\n",
      "validation loss: 0.4740477502346039, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 56 -------------------\n",
      "average training loss: 0.4818476467379919, training acc: 0.7740634083747864\n",
      "validation loss: 0.47024611393976873, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 57 -------------------\n",
      "average training loss: 0.47953720085902585, training acc: 0.7806916236877441\n",
      "validation loss: 0.47104263236995114, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 58 -------------------\n",
      "average training loss: 0.47957648918333246, training acc: 0.7769452333450317\n",
      "validation loss: 0.47368487152635774, validation acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 59 -------------------\n",
      "average training loss: 0.48029517972847224, training acc: 0.7755043506622314\n",
      "validation loss: 0.46863271495164266, validation acc: 0.7949308753013611\n",
      "\n",
      "------------------ EPOCH 60 -------------------\n",
      "average training loss: 0.479409770439956, training acc: 0.7775216102600098\n",
      "validation loss: 0.47401050996670524, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 61 -------------------\n",
      "average training loss: 0.47822898511240736, training acc: 0.7850143909454346\n",
      "validation loss: 0.4765944074375838, validation acc: 0.7903226017951965\n",
      "\n",
      "------------------ EPOCH 62 -------------------\n",
      "average training loss: 0.4820651172560986, training acc: 0.7740634083747864\n",
      "validation loss: 0.4710264693482131, validation acc: 0.7949308753013611\n",
      "\n",
      "------------------ EPOCH 63 -------------------\n",
      "average training loss: 0.4758905617235717, training acc: 0.7778097987174988\n",
      "validation loss: 0.4727129537938377, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 64 -------------------\n",
      "average training loss: 0.4750432944435208, training acc: 0.7855907678604126\n",
      "validation loss: 0.4661459400906541, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 65 -------------------\n",
      "average training loss: 0.4750703936007937, training acc: 0.7778097987174988\n",
      "validation loss: 0.47098973462109195, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 66 -------------------\n",
      "average training loss: 0.47684602060647796, training acc: 0.7772334218025208\n",
      "validation loss: 0.4730149642113716, validation acc: 0.7764977216720581\n",
      "\n",
      "------------------ EPOCH 67 -------------------\n",
      "average training loss: 0.47423410687048084, training acc: 0.7755043506622314\n",
      "validation loss: 0.4690232125844824, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 68 -------------------\n",
      "average training loss: 0.47564985022077644, training acc: 0.7749279737472534\n",
      "validation loss: 0.4899139457858653, validation acc: 0.7603686451911926\n",
      "\n",
      "------------------ EPOCH 69 -------------------\n",
      "average training loss: 0.4761427186236258, training acc: 0.7757924795150757\n",
      "validation loss: 0.4676140861302477, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 70 -------------------\n",
      "average training loss: 0.46939530176800337, training acc: 0.7815561890602112\n",
      "validation loss: 0.46812235375153854, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 71 -------------------\n",
      "average training loss: 0.4712043855994167, training acc: 0.7838616967201233\n",
      "validation loss: 0.47544704466920845, validation acc: 0.774193525314331\n",
      "\n",
      "------------------ EPOCH 72 -------------------\n",
      "average training loss: 0.4706720181088626, training acc: 0.7832853198051453\n",
      "validation loss: 0.4630813653567969, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 73 -------------------\n",
      "average training loss: 0.4681400069242252, training acc: 0.7812680006027222\n",
      "validation loss: 0.4650214071372687, validation acc: 0.7949308753013611\n",
      "\n",
      "------------------ EPOCH 74 -------------------\n",
      "average training loss: 0.4658316271449372, training acc: 0.7855907678604126\n",
      "validation loss: 0.46168914931710414, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 75 -------------------\n",
      "average training loss: 0.4720244443725784, training acc: 0.7792507410049438\n",
      "validation loss: 0.4728184468735198, validation acc: 0.7811059951782227\n",
      "\n",
      "------------------ EPOCH 76 -------------------\n",
      "average training loss: 0.4675769635854606, training acc: 0.7841498851776123\n",
      "validation loss: 0.4599132081879998, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 77 -------------------\n",
      "average training loss: 0.47084471784338827, training acc: 0.7821325659751892\n",
      "validation loss: 0.46002101335108003, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 78 -------------------\n",
      "average training loss: 0.4672592929185983, training acc: 0.7798271179199219\n",
      "validation loss: 0.46139418639345653, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 79 -------------------\n",
      "average training loss: 0.4651023931736905, training acc: 0.7867435216903687\n",
      "validation loss: 0.46607331279236053, validation acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 80 -------------------\n",
      "average training loss: 0.4681318911420509, training acc: 0.7861671447753906\n",
      "validation loss: 0.45962653868758735, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 81 -------------------\n",
      "average training loss: 0.4716423027110031, training acc: 0.7769452333450317\n",
      "validation loss: 0.45983499549500956, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 82 -------------------\n",
      "average training loss: 0.46169192691357747, training acc: 0.7881844639778137\n",
      "validation loss: 0.4581338509161901, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 83 -------------------\n",
      "average training loss: 0.45817423134784535, training acc: 0.790489912033081\n",
      "validation loss: 0.4691931204312408, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 84 -------------------\n",
      "average training loss: 0.46697204216069377, training acc: 0.7824207544326782\n",
      "validation loss: 0.46649891618759404, validation acc: 0.7926267385482788\n",
      "\n",
      "------------------ EPOCH 85 -------------------\n",
      "average training loss: 0.4627166775530285, training acc: 0.7850143909454346\n",
      "validation loss: 0.49562003618011824, validation acc: 0.7488479018211365\n",
      "\n",
      "------------------ EPOCH 86 -------------------\n",
      "average training loss: 0.46716268830409313, training acc: 0.7841498851776123\n",
      "validation loss: 0.45986304607259515, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 87 -------------------\n",
      "average training loss: 0.46615218358699456, training acc: 0.7858789563179016\n",
      "validation loss: 0.45874339767864775, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 88 -------------------\n",
      "average training loss: 0.45771962989991266, training acc: 0.7841498851776123\n",
      "validation loss: 0.4688197672367096, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 89 -------------------\n",
      "average training loss: 0.4589458722717824, training acc: 0.7919308543205261\n",
      "validation loss: 0.4742225750525426, validation acc: 0.774193525314331\n",
      "\n",
      "------------------ EPOCH 90 -------------------\n",
      "average training loss: 0.4627202850597393, training acc: 0.7873198986053467\n",
      "validation loss: 0.4625656364425536, validation acc: 0.7903226017951965\n",
      "\n",
      "------------------ EPOCH 91 -------------------\n",
      "average training loss: 0.46595088458198636, training acc: 0.7878962755203247\n",
      "validation loss: 0.4617930028570412, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 92 -------------------\n",
      "average training loss: 0.4575618672096077, training acc: 0.7907781004905701\n",
      "validation loss: 0.46718736233249786, validation acc: 0.7880184054374695\n",
      "\n",
      "------------------ EPOCH 93 -------------------\n",
      "average training loss: 0.4621694263360686, training acc: 0.7818443775177002\n",
      "validation loss: 0.4547956226058819, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 94 -------------------\n",
      "average training loss: 0.46426150898424967, training acc: 0.7881844639778137\n",
      "validation loss: 0.4629883727719707, validation acc: 0.7834101319313049\n",
      "\n",
      "------------------ EPOCH 95 -------------------\n",
      "average training loss: 0.4634762596500023, training acc: 0.7876080870628357\n",
      "validation loss: 0.45224922002735224, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 96 -------------------\n",
      "average training loss: 0.45750786991902664, training acc: 0.7858789563179016\n",
      "validation loss: 0.4559015120778765, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 97 -------------------\n",
      "average training loss: 0.4576218110683672, training acc: 0.7853025794029236\n",
      "validation loss: 0.4522064616603236, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 98 -------------------\n",
      "average training loss: 0.4615362034922718, training acc: 0.7853025794029236\n",
      "validation loss: 0.453136652158702, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 99 -------------------\n",
      "average training loss: 0.45309332423663623, training acc: 0.7878962755203247\n",
      "validation loss: 0.45276017205506425, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 100 -------------------\n",
      "average training loss: 0.4543802797279028, training acc: 0.7948126792907715\n",
      "validation loss: 0.45453847141309817, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 101 -------------------\n",
      "average training loss: 0.46459247966321127, training acc: 0.7818443775177002\n",
      "validation loss: 0.45293559566620856, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 102 -------------------\n",
      "average training loss: 0.4572586293179295, training acc: 0.7881844639778137\n",
      "validation loss: 0.46627952659734384, validation acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 103 -------------------\n",
      "average training loss: 0.45717043447219674, training acc: 0.789913535118103\n",
      "validation loss: 0.4509243322407595, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 104 -------------------\n",
      "average training loss: 0.4586082150681905, training acc: 0.7876080870628357\n",
      "validation loss: 0.45678834417997966, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 105 -------------------\n",
      "average training loss: 0.45888456406785705, training acc: 0.7850143909454346\n",
      "validation loss: 0.4525683273642843, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 106 -------------------\n",
      "average training loss: 0.45835384188021294, training acc: 0.7936599254608154\n",
      "validation loss: 0.46419382205207227, validation acc: 0.7903226017951965\n",
      "\n",
      "------------------ EPOCH 107 -------------------\n",
      "average training loss: 0.4535333030162009, training acc: 0.7922190427780151\n",
      "validation loss: 0.44954204875203324, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 108 -------------------\n",
      "average training loss: 0.45992382876467636, training acc: 0.7925072312355042\n",
      "validation loss: 0.44956383562307756, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 109 -------------------\n",
      "average training loss: 0.45692899550072397, training acc: 0.7968299984931946\n",
      "validation loss: 0.45029688993906647, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 110 -------------------\n",
      "average training loss: 0.4524199478392642, training acc: 0.7876080870628357\n",
      "validation loss: 0.4598933814033385, validation acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 111 -------------------\n",
      "average training loss: 0.4511814368818954, training acc: 0.7922190427780151\n",
      "validation loss: 0.44770987737013995, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 112 -------------------\n",
      "average training loss: 0.4557874961098608, training acc: 0.788472592830658\n",
      "validation loss: 0.4578860836094975, validation acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 113 -------------------\n",
      "average training loss: 0.4566423432971284, training acc: 0.788760781288147\n",
      "validation loss: 0.4489332415541196, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 114 -------------------\n",
      "average training loss: 0.4573786926887908, training acc: 0.7927953600883484\n",
      "validation loss: 0.4507499121575861, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 115 -------------------\n",
      "average training loss: 0.4518871356156099, training acc: 0.7916426658630371\n",
      "validation loss: 0.4471027653338173, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 116 -------------------\n",
      "average training loss: 0.4462097549644602, training acc: 0.7933717370033264\n",
      "validation loss: 0.4474766060778622, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 117 -------------------\n",
      "average training loss: 0.45849590420035874, training acc: 0.7867435216903687\n",
      "validation loss: 0.4463787766920257, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 118 -------------------\n",
      "average training loss: 0.457656051617878, training acc: 0.7925072312355042\n",
      "validation loss: 0.44648556321996696, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 119 -------------------\n",
      "average training loss: 0.4536196265165675, training acc: 0.789048969745636\n",
      "validation loss: 0.44448711424379306, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 120 -------------------\n",
      "average training loss: 0.4497459673057028, training acc: 0.7959654331207275\n",
      "validation loss: 0.4443862993046985, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 121 -------------------\n",
      "average training loss: 0.4446918991182311, training acc: 0.7939481139183044\n",
      "validation loss: 0.4432950261551114, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 122 -------------------\n",
      "average training loss: 0.45003816040517275, training acc: 0.7916426658630371\n",
      "validation loss: 0.4498420242340334, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 123 -------------------\n",
      "average training loss: 0.44947685961764555, training acc: 0.7997118234634399\n",
      "validation loss: 0.45079130181519117, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 124 -------------------\n",
      "average training loss: 0.44898757953465157, training acc: 0.7994236350059509\n",
      "validation loss: 0.44779277520795024, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 125 -------------------\n",
      "average training loss: 0.4411631911563598, training acc: 0.801152765750885\n",
      "validation loss: 0.45330874546332295, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 126 -------------------\n",
      "average training loss: 0.451970987567297, training acc: 0.7933717370033264\n",
      "validation loss: 0.44471223508158036, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 127 -------------------\n",
      "average training loss: 0.44629505257785146, training acc: 0.7939481139183044\n",
      "validation loss: 0.4541816446363651, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 128 -------------------\n",
      "average training loss: 0.45014884420361917, training acc: 0.7933717370033264\n",
      "validation loss: 0.4428922772956883, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 129 -------------------\n",
      "average training loss: 0.4444087359850276, training acc: 0.7959654331207275\n",
      "validation loss: 0.45208537853258546, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 130 -------------------\n",
      "average training loss: 0.4482527579629112, training acc: 0.7988472580909729\n",
      "validation loss: 0.4472193782505352, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 131 -------------------\n",
      "average training loss: 0.4463808746262311, training acc: 0.7913544774055481\n",
      "validation loss: 0.4510568817090329, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 132 -------------------\n",
      "average training loss: 0.44776877632058665, training acc: 0.7930835485458374\n",
      "validation loss: 0.44565328227759504, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 133 -------------------\n",
      "average training loss: 0.4521193045875868, training acc: 0.7965418100357056\n",
      "validation loss: 0.4493776664206509, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 134 -------------------\n",
      "average training loss: 0.44507564321718573, training acc: 0.7962536215782166\n",
      "validation loss: 0.4441982907358952, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 135 -------------------\n",
      "average training loss: 0.45213528943680203, training acc: 0.7939481139183044\n",
      "validation loss: 0.4441394403508182, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 136 -------------------\n",
      "average training loss: 0.4422519945273825, training acc: 0.7997118234634399\n",
      "validation loss: 0.4445484476979427, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 137 -------------------\n",
      "average training loss: 0.4462635037191319, training acc: 0.7968299984931946\n",
      "validation loss: 0.44671949153671614, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 138 -------------------\n",
      "average training loss: 0.44170371835101235, training acc: 0.800000011920929\n",
      "validation loss: 0.44410197635949483, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 139 -------------------\n",
      "average training loss: 0.4488972132762502, training acc: 0.7910662889480591\n",
      "validation loss: 0.43859511613845825, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 140 -------------------\n",
      "average training loss: 0.446293966124312, training acc: 0.7942363023757935\n",
      "validation loss: 0.45090513460097775, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 141 -------------------\n",
      "average training loss: 0.44184498773184566, training acc: 0.7985590696334839\n",
      "validation loss: 0.4461729411155947, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 142 -------------------\n",
      "average training loss: 0.4367950208936026, training acc: 0.8054755330085754\n",
      "validation loss: 0.43730475001620805, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 143 -------------------\n",
      "average training loss: 0.4363169130571294, training acc: 0.8028818368911743\n",
      "validation loss: 0.4413122897323925, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 144 -------------------\n",
      "average training loss: 0.44161252152679287, training acc: 0.8023054599761963\n",
      "validation loss: 0.4569089131146532, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 145 -------------------\n",
      "average training loss: 0.4376003363634049, training acc: 0.7985590696334839\n",
      "validation loss: 0.442022661184935, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 146 -------------------\n",
      "average training loss: 0.4391948988183431, training acc: 0.8014408946037292\n",
      "validation loss: 0.43834416080729754, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 147 -------------------\n",
      "average training loss: 0.44579964371167274, training acc: 0.7988472580909729\n",
      "validation loss: 0.4373853114618134, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 148 -------------------\n",
      "average training loss: 0.4442587558577315, training acc: 0.8028818368911743\n",
      "validation loss: 0.44391185292450513, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 149 -------------------\n",
      "average training loss: 0.4370839268570331, training acc: 0.8014408946037292\n",
      "validation loss: 0.44673381354402286, validation acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 150 -------------------\n",
      "average training loss: 0.4417732356432879, training acc: 0.7959654331207275\n",
      "validation loss: 0.4417927644219816, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 151 -------------------\n",
      "average training loss: 0.44111997954096505, training acc: 0.8043227791786194\n",
      "validation loss: 0.4425369039658577, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 152 -------------------\n",
      "average training loss: 0.4437470347118653, training acc: 0.7982708811759949\n",
      "validation loss: 0.438864953232251, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 153 -------------------\n",
      "average training loss: 0.43671293377189196, training acc: 0.8089337348937988\n",
      "validation loss: 0.43522704416705715, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 154 -------------------\n",
      "average training loss: 0.4344060457405508, training acc: 0.800576388835907\n",
      "validation loss: 0.4390396755961229, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 155 -------------------\n",
      "average training loss: 0.44606309988313175, training acc: 0.800576388835907\n",
      "validation loss: 0.4355678782210372, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 156 -------------------\n",
      "average training loss: 0.43609997767536374, training acc: 0.8040345907211304\n",
      "validation loss: 0.43885760455636935, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 157 -------------------\n",
      "average training loss: 0.4373356008564017, training acc: 0.7939481139183044\n",
      "validation loss: 0.43576288951157427, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 158 -------------------\n",
      "average training loss: 0.43535278879256345, training acc: 0.7968299984931946\n",
      "validation loss: 0.4385420597643347, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 159 -------------------\n",
      "average training loss: 0.4404302352958866, training acc: 0.8028818368911743\n",
      "validation loss: 0.43238198633567526, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 160 -------------------\n",
      "average training loss: 0.43826385596471834, training acc: 0.7997118234634399\n",
      "validation loss: 0.4363112549902657, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 161 -------------------\n",
      "average training loss: 0.441783529812046, training acc: 0.7979826927185059\n",
      "validation loss: 0.43736310461149785, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 162 -------------------\n",
      "average training loss: 0.44802207239079544, training acc: 0.7951008677482605\n",
      "validation loss: 0.43861601704276654, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 163 -------------------\n",
      "average training loss: 0.4354116700224643, training acc: 0.7997118234634399\n",
      "validation loss: 0.43851015727091497, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 164 -------------------\n",
      "average training loss: 0.4313533042624636, training acc: 0.800576388835907\n",
      "validation loss: 0.43685216878965705, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 165 -------------------\n",
      "average training loss: 0.4367301644612458, training acc: 0.8040345907211304\n",
      "validation loss: 0.4359883484752497, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 166 -------------------\n",
      "average training loss: 0.4387451921141457, training acc: 0.8028818368911743\n",
      "validation loss: 0.441309424039955, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 167 -------------------\n",
      "average training loss: 0.43714823241879686, training acc: 0.801152765750885\n",
      "validation loss: 0.43767676045817716, validation acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 168 -------------------\n",
      "average training loss: 0.43499801875191396, training acc: 0.8054755330085754\n",
      "validation loss: 0.4387642555797155, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 169 -------------------\n",
      "average training loss: 0.43471239760561015, training acc: 0.8083573579788208\n",
      "validation loss: 0.43369132088076684, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 170 -------------------\n",
      "average training loss: 0.44190720153129753, training acc: 0.801152765750885\n",
      "validation loss: 0.43727171750661964, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 171 -------------------\n",
      "average training loss: 0.4450223527827249, training acc: 0.7913544774055481\n",
      "validation loss: 0.4365928637267258, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 172 -------------------\n",
      "average training loss: 0.4336748516009933, training acc: 0.8066282272338867\n",
      "validation loss: 0.43889362979594465, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 173 -------------------\n",
      "average training loss: 0.43729332590137504, training acc: 0.8066282272338867\n",
      "validation loss: 0.43750579689504915, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 174 -------------------\n",
      "average training loss: 0.4387206969755871, training acc: 0.8025936484336853\n",
      "validation loss: 0.4323441949308193, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 175 -------------------\n",
      "average training loss: 0.4321325678990279, training acc: 0.8066282272338867\n",
      "validation loss: 0.4284362893225411, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 176 -------------------\n",
      "average training loss: 0.43056516600960615, training acc: 0.8040345907211304\n",
      "validation loss: 0.43917072272520463, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 177 -------------------\n",
      "average training loss: 0.43290570228862485, training acc: 0.8023054599761963\n",
      "validation loss: 0.43554487192685704, validation acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 178 -------------------\n",
      "average training loss: 0.4374120366161083, training acc: 0.7974063158035278\n",
      "validation loss: 0.43262708434311475, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 179 -------------------\n",
      "average training loss: 0.4327163839889878, training acc: 0.800576388835907\n",
      "validation loss: 0.44734876029502413, validation acc: 0.7949308753013611\n",
      "\n",
      "------------------ EPOCH 180 -------------------\n",
      "average training loss: 0.4279078767004205, training acc: 0.8060518503189087\n",
      "validation loss: 0.4368992439612815, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 181 -------------------\n",
      "average training loss: 0.4374540679049423, training acc: 0.800288200378418\n",
      "validation loss: 0.433941471686561, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 182 -------------------\n",
      "average training loss: 0.43442701843355164, training acc: 0.7971181273460388\n",
      "validation loss: 0.4306218452442626, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 183 -------------------\n",
      "average training loss: 0.4244908151949517, training acc: 0.8069164156913757\n",
      "validation loss: 0.43393188563909396, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 184 -------------------\n",
      "average training loss: 0.4335705577811865, training acc: 0.8020172715187073\n",
      "validation loss: 0.4306407886716078, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 185 -------------------\n",
      "average training loss: 0.42785001063037675, training acc: 0.8043227791786194\n",
      "validation loss: 0.43286271400166, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 186 -------------------\n",
      "average training loss: 0.4339515714205651, training acc: 0.8046109676361084\n",
      "validation loss: 0.43636363937008765, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 187 -------------------\n",
      "average training loss: 0.4332536801137567, training acc: 0.8051873445510864\n",
      "validation loss: 0.4331611105099252, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 188 -------------------\n",
      "average training loss: 0.43367241736104234, training acc: 0.8040345907211304\n",
      "validation loss: 0.4285957057904538, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 189 -------------------\n",
      "average training loss: 0.43184911167243717, training acc: 0.8017290830612183\n",
      "validation loss: 0.4349692293575832, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 190 -------------------\n",
      "average training loss: 0.4291767285862986, training acc: 0.8034582138061523\n",
      "validation loss: 0.4308897054964496, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 191 -------------------\n",
      "average training loss: 0.4270998159471781, training acc: 0.8086455464363098\n",
      "validation loss: 0.4294090184473222, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 192 -------------------\n",
      "average training loss: 0.42921356089864066, training acc: 0.8014408946037292\n",
      "validation loss: 0.43243361274767583, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 193 -------------------\n",
      "average training loss: 0.4297149279962699, training acc: 0.8014408946037292\n",
      "validation loss: 0.43154009764644957, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 194 -------------------\n",
      "average training loss: 0.4258198860571089, training acc: 0.8080691695213318\n",
      "validation loss: 0.42781717477855596, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 195 -------------------\n",
      "average training loss: 0.42487334414930095, training acc: 0.8126801252365112\n",
      "validation loss: 0.4309664113180978, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 196 -------------------\n",
      "average training loss: 0.42801635371848556, training acc: 0.801152765750885\n",
      "validation loss: 0.4370033296022547, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 197 -------------------\n",
      "average training loss: 0.426013258829584, training acc: 0.8066282272338867\n",
      "validation loss: 0.4288413683939639, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 198 -------------------\n",
      "average training loss: 0.43382764633863047, training acc: 0.8020172715187073\n",
      "validation loss: 0.4333498947631379, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 199 -------------------\n",
      "average training loss: 0.42709371444127747, training acc: 0.8063400387763977\n",
      "validation loss: 0.42884203503208773, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 200 -------------------\n",
      "average training loss: 0.4255894111625056, training acc: 0.8017290830612183\n",
      "validation loss: 0.42824983322125976, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 201 -------------------\n",
      "average training loss: 0.4268523951600539, training acc: 0.8048991560935974\n",
      "validation loss: 0.4294137287249763, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 202 -------------------\n",
      "average training loss: 0.428520428103741, training acc: 0.8051873445510864\n",
      "validation loss: 0.4345718537058149, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 203 -------------------\n",
      "average training loss: 0.42704749552248533, training acc: 0.8092219233512878\n",
      "validation loss: 0.4351527273380262, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 204 -------------------\n",
      "average training loss: 0.42834787595512547, training acc: 0.8089337348937988\n",
      "validation loss: 0.4323266361440931, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 205 -------------------\n",
      "average training loss: 0.4262819576675679, training acc: 0.8080691695213318\n",
      "validation loss: 0.43562886654506633, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 206 -------------------\n",
      "average training loss: 0.4317674273372727, training acc: 0.8046109676361084\n",
      "validation loss: 0.43217312520550144, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 207 -------------------\n",
      "average training loss: 0.43168577170509426, training acc: 0.8034582138061523\n",
      "validation loss: 0.4273503337587629, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 208 -------------------\n",
      "average training loss: 0.42979204417649197, training acc: 0.8025936484336853\n",
      "validation loss: 0.4318386217416157, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 209 -------------------\n",
      "average training loss: 0.42569328943315776, training acc: 0.8051873445510864\n",
      "validation loss: 0.4326634549874864, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 210 -------------------\n",
      "average training loss: 0.42089858388351087, training acc: 0.8123919367790222\n",
      "validation loss: 0.42940096921085763, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 211 -------------------\n",
      "average training loss: 0.4292027792858459, training acc: 0.8037464022636414\n",
      "validation loss: 0.43307153310643914, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 212 -------------------\n",
      "average training loss: 0.427546540615538, training acc: 0.8034582138061523\n",
      "validation loss: 0.4276702464450889, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 213 -------------------\n",
      "average training loss: 0.4222750570657274, training acc: 0.8121037483215332\n",
      "validation loss: 0.42622105509454755, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 214 -------------------\n",
      "average training loss: 0.4171154168909496, training acc: 0.8086455464363098\n",
      "validation loss: 0.4323832108403131, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 215 -------------------\n",
      "average training loss: 0.42749227573960935, training acc: 0.8048991560935974\n",
      "validation loss: 0.4261609586427838, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 216 -------------------\n",
      "average training loss: 0.4157068595762555, training acc: 0.8135446906089783\n",
      "validation loss: 0.42490393774850027, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 217 -------------------\n",
      "average training loss: 0.4260738649698087, training acc: 0.8089337348937988\n",
      "validation loss: 0.4296758177642998, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 218 -------------------\n",
      "average training loss: 0.42901141801553777, training acc: 0.8069164156913757\n",
      "validation loss: 0.4286332254036231, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 219 -------------------\n",
      "average training loss: 0.4291185050258032, training acc: 0.8066282272338867\n",
      "validation loss: 0.4322418191465914, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 220 -------------------\n",
      "average training loss: 0.4224719921518815, training acc: 0.8092219233512878\n",
      "validation loss: 0.4244141542966465, validation acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 221 -------------------\n",
      "average training loss: 0.4205624619375388, training acc: 0.8057636618614197\n",
      "validation loss: 0.429846512282499, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 222 -------------------\n",
      "average training loss: 0.4227898458926066, training acc: 0.8031700253486633\n",
      "validation loss: 0.42582576945080736, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 223 -------------------\n",
      "average training loss: 0.426303588467991, training acc: 0.8086455464363098\n",
      "validation loss: 0.4251806374793778, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 224 -------------------\n",
      "average training loss: 0.42404497587028084, training acc: 0.8089337348937988\n",
      "validation loss: 0.4266177404860747, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 225 -------------------\n",
      "average training loss: 0.4230608851662287, training acc: 0.8109509944915771\n",
      "validation loss: 0.4423311355476555, validation acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 226 -------------------\n",
      "average training loss: 0.4224752555147715, training acc: 0.8080691695213318\n",
      "validation loss: 0.4300698624228552, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 227 -------------------\n",
      "average training loss: 0.42267795198245417, training acc: 0.8048991560935974\n",
      "validation loss: 0.4303943060235494, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 228 -------------------\n",
      "average training loss: 0.4217864111108807, training acc: 0.8077809810638428\n",
      "validation loss: 0.42712302636440996, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 229 -------------------\n",
      "average training loss: 0.42514664499835253, training acc: 0.8057636618614197\n",
      "validation loss: 0.431880866876945, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 230 -------------------\n",
      "average training loss: 0.42389867166620854, training acc: 0.8063400387763977\n",
      "validation loss: 0.4260819999303686, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 231 -------------------\n",
      "average training loss: 0.42199322823488744, training acc: 0.8112391829490662\n",
      "validation loss: 0.4293462915629286, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 232 -------------------\n",
      "average training loss: 0.42903247552921175, training acc: 0.8074927926063538\n",
      "validation loss: 0.43181790006325543, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 233 -------------------\n",
      "average training loss: 0.42034410234830566, training acc: 0.8066282272338867\n",
      "validation loss: 0.4283390318468419, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 234 -------------------\n",
      "average training loss: 0.4186085875680192, training acc: 0.8097983002662659\n",
      "validation loss: 0.42651388804484075, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 235 -------------------\n",
      "average training loss: 0.42664526183941864, training acc: 0.8080691695213318\n",
      "validation loss: 0.4267824932177495, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 236 -------------------\n",
      "average training loss: 0.41915588435590784, training acc: 0.8051873445510864\n",
      "validation loss: 0.4270165070960049, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 237 -------------------\n",
      "average training loss: 0.4249809525198483, training acc: 0.8080691695213318\n",
      "validation loss: 0.4226571539854674, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 238 -------------------\n",
      "average training loss: 0.43158219937632336, training acc: 0.7988472580909729\n",
      "validation loss: 0.42345527762092205, validation acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 239 -------------------\n",
      "average training loss: 0.41901810237928494, training acc: 0.8115273714065552\n",
      "validation loss: 0.41996233007325556, validation acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 240 -------------------\n",
      "average training loss: 0.41334090983489746, training acc: 0.8158501386642456\n",
      "validation loss: 0.4217788160945963, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 241 -------------------\n",
      "average training loss: 0.41627729186407086, training acc: 0.8126801252365112\n",
      "validation loss: 0.4231183728040089, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 242 -------------------\n",
      "average training loss: 0.4310929504526452, training acc: 0.8037464022636414\n",
      "validation loss: 0.42230308495358937, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 243 -------------------\n",
      "average training loss: 0.41441789721205874, training acc: 0.8103746175765991\n",
      "validation loss: 0.4266362002093671, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 244 -------------------\n",
      "average training loss: 0.4180898440674334, training acc: 0.8138328790664673\n",
      "validation loss: 0.4233522954899045, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 245 -------------------\n",
      "average training loss: 0.4207690807172132, training acc: 0.8080691695213318\n",
      "validation loss: 0.429473384734123, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 246 -------------------\n",
      "average training loss: 0.41550886703155915, training acc: 0.8149855732917786\n",
      "validation loss: 0.4230372548652684, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 247 -------------------\n",
      "average training loss: 0.41989888160647854, training acc: 0.8074927926063538\n",
      "validation loss: 0.4248658561486802, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 248 -------------------\n",
      "average training loss: 0.42468372944109034, training acc: 0.8060518503189087\n",
      "validation loss: 0.42232278277797086, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 249 -------------------\n",
      "average training loss: 0.419816686509322, training acc: 0.8103746175765991\n",
      "validation loss: 0.4262045718008472, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 250 -------------------\n",
      "average training loss: 0.41508027403601994, training acc: 0.8112391829490662\n",
      "validation loss: 0.4250278983797346, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 251 -------------------\n",
      "average training loss: 0.4168915955752392, training acc: 0.8072046041488647\n",
      "validation loss: 0.4205791576666766, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 252 -------------------\n",
      "average training loss: 0.42233791962824224, training acc: 0.8028818368911743\n",
      "validation loss: 0.42462216104779926, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 253 -------------------\n",
      "average training loss: 0.41573280905955806, training acc: 0.8112391829490662\n",
      "validation loss: 0.4177003055124239, validation acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 254 -------------------\n",
      "average training loss: 0.42279584047086644, training acc: 0.8014408946037292\n",
      "validation loss: 0.4228380878674819, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 255 -------------------\n",
      "average training loss: 0.41867040284085344, training acc: 0.8086455464363098\n",
      "validation loss: 0.42718351519052883, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 256 -------------------\n",
      "average training loss: 0.4090838216223703, training acc: 0.8126801252365112\n",
      "validation loss: 0.4197013786036847, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 257 -------------------\n",
      "average training loss: 0.41783369226483175, training acc: 0.8095101118087769\n",
      "validation loss: 0.42293359263701374, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 258 -------------------\n",
      "average training loss: 0.41491803049354115, training acc: 0.8138328790664673\n",
      "validation loss: 0.42270718274577973, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 259 -------------------\n",
      "average training loss: 0.4209626180981353, training acc: 0.8095101118087769\n",
      "validation loss: 0.4233065604614223, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 260 -------------------\n",
      "average training loss: 0.41801660181122485, training acc: 0.8025936484336853\n",
      "validation loss: 0.41698628059730003, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 261 -------------------\n",
      "average training loss: 0.4136708723708601, training acc: 0.8118155598640442\n",
      "validation loss: 0.41634544702718884, validation acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 262 -------------------\n",
      "average training loss: 0.41501731597724495, training acc: 0.8170028924942017\n",
      "validation loss: 0.4224398662143039, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 263 -------------------\n",
      "average training loss: 0.42049735135235083, training acc: 0.8112391829490662\n",
      "validation loss: 0.43083013958095956, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 264 -------------------\n",
      "average training loss: 0.4248291954698755, training acc: 0.8054755330085754\n",
      "validation loss: 0.4195184362923495, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 265 -------------------\n",
      "average training loss: 0.4114058182631171, training acc: 0.8092219233512878\n",
      "validation loss: 0.42345815526175606, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 266 -------------------\n",
      "average training loss: 0.4172589192988206, training acc: 0.8060518503189087\n",
      "validation loss: 0.4242340796004792, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 267 -------------------\n",
      "average training loss: 0.41366555903761804, training acc: 0.8144091963768005\n",
      "validation loss: 0.42507508438303726, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 268 -------------------\n",
      "average training loss: 0.4239744340652004, training acc: 0.8040345907211304\n",
      "validation loss: 0.42245250171230686, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 269 -------------------\n",
      "average training loss: 0.4107981339139966, training acc: 0.8210374712944031\n",
      "validation loss: 0.42515097716436956, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 270 -------------------\n",
      "average training loss: 0.4166549463780538, training acc: 0.8077809810638428\n",
      "validation loss: 0.4253082242429531, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 271 -------------------\n",
      "average training loss: 0.40793130973230524, training acc: 0.8155619502067566\n",
      "validation loss: 0.42048279934215105, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 272 -------------------\n",
      "average training loss: 0.4211245556128472, training acc: 0.8083573579788208\n",
      "validation loss: 0.419562594544503, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 273 -------------------\n",
      "average training loss: 0.4234936728944696, training acc: 0.8069164156913757\n",
      "validation loss: 0.43935154165540424, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 274 -------------------\n",
      "average training loss: 0.4158853871506298, training acc: 0.820172905921936\n",
      "validation loss: 0.4204719690133899, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 275 -------------------\n",
      "average training loss: 0.4165845624995163, training acc: 0.8115273714065552\n",
      "validation loss: 0.4267292723128323, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 276 -------------------\n",
      "average training loss: 0.41454509750910384, training acc: 0.8092219233512878\n",
      "validation loss: 0.419108504935893, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 277 -------------------\n",
      "average training loss: 0.41050426578659144, training acc: 0.819596529006958\n",
      "validation loss: 0.42018833852583365, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 278 -------------------\n",
      "average training loss: 0.4173644338801546, training acc: 0.8100864291191101\n",
      "validation loss: 0.4279236288114627, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 279 -------------------\n",
      "average training loss: 0.4184448039153811, training acc: 0.8100864291191101\n",
      "validation loss: 0.42103708449596633, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 280 -------------------\n",
      "average training loss: 0.40583723501788094, training acc: 0.818731963634491\n",
      "validation loss: 0.4197032010775008, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 281 -------------------\n",
      "average training loss: 0.40854576413844435, training acc: 0.8135446906089783\n",
      "validation loss: 0.42632810489922623, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 282 -------------------\n",
      "average training loss: 0.411384822724532, training acc: 0.8181556463241577\n",
      "validation loss: 0.42480838326265186, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 283 -------------------\n",
      "average training loss: 0.4156544046374494, training acc: 0.8089337348937988\n",
      "validation loss: 0.4255847212631032, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 284 -------------------\n",
      "average training loss: 0.41239036249496064, training acc: 0.820461094379425\n",
      "validation loss: 0.4225333558249583, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 285 -------------------\n",
      "average training loss: 0.4061702945562192, training acc: 0.8115273714065552\n",
      "validation loss: 0.4306648219785383, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 286 -------------------\n",
      "average training loss: 0.41088374975091785, training acc: 0.8172910809516907\n",
      "validation loss: 0.41757922526878144, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 287 -------------------\n",
      "average training loss: 0.41094938976963935, training acc: 0.8158501386642456\n",
      "validation loss: 0.4259924641402636, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 288 -------------------\n",
      "average training loss: 0.4086845108858103, training acc: 0.8161383271217346\n",
      "validation loss: 0.4254557865281259, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 289 -------------------\n",
      "average training loss: 0.41547828270310283, training acc: 0.8149855732917786\n",
      "validation loss: 0.42036101070966586, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 290 -------------------\n",
      "average training loss: 0.4064473482648646, training acc: 0.820461094379425\n",
      "validation loss: 0.4216110096549109, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 291 -------------------\n",
      "average training loss: 0.41673042009818106, training acc: 0.8112391829490662\n",
      "validation loss: 0.4209284675286113, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 292 -------------------\n",
      "average training loss: 0.4098930850667981, training acc: 0.8178674578666687\n",
      "validation loss: 0.4245584475279953, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 293 -------------------\n",
      "average training loss: 0.4137123348389991, training acc: 0.8146973848342896\n",
      "validation loss: 0.42102364735669257, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 294 -------------------\n",
      "average training loss: 0.41554797047840414, training acc: 0.8146973848342896\n",
      "validation loss: 0.42056025351796833, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 295 -------------------\n",
      "average training loss: 0.41134952043937334, training acc: 0.8161383271217346\n",
      "validation loss: 0.41791692156396154, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 296 -------------------\n",
      "average training loss: 0.4043080101610948, training acc: 0.8242074847221375\n",
      "validation loss: 0.4211878451059491, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 297 -------------------\n",
      "average training loss: 0.4130611210632049, training acc: 0.8144091963768005\n",
      "validation loss: 0.4184960192799019, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 298 -------------------\n",
      "average training loss: 0.4157601602826407, training acc: 0.8106628060340881\n",
      "validation loss: 0.41952777925174906, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 299 -------------------\n",
      "average training loss: 0.416782087448351, training acc: 0.8100864291191101\n",
      "validation loss: 0.42663617754861505, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 300 -------------------\n",
      "average training loss: 0.4148910042531896, training acc: 0.8149855732917786\n",
      "validation loss: 0.41997121020396183, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 301 -------------------\n",
      "average training loss: 0.4132151541861059, training acc: 0.818443775177002\n",
      "validation loss: 0.41602029215355624, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 302 -------------------\n",
      "average training loss: 0.4112849147759528, training acc: 0.8126801252365112\n",
      "validation loss: 0.42051046647234447, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 303 -------------------\n",
      "average training loss: 0.40593780224192727, training acc: 0.8132565021514893\n",
      "validation loss: 0.4128275417512463, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 304 -------------------\n",
      "average training loss: 0.40979078056489354, training acc: 0.8210374712944031\n",
      "validation loss: 0.41578306086052397, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 305 -------------------\n",
      "average training loss: 0.4118944888499697, training acc: 0.8224784135818481\n",
      "validation loss: 0.4197091340744001, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 306 -------------------\n",
      "average training loss: 0.4097709733745894, training acc: 0.8109509944915771\n",
      "validation loss: 0.41642603113354626, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 307 -------------------\n",
      "average training loss: 0.4038894419539559, training acc: 0.8178674578666687\n",
      "validation loss: 0.41905557024314105, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 308 -------------------\n",
      "average training loss: 0.4098462483037789, training acc: 0.8115273714065552\n",
      "validation loss: 0.4172917733544029, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 309 -------------------\n",
      "average training loss: 0.4051076629148093, training acc: 0.819308340549469\n",
      "validation loss: 0.41740385673013153, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 310 -------------------\n",
      "average training loss: 0.4152711054433663, training acc: 0.8051873445510864\n",
      "validation loss: 0.4180193822230062, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 311 -------------------\n",
      "average training loss: 0.4147594582450493, training acc: 0.8089337348937988\n",
      "validation loss: 0.4203043798422484, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 312 -------------------\n",
      "average training loss: 0.40614321328033975, training acc: 0.8175792694091797\n",
      "validation loss: 0.43081916587144, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 313 -------------------\n",
      "average training loss: 0.4144448128660405, training acc: 0.8123919367790222\n",
      "validation loss: 0.42152881100430467, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 314 -------------------\n",
      "average training loss: 0.4191473743585757, training acc: 0.8152737617492676\n",
      "validation loss: 0.42636921397551963, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 315 -------------------\n",
      "average training loss: 0.408946645500337, training acc: 0.8152737617492676\n",
      "validation loss: 0.4183367435833276, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 316 -------------------\n",
      "average training loss: 0.412019914835262, training acc: 0.8080691695213318\n",
      "validation loss: 0.4202447168288692, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 317 -------------------\n",
      "average training loss: 0.4086359117147902, training acc: 0.8146973848342896\n",
      "validation loss: 0.42197797897224604, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 318 -------------------\n",
      "average training loss: 0.40490626007404384, training acc: 0.820172905921936\n",
      "validation loss: 0.4208789150561056, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 319 -------------------\n",
      "average training loss: 0.40309387668752533, training acc: 0.8213256597518921\n",
      "validation loss: 0.42861342498783694, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 320 -------------------\n",
      "average training loss: 0.41018245632435474, training acc: 0.8155619502067566\n",
      "validation loss: 0.42066795265619655, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 321 -------------------\n",
      "average training loss: 0.40803371351802725, training acc: 0.8152737617492676\n",
      "validation loss: 0.41839967510117915, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 322 -------------------\n",
      "average training loss: 0.4074086926168942, training acc: 0.8158501386642456\n",
      "validation loss: 0.4221436760392607, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 323 -------------------\n",
      "average training loss: 0.41386386958254173, training acc: 0.8181556463241577\n",
      "validation loss: 0.41627854589493046, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 324 -------------------\n",
      "average training loss: 0.40871291225856593, training acc: 0.8172910809516907\n",
      "validation loss: 0.4141716994173516, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 325 -------------------\n",
      "average training loss: 0.4062148826524229, training acc: 0.8161383271217346\n",
      "validation loss: 0.41562332013785014, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 326 -------------------\n",
      "average training loss: 0.4141186845147988, training acc: 0.8132565021514893\n",
      "validation loss: 0.4181274354183179, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 327 -------------------\n",
      "average training loss: 0.40962190865096165, training acc: 0.8149855732917786\n",
      "validation loss: 0.41829023891330314, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 328 -------------------\n",
      "average training loss: 0.4039532028460709, training acc: 0.8172910809516907\n",
      "validation loss: 0.4215270837056472, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 329 -------------------\n",
      "average training loss: 0.4022909141754898, training acc: 0.8175792694091797\n",
      "validation loss: 0.41733743998861533, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 330 -------------------\n",
      "average training loss: 0.40745645335497016, training acc: 0.8164265155792236\n",
      "validation loss: 0.417353890046546, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 331 -------------------\n",
      "average training loss: 0.4086614324654901, training acc: 0.819596529006958\n",
      "validation loss: 0.41888691450593657, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 332 -------------------\n",
      "average training loss: 0.41201394859067986, training acc: 0.8141210079193115\n",
      "validation loss: 0.41967113652536947, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 333 -------------------\n",
      "average training loss: 0.4024274867274919, training acc: 0.8175792694091797\n",
      "validation loss: 0.41997286237879283, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 334 -------------------\n",
      "average training loss: 0.40441197084762176, training acc: 0.819308340549469\n",
      "validation loss: 0.41893564459914984, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 335 -------------------\n",
      "average training loss: 0.40477103359074, training acc: 0.820461094379425\n",
      "validation loss: 0.4219207267882088, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 336 -------------------\n",
      "average training loss: 0.3988659018226591, training acc: 0.8216138482093811\n",
      "validation loss: 0.4209098387423748, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 337 -------------------\n",
      "average training loss: 0.4057762859018804, training acc: 0.8138328790664673\n",
      "validation loss: 0.4165339956085803, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 338 -------------------\n",
      "average training loss: 0.402137974926649, training acc: 0.8230547308921814\n",
      "validation loss: 0.4188448948794246, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 339 -------------------\n",
      "average training loss: 0.40677305623158944, training acc: 0.818443775177002\n",
      "validation loss: 0.42317497895060596, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 340 -------------------\n",
      "average training loss: 0.40376693200996355, training acc: 0.8170028924942017\n",
      "validation loss: 0.42497221390772527, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 341 -------------------\n",
      "average training loss: 0.4024736821307916, training acc: 0.818731963634491\n",
      "validation loss: 0.4232207212579964, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 342 -------------------\n",
      "average training loss: 0.40095278567470805, training acc: 0.8167147040367126\n",
      "validation loss: 0.42211456562516875, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 343 -------------------\n",
      "average training loss: 0.411937611934431, training acc: 0.8144091963768005\n",
      "validation loss: 0.42257297492247026, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 344 -------------------\n",
      "average training loss: 0.39994803342420704, training acc: 0.8181556463241577\n",
      "validation loss: 0.4230555838428884, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 345 -------------------\n",
      "average training loss: 0.4094647773061087, training acc: 0.8221902251243591\n",
      "validation loss: 0.4314655971966581, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 346 -------------------\n",
      "average training loss: 0.40448187211748504, training acc: 0.819308340549469\n",
      "validation loss: 0.4173781863555381, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 347 -------------------\n",
      "average training loss: 0.40576072783566347, training acc: 0.8158501386642456\n",
      "validation loss: 0.42123080233824417, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 348 -------------------\n",
      "average training loss: 0.4085636346072216, training acc: 0.819308340549469\n",
      "validation loss: 0.41465312173838986, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 349 -------------------\n",
      "average training loss: 0.4050631278186435, training acc: 0.8123919367790222\n",
      "validation loss: 0.4230912393688606, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 350 -------------------\n",
      "average training loss: 0.40302127697625834, training acc: 0.820172905921936\n",
      "validation loss: 0.42181677271693535, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 351 -------------------\n",
      "average training loss: 0.3992794910150577, training acc: 0.8265129923820496\n",
      "validation loss: 0.41984733321150325, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 352 -------------------\n",
      "average training loss: 0.4022967295790955, training acc: 0.8210374712944031\n",
      "validation loss: 0.42569434560389013, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 353 -------------------\n",
      "average training loss: 0.4070477878497726, training acc: 0.8219020366668701\n",
      "validation loss: 0.4265310348178934, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 354 -------------------\n",
      "average training loss: 0.4053942882361948, training acc: 0.8216138482093811\n",
      "validation loss: 0.4191770353075546, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 355 -------------------\n",
      "average training loss: 0.4014148794436661, training acc: 0.8172910809516907\n",
      "validation loss: 0.4209530157152958, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 356 -------------------\n",
      "average training loss: 0.4046640648536105, training acc: 0.818443775177002\n",
      "validation loss: 0.4186089336872101, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 357 -------------------\n",
      "average training loss: 0.4046083511639741, training acc: 0.8210374712944031\n",
      "validation loss: 0.4177468723965131, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 358 -------------------\n",
      "average training loss: 0.39835719663746416, training acc: 0.8296830058097839\n",
      "validation loss: 0.42272050397187333, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 359 -------------------\n",
      "average training loss: 0.4117309418810204, training acc: 0.8213256597518921\n",
      "validation loss: 0.41532334657858044, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 360 -------------------\n",
      "average training loss: 0.4026891120229056, training acc: 0.8170028924942017\n",
      "validation loss: 0.4140777920248322, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 361 -------------------\n",
      "average training loss: 0.40957706237388963, training acc: 0.8181556463241577\n",
      "validation loss: 0.4295168188035763, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 362 -------------------\n",
      "average training loss: 0.40377727930758806, training acc: 0.819884717464447\n",
      "validation loss: 0.4125012835049959, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 363 -------------------\n",
      "average training loss: 0.40633971478135167, training acc: 0.8216138482093811\n",
      "validation loss: 0.41442576792382974, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 364 -------------------\n",
      "average training loss: 0.4003802057989049, training acc: 0.8213256597518921\n",
      "validation loss: 0.4132819172973457, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 365 -------------------\n",
      "average training loss: 0.4028217761420379, training acc: 0.819596529006958\n",
      "validation loss: 0.4125070386493261, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 366 -------------------\n",
      "average training loss: 0.3954952319176809, training acc: 0.8219020366668701\n",
      "validation loss: 0.4214695236100579, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 367 -------------------\n",
      "average training loss: 0.4043852372025207, training acc: 0.8236311078071594\n",
      "validation loss: 0.41455532232737213, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 368 -------------------\n",
      "average training loss: 0.4010640865100564, training acc: 0.820461094379425\n",
      "validation loss: 0.42413487961764706, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 369 -------------------\n",
      "average training loss: 0.41113203918555974, training acc: 0.8155619502067566\n",
      "validation loss: 0.41302345219295694, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 370 -------------------\n",
      "average training loss: 0.39945790628534916, training acc: 0.8230547308921814\n",
      "validation loss: 0.42189088614854947, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 371 -------------------\n",
      "average training loss: 0.4050155158345225, training acc: 0.8270893096923828\n",
      "validation loss: 0.4131575306439729, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 372 -------------------\n",
      "average training loss: 0.40296392073205295, training acc: 0.819596529006958\n",
      "validation loss: 0.41468420913142545, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 373 -------------------\n",
      "average training loss: 0.39952544612912005, training acc: 0.820461094379425\n",
      "validation loss: 0.4167344229561942, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 374 -------------------\n",
      "average training loss: 0.40278263692381744, training acc: 0.8181556463241577\n",
      "validation loss: 0.4118330394892099, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 375 -------------------\n",
      "average training loss: 0.4020165779748636, training acc: 0.8152737617492676\n",
      "validation loss: 0.4130691335223238, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 376 -------------------\n",
      "average training loss: 0.39668195628982456, training acc: 0.8244956731796265\n",
      "validation loss: 0.4146840415791982, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 377 -------------------\n",
      "average training loss: 0.4056256967594026, training acc: 0.8118155598640442\n",
      "validation loss: 0.41481189601432344, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 378 -------------------\n",
      "average training loss: 0.40642564121515673, training acc: 0.8121037483215332\n",
      "validation loss: 0.43322198250876043, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 379 -------------------\n",
      "average training loss: 0.4001106100054914, training acc: 0.8253602385520935\n",
      "validation loss: 0.43033510075736153, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 380 -------------------\n",
      "average training loss: 0.40474007138257756, training acc: 0.8181556463241577\n",
      "validation loss: 0.41556350426739813, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 381 -------------------\n",
      "average training loss: 0.4018540303713994, training acc: 0.8175792694091797\n",
      "validation loss: 0.41569021165645614, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 382 -------------------\n",
      "average training loss: 0.3972417927956375, training acc: 0.8233429193496704\n",
      "validation loss: 0.4201483791050274, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 383 -------------------\n",
      "average training loss: 0.3928073140746922, training acc: 0.8250720500946045\n",
      "validation loss: 0.41896484208546475, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 384 -------------------\n",
      "average training loss: 0.4041215656985467, training acc: 0.8164265155792236\n",
      "validation loss: 0.42194848936823653, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 385 -------------------\n",
      "average training loss: 0.402511532918177, training acc: 0.8164265155792236\n",
      "validation loss: 0.4116319890395837, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 386 -------------------\n",
      "average training loss: 0.4015114991396923, training acc: 0.8244956731796265\n",
      "validation loss: 0.4168412604364931, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 387 -------------------\n",
      "average training loss: 0.40415800928382434, training acc: 0.8242074847221375\n",
      "validation loss: 0.4192054914439329, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 388 -------------------\n",
      "average training loss: 0.3985702970529496, training acc: 0.818731963634491\n",
      "validation loss: 0.42415900933577716, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 389 -------------------\n",
      "average training loss: 0.40159067231571294, training acc: 0.819308340549469\n",
      "validation loss: 0.42088786426777114, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 390 -------------------\n",
      "average training loss: 0.40578000265514474, training acc: 0.8129683136940002\n",
      "validation loss: 0.41726471957523154, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 391 -------------------\n",
      "average training loss: 0.3989672997155863, training acc: 0.8221902251243591\n",
      "validation loss: 0.42065102603578347, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 392 -------------------\n",
      "average training loss: 0.3985066618287254, training acc: 0.8216138482093811\n",
      "validation loss: 0.41838632695685884, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 393 -------------------\n",
      "average training loss: 0.39868337953468563, training acc: 0.8279538750648499\n",
      "validation loss: 0.42012770508291536, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 394 -------------------\n",
      "average training loss: 0.3984576147983672, training acc: 0.820172905921936\n",
      "validation loss: 0.4141310533070894, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 395 -------------------\n",
      "average training loss: 0.39685639526040134, training acc: 0.8233429193496704\n",
      "validation loss: 0.4110989268474315, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 396 -------------------\n",
      "average training loss: 0.3996581426013787, training acc: 0.8250720500946045\n",
      "validation loss: 0.41702639713265377, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 397 -------------------\n",
      "average training loss: 0.4004686764406539, training acc: 0.8259366154670715\n",
      "validation loss: 0.413703338204441, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 398 -------------------\n",
      "average training loss: 0.39543097776707037, training acc: 0.8273774981498718\n",
      "validation loss: 0.4101045656314094, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 399 -------------------\n",
      "average training loss: 0.3969903035191363, training acc: 0.8242074847221375\n",
      "validation loss: 0.4158637433008115, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 400 -------------------\n",
      "average training loss: 0.3938595855442179, training acc: 0.8233429193496704\n",
      "validation loss: 0.4123905643065404, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 401 -------------------\n",
      "average training loss: 0.39539185396532506, training acc: 0.8221902251243591\n",
      "validation loss: 0.4192369028170537, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 402 -------------------\n",
      "average training loss: 0.4037332848015024, training acc: 0.8230547308921814\n",
      "validation loss: 0.4162355004917092, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 403 -------------------\n",
      "average training loss: 0.3948162264026895, training acc: 0.8244956731796265\n",
      "validation loss: 0.41559309069462086, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 404 -------------------\n",
      "average training loss: 0.39008949952098065, training acc: 0.830547571182251\n",
      "validation loss: 0.41590141645774314, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 405 -------------------\n",
      "average training loss: 0.39261520486056634, training acc: 0.8276656866073608\n",
      "validation loss: 0.4165239654103732, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 406 -------------------\n",
      "average training loss: 0.4015818284121302, training acc: 0.8170028924942017\n",
      "validation loss: 0.4149005256490224, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 407 -------------------\n",
      "average training loss: 0.39614436767286804, training acc: 0.8236311078071594\n",
      "validation loss: 0.41630193714721964, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 408 -------------------\n",
      "average training loss: 0.3952247701220279, training acc: 0.8219020366668701\n",
      "validation loss: 0.4201008133624556, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 409 -------------------\n",
      "average training loss: 0.3910261875614309, training acc: 0.8239192962646484\n",
      "validation loss: 0.4169154592922756, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 410 -------------------\n",
      "average training loss: 0.39041313152835416, training acc: 0.8265129923820496\n",
      "validation loss: 0.4143787152756194, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 411 -------------------\n",
      "average training loss: 0.39560478880185557, training acc: 0.8273774981498718\n",
      "validation loss: 0.41248187175544176, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 412 -------------------\n",
      "average training loss: 0.39857643954348493, training acc: 0.8175792694091797\n",
      "validation loss: 0.4133886569930661, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 413 -------------------\n",
      "average training loss: 0.4058524548749759, training acc: 0.8224784135818481\n",
      "validation loss: 0.4141018482671905, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 414 -------------------\n",
      "average training loss: 0.4025470150822521, training acc: 0.8178674578666687\n",
      "validation loss: 0.4139891763985981, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 415 -------------------\n",
      "average training loss: 0.3972484185991095, training acc: 0.818731963634491\n",
      "validation loss: 0.41609488832785785, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 416 -------------------\n",
      "average training loss: 0.3973901755356308, training acc: 0.8256484270095825\n",
      "validation loss: 0.41947374201040666, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 417 -------------------\n",
      "average training loss: 0.3939217248808067, training acc: 0.8236311078071594\n",
      "validation loss: 0.4192806394418813, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 418 -------------------\n",
      "average training loss: 0.4027084400571389, training acc: 0.8207492828369141\n",
      "validation loss: 0.4190414168867647, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 419 -------------------\n",
      "average training loss: 0.392900467399905, training acc: 0.8256484270095825\n",
      "validation loss: 0.4183167811088298, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 420 -------------------\n",
      "average training loss: 0.39906640039053703, training acc: 0.818443775177002\n",
      "validation loss: 0.42005552481945757, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 421 -------------------\n",
      "average training loss: 0.3954517823131352, training acc: 0.8233429193496704\n",
      "validation loss: 0.4220958965989302, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 422 -------------------\n",
      "average training loss: 0.38582346657511135, training acc: 0.8268011808395386\n",
      "validation loss: 0.41469101573465056, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 423 -------------------\n",
      "average training loss: 0.3958934841478936, training acc: 0.8219020366668701\n",
      "validation loss: 0.4197517354642191, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 424 -------------------\n",
      "average training loss: 0.3965424188104074, training acc: 0.8253602385520935\n",
      "validation loss: 0.417111727224517, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 425 -------------------\n",
      "average training loss: 0.38619971005648634, training acc: 0.8244956731796265\n",
      "validation loss: 0.41325885277189967, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 426 -------------------\n",
      "average training loss: 0.39979067593812945, training acc: 0.8172910809516907\n",
      "validation loss: 0.416130601947758, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 427 -------------------\n",
      "average training loss: 0.3999379312700085, training acc: 0.8239192962646484\n",
      "validation loss: 0.4186144098982833, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 428 -------------------\n",
      "average training loss: 0.3973724904768062, training acc: 0.820461094379425\n",
      "validation loss: 0.41249830615685285, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 429 -------------------\n",
      "average training loss: 0.3990152017699195, training acc: 0.8244956731796265\n",
      "validation loss: 0.4115273886561943, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 430 -------------------\n",
      "average training loss: 0.3895592046230602, training acc: 0.8291066288948059\n",
      "validation loss: 0.4159366807080634, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 431 -------------------\n",
      "average training loss: 0.3961757781182655, training acc: 0.8233429193496704\n",
      "validation loss: 0.4136031704014897, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 432 -------------------\n",
      "average training loss: 0.39801811187256997, training acc: 0.8219020366668701\n",
      "validation loss: 0.42090854021261365, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 433 -------------------\n",
      "average training loss: 0.39602412686224286, training acc: 0.8253602385520935\n",
      "validation loss: 0.41288864406572506, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 434 -------------------\n",
      "average training loss: 0.39188447586054076, training acc: 0.8296830058097839\n",
      "validation loss: 0.4141994802633189, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 435 -------------------\n",
      "average training loss: 0.39487390157468727, training acc: 0.8239192962646484\n",
      "validation loss: 0.41367039812325335, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 436 -------------------\n",
      "average training loss: 0.3894437517659465, training acc: 0.8291066288948059\n",
      "validation loss: 0.41795317862989717, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 437 -------------------\n",
      "average training loss: 0.3915589136589501, training acc: 0.8259366154670715\n",
      "validation loss: 0.41673776713384464, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 438 -------------------\n",
      "average training loss: 0.3879201306733343, training acc: 0.8239192962646484\n",
      "validation loss: 0.41592272470623665, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 439 -------------------\n",
      "average training loss: 0.3914170152344003, training acc: 0.830259382724762\n",
      "validation loss: 0.4153251708377891, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 440 -------------------\n",
      "average training loss: 0.3979001872821225, training acc: 0.8293948173522949\n",
      "validation loss: 0.41522292937001876, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 441 -------------------\n",
      "average training loss: 0.3971797626025395, training acc: 0.8259366154670715\n",
      "validation loss: 0.4175475014519582, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 442 -------------------\n",
      "average training loss: 0.39165809322846384, training acc: 0.8276656866073608\n",
      "validation loss: 0.41495677375573714, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 443 -------------------\n",
      "average training loss: 0.3848534449548474, training acc: 0.8365994095802307\n",
      "validation loss: 0.4195778488014151, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 444 -------------------\n",
      "average training loss: 0.39684324817629985, training acc: 0.8273774981498718\n",
      "validation loss: 0.423810586127268, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 445 -------------------\n",
      "average training loss: 0.39002188380582187, training acc: 0.8276656866073608\n",
      "validation loss: 0.4131585676823893, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 446 -------------------\n",
      "average training loss: 0.39304309995785913, training acc: 0.8247838616371155\n",
      "validation loss: 0.41621871848809555, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 447 -------------------\n",
      "average training loss: 0.38791641075947786, training acc: 0.8279538750648499\n",
      "validation loss: 0.4142746053258395, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 448 -------------------\n",
      "average training loss: 0.397774571489532, training acc: 0.8221902251243591\n",
      "validation loss: 0.41363187772887094, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 449 -------------------\n",
      "average training loss: 0.39078426046742487, training acc: 0.8256484270095825\n",
      "validation loss: 0.4114869779430776, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 450 -------------------\n",
      "average training loss: 0.39012372785755123, training acc: 0.8319884538650513\n",
      "validation loss: 0.4140091681260667, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 451 -------------------\n",
      "average training loss: 0.3850835622387592, training acc: 0.8259366154670715\n",
      "validation loss: 0.4097400141476486, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 452 -------------------\n",
      "average training loss: 0.3961208730334851, training acc: 0.819308340549469\n",
      "validation loss: 0.41617492088524427, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 453 -------------------\n",
      "average training loss: 0.38830731421794945, training acc: 0.8227665424346924\n",
      "validation loss: 0.41697696112267985, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 454 -------------------\n",
      "average training loss: 0.3971659011902658, training acc: 0.8207492828369141\n",
      "validation loss: 0.4136064448114914, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 455 -------------------\n",
      "average training loss: 0.3933465769723788, training acc: 0.8253602385520935\n",
      "validation loss: 0.4206954075993481, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 456 -------------------\n",
      "average training loss: 0.39303006856173534, training acc: 0.8296830058097839\n",
      "validation loss: 0.41239782714624007, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 457 -------------------\n",
      "average training loss: 0.3923107655659876, training acc: 0.8239192962646484\n",
      "validation loss: 0.41293717804042973, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 458 -------------------\n",
      "average training loss: 0.3895824268932645, training acc: 0.830547571182251\n",
      "validation loss: 0.4233827048457713, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 459 -------------------\n",
      "average training loss: 0.39191587460831195, training acc: 0.8265129923820496\n",
      "validation loss: 0.4148614488988428, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 460 -------------------\n",
      "average training loss: 0.3929753074814332, training acc: 0.8216138482093811\n",
      "validation loss: 0.4125491171937934, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 461 -------------------\n",
      "average training loss: 0.38920083975242264, training acc: 0.8296830058097839\n",
      "validation loss: 0.4170040676396014, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 462 -------------------\n",
      "average training loss: 0.39250270925269004, training acc: 0.820461094379425\n",
      "validation loss: 0.41676362607336265, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 463 -------------------\n",
      "average training loss: 0.400404183562276, training acc: 0.8181556463241577\n",
      "validation loss: 0.42399471009381906, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 464 -------------------\n",
      "average training loss: 0.3948560593794677, training acc: 0.8253602385520935\n",
      "validation loss: 0.41766062969436296, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 465 -------------------\n",
      "average training loss: 0.3884486525821411, training acc: 0.8221902251243591\n",
      "validation loss: 0.41119726572168586, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 466 -------------------\n",
      "average training loss: 0.3905431834009264, training acc: 0.8259366154670715\n",
      "validation loss: 0.41809367336985154, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 467 -------------------\n",
      "average training loss: 0.3852394322497013, training acc: 0.8244956731796265\n",
      "validation loss: 0.4152704046069202, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 468 -------------------\n",
      "average training loss: 0.3916336399505736, training acc: 0.8233429193496704\n",
      "validation loss: 0.41652751435881935, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 469 -------------------\n",
      "average training loss: 0.39463325914113595, training acc: 0.8265129923820496\n",
      "validation loss: 0.41900296653470687, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 470 -------------------\n",
      "average training loss: 0.39128378933719665, training acc: 0.8239192962646484\n",
      "validation loss: 0.42638842768383467, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 471 -------------------\n",
      "average training loss: 0.393265954475925, training acc: 0.8213256597518921\n",
      "validation loss: 0.42073817228391974, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 472 -------------------\n",
      "average training loss: 0.38468528975670896, training acc: 0.8354467153549194\n",
      "validation loss: 0.4148165983263798, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 473 -------------------\n",
      "average training loss: 0.3909063312437074, training acc: 0.8253602385520935\n",
      "validation loss: 0.41735119259302517, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 474 -------------------\n",
      "average training loss: 0.3991503331262715, training acc: 0.8146973848342896\n",
      "validation loss: 0.41510987309266895, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 475 -------------------\n",
      "average training loss: 0.3949911109824002, training acc: 0.81902015209198\n",
      "validation loss: 0.4143530263604107, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 476 -------------------\n",
      "average training loss: 0.3839838539660836, training acc: 0.8262248039245605\n",
      "validation loss: 0.4151332757440031, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 477 -------------------\n",
      "average training loss: 0.3918340309123141, training acc: 0.8296830058097839\n",
      "validation loss: 0.42393013656414047, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 478 -------------------\n",
      "average training loss: 0.40239838764543834, training acc: 0.819884717464447\n",
      "validation loss: 0.4197012628278425, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 479 -------------------\n",
      "average training loss: 0.39017027630242557, training acc: 0.8265129923820496\n",
      "validation loss: 0.41777081972992364, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 480 -------------------\n",
      "average training loss: 0.39223178501431466, training acc: 0.8268011808395386\n",
      "validation loss: 0.4250031388300355, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 481 -------------------\n",
      "average training loss: 0.40076662899781373, training acc: 0.8210374712944031\n",
      "validation loss: 0.42308992683063457, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 482 -------------------\n",
      "average training loss: 0.39296742780751387, training acc: 0.8250720500946045\n",
      "validation loss: 0.4167554614730694, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 483 -------------------\n",
      "average training loss: 0.3869698405952893, training acc: 0.8288184404373169\n",
      "validation loss: 0.41887779993945, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 484 -------------------\n",
      "average training loss: 0.39378419595767855, training acc: 0.8247838616371155\n",
      "validation loss: 0.4207462485759489, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 485 -------------------\n",
      "average training loss: 0.39369993711411094, training acc: 0.8262248039245605\n",
      "validation loss: 0.41616990873890536, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 486 -------------------\n",
      "average training loss: 0.38753359259377296, training acc: 0.8360230326652527\n",
      "validation loss: 0.4215133065177548, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 487 -------------------\n",
      "average training loss: 0.39171548539005024, training acc: 0.8276656866073608\n",
      "validation loss: 0.424910267789243, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 488 -------------------\n",
      "average training loss: 0.3884770218680159, training acc: 0.8242074847221375\n",
      "validation loss: 0.41818541769058476, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 489 -------------------\n",
      "average training loss: 0.3913774700948072, training acc: 0.8236311078071594\n",
      "validation loss: 0.41512061401446293, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 490 -------------------\n",
      "average training loss: 0.3918209131238096, training acc: 0.8256484270095825\n",
      "validation loss: 0.4182095916315158, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 491 -------------------\n",
      "average training loss: 0.3871455615638656, training acc: 0.8285302519798279\n",
      "validation loss: 0.4179548536028181, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 492 -------------------\n",
      "average training loss: 0.38582356340259916, training acc: 0.8273774981498718\n",
      "validation loss: 0.4129796261611622, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 493 -------------------\n",
      "average training loss: 0.38664871727355277, training acc: 0.8291066288948059\n",
      "validation loss: 0.41253030876959523, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 494 -------------------\n",
      "average training loss: 0.38171292718617994, training acc: 0.830547571182251\n",
      "validation loss: 0.41371735683234606, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 495 -------------------\n",
      "average training loss: 0.39382193945670335, training acc: 0.8259366154670715\n",
      "validation loss: 0.42017523621633857, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 496 -------------------\n",
      "average training loss: 0.38413224891901704, training acc: 0.8262248039245605\n",
      "validation loss: 0.41537569360249604, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 497 -------------------\n",
      "average training loss: 0.3912632996479441, training acc: 0.8268011808395386\n",
      "validation loss: 0.42430833723687905, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 498 -------------------\n",
      "average training loss: 0.3909433063065971, training acc: 0.8345821499824524\n",
      "validation loss: 0.4186428360950013, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 499 -------------------\n",
      "average training loss: 0.383284950565536, training acc: 0.8328530192375183\n",
      "validation loss: 0.42866873370337594, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 500 -------------------\n",
      "average training loss: 0.38851150851428334, training acc: 0.8244956731796265\n",
      "validation loss: 0.4224881917100898, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 501 -------------------\n",
      "average training loss: 0.38353405651510275, training acc: 0.829971194267273\n",
      "validation loss: 0.42062973316913377, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 502 -------------------\n",
      "average training loss: 0.39468927295819484, training acc: 0.8247838616371155\n",
      "validation loss: 0.41900477046790763, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 503 -------------------\n",
      "average training loss: 0.38738900534701276, training acc: 0.8268011808395386\n",
      "validation loss: 0.41609371477557766, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 504 -------------------\n",
      "average training loss: 0.3914636044062524, training acc: 0.8259366154670715\n",
      "validation loss: 0.42078285914961644, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 505 -------------------\n",
      "average training loss: 0.3829857870034594, training acc: 0.8328530192375183\n",
      "validation loss: 0.42380854061671663, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 506 -------------------\n",
      "average training loss: 0.39645609853934144, training acc: 0.819884717464447\n",
      "validation loss: 0.4159142896876357, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 507 -------------------\n",
      "average training loss: 0.3797631092305142, training acc: 0.8314120769500732\n",
      "validation loss: 0.41579649085822745, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 508 -------------------\n",
      "average training loss: 0.3851276462462862, training acc: 0.83083575963974\n",
      "validation loss: 0.416062910298598, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 509 -------------------\n",
      "average training loss: 0.39031032608977656, training acc: 0.8256484270095825\n",
      "validation loss: 0.41751668530125774, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 510 -------------------\n",
      "average training loss: 0.3928396987640205, training acc: 0.8247838616371155\n",
      "validation loss: 0.4173270753726432, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 511 -------------------\n",
      "average training loss: 0.38091356977605684, training acc: 0.830547571182251\n",
      "validation loss: 0.41734092095480535, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 512 -------------------\n",
      "average training loss: 0.38115950486158434, training acc: 0.8293948173522949\n",
      "validation loss: 0.41544228064299726, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 513 -------------------\n",
      "average training loss: 0.37913661358679407, training acc: 0.8293948173522949\n",
      "validation loss: 0.4127946493263069, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 514 -------------------\n",
      "average training loss: 0.3864965650465028, training acc: 0.8282420635223389\n",
      "validation loss: 0.41439659776775517, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 515 -------------------\n",
      "average training loss: 0.38596102159030155, training acc: 0.8262248039245605\n",
      "validation loss: 0.41989690944346414, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 516 -------------------\n",
      "average training loss: 0.38573818759890727, training acc: 0.8273774981498718\n",
      "validation loss: 0.41414448962233585, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 517 -------------------\n",
      "average training loss: 0.3823914052086536, training acc: 0.8317002654075623\n",
      "validation loss: 0.413330297728288, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 518 -------------------\n",
      "average training loss: 0.3879987097267459, training acc: 0.8253602385520935\n",
      "validation loss: 0.419603463004811, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 519 -------------------\n",
      "average training loss: 0.38846318618708453, training acc: 0.8250720500946045\n",
      "validation loss: 0.4198626432275992, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 520 -------------------\n",
      "average training loss: 0.3895017736583347, training acc: 0.8227665424346924\n",
      "validation loss: 0.41223992702598394, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 521 -------------------\n",
      "average training loss: 0.3829984462570388, training acc: 0.8331412076950073\n",
      "validation loss: 0.413437137680669, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 522 -------------------\n",
      "average training loss: 0.3907838920523179, training acc: 0.8227665424346924\n",
      "validation loss: 0.41307423136750676, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 523 -------------------\n",
      "average training loss: 0.387283779925503, training acc: 0.83083575963974\n",
      "validation loss: 0.414879970698862, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 524 -------------------\n",
      "average training loss: 0.3825148211947779, training acc: 0.8345821499824524\n",
      "validation loss: 0.41260151104992987, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 525 -------------------\n",
      "average training loss: 0.3900768986352926, training acc: 0.83083575963974\n",
      "validation loss: 0.41336410166481125, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 526 -------------------\n",
      "average training loss: 0.37961646367390495, training acc: 0.8348703384399414\n",
      "validation loss: 0.4115417098394737, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 527 -------------------\n",
      "average training loss: 0.3840014957900693, training acc: 0.8262248039245605\n",
      "validation loss: 0.4088149794510433, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 528 -------------------\n",
      "average training loss: 0.38051141485013606, training acc: 0.8317002654075623\n",
      "validation loss: 0.4141628110463718, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 529 -------------------\n",
      "average training loss: 0.3838252940335947, training acc: 0.8337175846099854\n",
      "validation loss: 0.41846983169081026, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 530 -------------------\n",
      "average training loss: 0.3922417769858061, training acc: 0.8233429193496704\n",
      "validation loss: 0.4077881858920172, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 531 -------------------\n",
      "average training loss: 0.38147215059923506, training acc: 0.8288184404373169\n",
      "validation loss: 0.410663464789017, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 532 -------------------\n",
      "average training loss: 0.3846773546693648, training acc: 0.8374639749526978\n",
      "validation loss: 0.41202233491405366, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 533 -------------------\n",
      "average training loss: 0.3791374886757359, training acc: 0.8348703384399414\n",
      "validation loss: 0.41353107954499907, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 534 -------------------\n",
      "average training loss: 0.38369261086502404, training acc: 0.8314120769500732\n",
      "validation loss: 0.4112005044238359, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 535 -------------------\n",
      "average training loss: 0.37807872772903883, training acc: 0.8334293961524963\n",
      "validation loss: 0.4176519020087159, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 536 -------------------\n",
      "average training loss: 0.383966583992631, training acc: 0.8314120769500732\n",
      "validation loss: 0.4157858320644924, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 537 -------------------\n",
      "average training loss: 0.38558974015266134, training acc: 0.8279538750648499\n",
      "validation loss: 0.4101679881322219, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 538 -------------------\n",
      "average training loss: 0.3791022263274069, training acc: 0.8331412076950073\n",
      "validation loss: 0.4134596006661516, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 539 -------------------\n",
      "average training loss: 0.3799452150847108, training acc: 0.820461094379425\n",
      "validation loss: 0.4144942452830653, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 540 -------------------\n",
      "average training loss: 0.3823142991887046, training acc: 0.83083575963974\n",
      "validation loss: 0.4172054386358657, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 541 -------------------\n",
      "average training loss: 0.3831647628837772, training acc: 0.8365994095802307\n",
      "validation loss: 0.4161134678097914, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 542 -------------------\n",
      "average training loss: 0.38301828934754695, training acc: 0.8270893096923828\n",
      "validation loss: 0.4149720149655496, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 543 -------------------\n",
      "average training loss: 0.3848947464560913, training acc: 0.8270893096923828\n",
      "validation loss: 0.41162091713347193, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 544 -------------------\n",
      "average training loss: 0.38068636137058137, training acc: 0.8282420635223389\n",
      "validation loss: 0.41386861103470973, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 545 -------------------\n",
      "average training loss: 0.38886104944116445, training acc: 0.8328530192375183\n",
      "validation loss: 0.41800412755408045, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 546 -------------------\n",
      "average training loss: 0.39045321075648326, training acc: 0.8242074847221375\n",
      "validation loss: 0.41875767762759863, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 547 -------------------\n",
      "average training loss: 0.37608712331018807, training acc: 0.8291066288948059\n",
      "validation loss: 0.413333502370641, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 548 -------------------\n",
      "average training loss: 0.3853207440730131, training acc: 0.8236311078071594\n",
      "validation loss: 0.41338532133036493, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 549 -------------------\n",
      "average training loss: 0.3792284349972645, training acc: 0.8368875980377197\n",
      "validation loss: 0.41338850674541316, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 550 -------------------\n",
      "average training loss: 0.3861846529784739, training acc: 0.8314120769500732\n",
      "validation loss: 0.4135104020894398, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 551 -------------------\n",
      "average training loss: 0.39441588383586673, training acc: 0.8236311078071594\n",
      "validation loss: 0.40930651148892766, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 552 -------------------\n",
      "average training loss: 0.3822681715921298, training acc: 0.8342939615249634\n",
      "validation loss: 0.411218624922537, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 553 -------------------\n",
      "average training loss: 0.38543429087836734, training acc: 0.8296830058097839\n",
      "validation loss: 0.4170364567211696, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 554 -------------------\n",
      "average training loss: 0.3817050588663442, training acc: 0.8265129923820496\n",
      "validation loss: 0.4157881883706915, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 555 -------------------\n",
      "average training loss: 0.38428949597761336, training acc: 0.8268011808395386\n",
      "validation loss: 0.42306915296387565, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 556 -------------------\n",
      "average training loss: 0.37943073421802576, training acc: 0.8348703384399414\n",
      "validation loss: 0.4178050255171165, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 557 -------------------\n",
      "average training loss: 0.3738602866442815, training acc: 0.8354467153549194\n",
      "validation loss: 0.41674594491857536, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 558 -------------------\n",
      "average training loss: 0.3807172763244563, training acc: 0.8348703384399414\n",
      "validation loss: 0.41885167868455986, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 559 -------------------\n",
      "average training loss: 0.38378251103915123, training acc: 0.8340057730674744\n",
      "validation loss: 0.42392155157256234, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 560 -------------------\n",
      "average training loss: 0.380447939802659, training acc: 0.8317002654075623\n",
      "validation loss: 0.42011950147866106, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 561 -------------------\n",
      "average training loss: 0.37631809014064777, training acc: 0.8239192962646484\n",
      "validation loss: 0.4175183844456475, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 562 -------------------\n",
      "average training loss: 0.380044790990758, training acc: 0.8319884538650513\n",
      "validation loss: 0.414476973120518, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 563 -------------------\n",
      "average training loss: 0.37498232306595836, training acc: 0.830547571182251\n",
      "validation loss: 0.4150801265294651, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 564 -------------------\n",
      "average training loss: 0.3800687101715236, training acc: 0.8314120769500732\n",
      "validation loss: 0.4214444138487363, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 565 -------------------\n",
      "average training loss: 0.38076839137833124, training acc: 0.8340057730674744\n",
      "validation loss: 0.41374266175081104, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 566 -------------------\n",
      "average training loss: 0.3826816870946362, training acc: 0.8288184404373169\n",
      "validation loss: 0.41484327030621365, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 567 -------------------\n",
      "average training loss: 0.3809631047228228, training acc: 0.8314120769500732\n",
      "validation loss: 0.4163563250121982, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 568 -------------------\n",
      "average training loss: 0.38898900321306346, training acc: 0.8250720500946045\n",
      "validation loss: 0.41852809605510555, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 569 -------------------\n",
      "average training loss: 0.3821544596887803, training acc: 0.8351585268974304\n",
      "validation loss: 0.4170052449000047, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 570 -------------------\n",
      "average training loss: 0.379770492425226, training acc: 0.830259382724762\n",
      "validation loss: 0.42239824294494593, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 571 -------------------\n",
      "average training loss: 0.3909959792919049, training acc: 0.8357348442077637\n",
      "validation loss: 0.41632904448816854, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 572 -------------------\n",
      "average training loss: 0.38198066166567185, training acc: 0.8314120769500732\n",
      "validation loss: 0.4174331118983607, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 573 -------------------\n",
      "average training loss: 0.38083989761061215, training acc: 0.8354467153549194\n",
      "validation loss: 0.41993764303796305, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 574 -------------------\n",
      "average training loss: 0.3743900363486507, training acc: 0.8345821499824524\n",
      "validation loss: 0.4225482286945466, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 575 -------------------\n",
      "average training loss: 0.3799375263517803, training acc: 0.8273774981498718\n",
      "validation loss: 0.4218595960447865, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 576 -------------------\n",
      "average training loss: 0.39017137596517887, training acc: 0.8244956731796265\n",
      "validation loss: 0.42525445687056684, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 577 -------------------\n",
      "average training loss: 0.392279253655277, training acc: 0.8259366154670715\n",
      "validation loss: 0.42533373187214546, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 578 -------------------\n",
      "average training loss: 0.3859372193772099, training acc: 0.8285302519798279\n",
      "validation loss: 0.43038219584298026, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 579 -------------------\n",
      "average training loss: 0.38179536509926104, training acc: 0.8293948173522949\n",
      "validation loss: 0.42410955107706483, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 580 -------------------\n",
      "average training loss: 0.38210696655322907, training acc: 0.8345821499824524\n",
      "validation loss: 0.4173689597213323, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 581 -------------------\n",
      "average training loss: 0.3778644968178499, training acc: 0.8363112211227417\n",
      "validation loss: 0.4186394060811689, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 582 -------------------\n",
      "average training loss: 0.39015088325275127, training acc: 0.8256484270095825\n",
      "validation loss: 0.4198794680806349, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 583 -------------------\n",
      "average training loss: 0.3770853987172976, training acc: 0.831123948097229\n",
      "validation loss: 0.4280683149665182, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 584 -------------------\n",
      "average training loss: 0.3792127675384884, training acc: 0.830547571182251\n",
      "validation loss: 0.4195226969257478, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 585 -------------------\n",
      "average training loss: 0.39317929782510147, training acc: 0.8250720500946045\n",
      "validation loss: 0.4204106303404004, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 586 -------------------\n",
      "average training loss: 0.38360842751494745, training acc: 0.8276656866073608\n",
      "validation loss: 0.42339603142804266, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 587 -------------------\n",
      "average training loss: 0.37862465761236913, training acc: 0.830547571182251\n",
      "validation loss: 0.42616722166263565, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 588 -------------------\n",
      "average training loss: 0.3794040295163905, training acc: 0.81902015209198\n",
      "validation loss: 0.42186833389343753, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 589 -------------------\n",
      "average training loss: 0.37838136615602014, training acc: 0.8273774981498718\n",
      "validation loss: 0.4195088996865233, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 590 -------------------\n",
      "average training loss: 0.3873555708944969, training acc: 0.8250720500946045\n",
      "validation loss: 0.4225741714101783, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 591 -------------------\n",
      "average training loss: 0.37807487429734266, training acc: 0.829971194267273\n",
      "validation loss: 0.4296342141342603, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 592 -------------------\n",
      "average training loss: 0.3858490551067704, training acc: 0.8268011808395386\n",
      "validation loss: 0.41975012998427114, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 593 -------------------\n",
      "average training loss: 0.39557208138858896, training acc: 0.8244956731796265\n",
      "validation loss: 0.4202627417403981, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 594 -------------------\n",
      "average training loss: 0.3819895937909997, training acc: 0.8325648307800293\n",
      "validation loss: 0.41884553981816164, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 595 -------------------\n",
      "average training loss: 0.3858145564880426, training acc: 0.829971194267273\n",
      "validation loss: 0.42136784797439925, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 596 -------------------\n",
      "average training loss: 0.37362915839173266, training acc: 0.8389049172401428\n",
      "validation loss: 0.4217474834160871, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 597 -------------------\n",
      "average training loss: 0.38336937660270876, training acc: 0.8285302519798279\n",
      "validation loss: 0.42210508244378225, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 598 -------------------\n",
      "average training loss: 0.3832941847335365, training acc: 0.83083575963974\n",
      "validation loss: 0.4186686694896716, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 599 -------------------\n",
      "average training loss: 0.37537155817839873, training acc: 0.8420749306678772\n",
      "validation loss: 0.4225704461198798, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 600 -------------------\n",
      "average training loss: 0.38160495042629133, training acc: 0.8291066288948059\n",
      "validation loss: 0.4204668152716852, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 601 -------------------\n",
      "average training loss: 0.38665742256627644, training acc: 0.8265129923820496\n",
      "validation loss: 0.4205831679330993, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 602 -------------------\n",
      "average training loss: 0.3789267663653371, training acc: 0.8342939615249634\n",
      "validation loss: 0.4200135807287858, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 603 -------------------\n",
      "average training loss: 0.3788057046939729, training acc: 0.8325648307800293\n",
      "validation loss: 0.4235529649642206, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 604 -------------------\n",
      "average training loss: 0.3735458073938958, training acc: 0.8357348442077637\n",
      "validation loss: 0.42067357224802815, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 605 -------------------\n",
      "average training loss: 0.38624537357851135, training acc: 0.8282420635223389\n",
      "validation loss: 0.42172983096491906, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 606 -------------------\n",
      "average training loss: 0.37987486151522104, training acc: 0.8291066288948059\n",
      "validation loss: 0.41919218010616743, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 607 -------------------\n",
      "average training loss: 0.3732047488950515, training acc: 0.8386167287826538\n",
      "validation loss: 0.41675712710701374, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 608 -------------------\n",
      "average training loss: 0.3802780535619609, training acc: 0.8322766423225403\n",
      "validation loss: 0.42221030318242614, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 609 -------------------\n",
      "average training loss: 0.37579188142454933, training acc: 0.8345821499824524\n",
      "validation loss: 0.42291824032084735, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 610 -------------------\n",
      "average training loss: 0.3735162279619607, training acc: 0.8354467153549194\n",
      "validation loss: 0.42752700618335177, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 611 -------------------\n",
      "average training loss: 0.3744706442617202, training acc: 0.8360230326652527\n",
      "validation loss: 0.41992620855981855, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 612 -------------------\n",
      "average training loss: 0.3762122925660796, training acc: 0.8259366154670715\n",
      "validation loss: 0.4220906427379028, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 613 -------------------\n",
      "average training loss: 0.3757803040553926, training acc: 0.8345821499824524\n",
      "validation loss: 0.42284420448514176, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 614 -------------------\n",
      "average training loss: 0.3845216718633855, training acc: 0.8273774981498718\n",
      "validation loss: 0.4169669995934183, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 615 -------------------\n",
      "average training loss: 0.38051854090319587, training acc: 0.831123948097229\n",
      "validation loss: 0.4234352581511994, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 616 -------------------\n",
      "average training loss: 0.3718678934000411, training acc: 0.8357348442077637\n",
      "validation loss: 0.4200975554330008, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 617 -------------------\n",
      "average training loss: 0.37826156276103745, training acc: 0.8363112211227417\n",
      "validation loss: 0.4182154168181705, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 618 -------------------\n",
      "average training loss: 0.37652217730321524, training acc: 0.8331412076950073\n",
      "validation loss: 0.4165123540410248, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 619 -------------------\n",
      "average training loss: 0.38273836726414023, training acc: 0.8288184404373169\n",
      "validation loss: 0.4145473938109139, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 620 -------------------\n",
      "average training loss: 0.37839570428521213, training acc: 0.831123948097229\n",
      "validation loss: 0.4213714352401171, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 621 -------------------\n",
      "average training loss: 0.3867918310488335, training acc: 0.8291066288948059\n",
      "validation loss: 0.42084321132453356, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 622 -------------------\n",
      "average training loss: 0.38320588501283004, training acc: 0.8270893096923828\n",
      "validation loss: 0.4216103878576085, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 623 -------------------\n",
      "average training loss: 0.380311016407755, training acc: 0.830547571182251\n",
      "validation loss: 0.4188439292567117, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 624 -------------------\n",
      "average training loss: 0.3788601123462149, training acc: 0.8340057730674744\n",
      "validation loss: 0.4160665196757163, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 625 -------------------\n",
      "average training loss: 0.38397665279742965, training acc: 0.8288184404373169\n",
      "validation loss: 0.41656976224090647, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 626 -------------------\n",
      "average training loss: 0.38109759940881205, training acc: 0.8250720500946045\n",
      "validation loss: 0.4171188273188156, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 627 -------------------\n",
      "average training loss: 0.3834350838097784, training acc: 0.831123948097229\n",
      "validation loss: 0.4163311406764017, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 628 -------------------\n",
      "average training loss: 0.37498231487246686, training acc: 0.8348703384399414\n",
      "validation loss: 0.4169742778149618, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 629 -------------------\n",
      "average training loss: 0.37512868197919313, training acc: 0.830547571182251\n",
      "validation loss: 0.4184438300572233, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 630 -------------------\n",
      "average training loss: 0.3797080813721896, training acc: 0.829971194267273\n",
      "validation loss: 0.4208487707623688, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 631 -------------------\n",
      "average training loss: 0.37615170042521673, training acc: 0.8417867422103882\n",
      "validation loss: 0.41386044162759034, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 632 -------------------\n",
      "average training loss: 0.3843673536344633, training acc: 0.8262248039245605\n",
      "validation loss: 0.413724979085307, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 633 -------------------\n",
      "average training loss: 0.3732040628318484, training acc: 0.8293948173522949\n",
      "validation loss: 0.41451066897212085, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 634 -------------------\n",
      "average training loss: 0.38222867985623715, training acc: 0.8270893096923828\n",
      "validation loss: 0.41635686131666333, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 635 -------------------\n",
      "average training loss: 0.38348695326607235, training acc: 0.8319884538650513\n",
      "validation loss: 0.4163053661996868, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 636 -------------------\n",
      "average training loss: 0.3824066927779992, training acc: 0.8285302519798279\n",
      "validation loss: 0.4137082283947325, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 637 -------------------\n",
      "average training loss: 0.38301781187483486, training acc: 0.8291066288948059\n",
      "validation loss: 0.4132468534230087, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 638 -------------------\n",
      "average training loss: 0.37247943976083475, training acc: 0.8426513075828552\n",
      "validation loss: 0.41673886048079634, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 639 -------------------\n",
      "average training loss: 0.3879960401171566, training acc: 0.8262248039245605\n",
      "validation loss: 0.42455193427850574, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 640 -------------------\n",
      "average training loss: 0.380305323253791, training acc: 0.8345821499824524\n",
      "validation loss: 0.41695147519287423, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 641 -------------------\n",
      "average training loss: 0.3724518058451177, training acc: 0.8345821499824524\n",
      "validation loss: 0.4145345702973379, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 642 -------------------\n",
      "average training loss: 0.38689524600072966, training acc: 0.8244956731796265\n",
      "validation loss: 0.4150801537223675, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 643 -------------------\n",
      "average training loss: 0.38299498929070463, training acc: 0.8282420635223389\n",
      "validation loss: 0.4165527977152354, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 644 -------------------\n",
      "average training loss: 0.3775466519233473, training acc: 0.8365994095802307\n",
      "validation loss: 0.4148027100321335, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 645 -------------------\n",
      "average training loss: 0.37484315319432304, training acc: 0.8351585268974304\n",
      "validation loss: 0.4184415400852256, validation acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 646 -------------------\n",
      "average training loss: 0.38303334798867833, training acc: 0.8325648307800293\n",
      "validation loss: 0.418071972609665, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 647 -------------------\n",
      "average training loss: 0.3762501097206424, training acc: 0.8331412076950073\n",
      "validation loss: 0.420121518422931, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 648 -------------------\n",
      "average training loss: 0.3697781308927179, training acc: 0.8394812941551208\n",
      "validation loss: 0.41388611831972677, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 649 -------------------\n",
      "average training loss: 0.3838274758384276, training acc: 0.8291066288948059\n",
      "validation loss: 0.41342673708216937, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 650 -------------------\n",
      "average training loss: 0.37252493888912697, training acc: 0.8351585268974304\n",
      "validation loss: 0.41565283377599055, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 651 -------------------\n",
      "average training loss: 0.3764688036799087, training acc: 0.8317002654075623\n",
      "validation loss: 0.41752716637976156, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 652 -------------------\n",
      "average training loss: 0.3766158473251189, training acc: 0.8360230326652527\n",
      "validation loss: 0.4253311540399279, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 653 -------------------\n",
      "average training loss: 0.370997875963233, training acc: 0.8371757864952087\n",
      "validation loss: 0.4143846474484914, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 654 -------------------\n",
      "average training loss: 0.3729318196045219, training acc: 0.830259382724762\n",
      "validation loss: 0.41895519396127096, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 655 -------------------\n",
      "average training loss: 0.3814933409694292, training acc: 0.830259382724762\n",
      "validation loss: 0.4160879443867415, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 656 -------------------\n",
      "average training loss: 0.3825172319192364, training acc: 0.8389049172401428\n",
      "validation loss: 0.41908217492740824, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 657 -------------------\n",
      "average training loss: 0.37102358521576917, training acc: 0.8432276844978333\n",
      "validation loss: 0.4199915554391624, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 658 -------------------\n",
      "average training loss: 0.3827857270364459, training acc: 0.8293948173522949\n",
      "validation loss: 0.4167206307984717, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 659 -------------------\n",
      "average training loss: 0.37992954881115676, training acc: 0.8273774981498718\n",
      "validation loss: 0.41780007860627594, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 660 -------------------\n",
      "average training loss: 0.37775185500682257, training acc: 0.8328530192375183\n",
      "validation loss: 0.4182490073316108, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 661 -------------------\n",
      "average training loss: 0.374580081034806, training acc: 0.8348703384399414\n",
      "validation loss: 0.41680244092018376, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 662 -------------------\n",
      "average training loss: 0.3804490691389062, training acc: 0.8357348442077637\n",
      "validation loss: 0.4146373499923038, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 663 -------------------\n",
      "average training loss: 0.3764466964374015, training acc: 0.8363112211227417\n",
      "validation loss: 0.41329912504842203, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 664 -------------------\n",
      "average training loss: 0.3793244676648368, training acc: 0.8253602385520935\n",
      "validation loss: 0.4180755203220701, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 665 -------------------\n",
      "average training loss: 0.3754257917060632, training acc: 0.8348703384399414\n",
      "validation loss: 0.41094969233609563, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 666 -------------------\n",
      "average training loss: 0.371768234940702, training acc: 0.8325648307800293\n",
      "validation loss: 0.41237784970191216, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 667 -------------------\n",
      "average training loss: 0.37652134230569734, training acc: 0.8317002654075623\n",
      "validation loss: 0.41950853574111163, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 668 -------------------\n",
      "average training loss: 0.38207034277984664, training acc: 0.8293948173522949\n",
      "validation loss: 0.4225609181663408, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 669 -------------------\n",
      "average training loss: 0.3795951337910523, training acc: 0.8426513075828552\n",
      "validation loss: 0.42059194670844186, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 670 -------------------\n",
      "average training loss: 0.3833316110053049, training acc: 0.8288184404373169\n",
      "validation loss: 0.41629474256445187, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 671 -------------------\n",
      "average training loss: 0.36759836093149545, training acc: 0.8426513075828552\n",
      "validation loss: 0.41744621681727573, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 672 -------------------\n",
      "average training loss: 0.3815937512202634, training acc: 0.830259382724762\n",
      "validation loss: 0.4175841896215342, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 673 -------------------\n",
      "average training loss: 0.37903977976065206, training acc: 0.8334293961524963\n",
      "validation loss: 0.41966288457817746, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 674 -------------------\n",
      "average training loss: 0.36929644806584294, training acc: 0.8368875980377197\n",
      "validation loss: 0.41734620297010044, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 675 -------------------\n",
      "average training loss: 0.375519123870976, training acc: 0.8337175846099854\n",
      "validation loss: 0.4166652999715322, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 676 -------------------\n",
      "average training loss: 0.3763777940864178, training acc: 0.8426513075828552\n",
      "validation loss: 0.4224922269720086, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 677 -------------------\n",
      "average training loss: 0.38063764754221147, training acc: 0.8293948173522949\n",
      "validation loss: 0.42493559976327255, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 678 -------------------\n",
      "average training loss: 0.38042746705005764, training acc: 0.8348703384399414\n",
      "validation loss: 0.4179032285641965, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 679 -------------------\n",
      "average training loss: 0.3836946270651364, training acc: 0.8268011808395386\n",
      "validation loss: 0.4210316913743173, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 680 -------------------\n",
      "average training loss: 0.3744108643071452, training acc: 0.829971194267273\n",
      "validation loss: 0.4147055618773957, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 681 -------------------\n",
      "average training loss: 0.37836362348509794, training acc: 0.83083575963974\n",
      "validation loss: 0.41323105956552214, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 682 -------------------\n",
      "average training loss: 0.37182168349065425, training acc: 0.8391931056976318\n",
      "validation loss: 0.41351684172581965, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 683 -------------------\n",
      "average training loss: 0.36374380410748186, training acc: 0.8423631191253662\n",
      "validation loss: 0.41812825367747364, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 684 -------------------\n",
      "average training loss: 0.38032142483020037, training acc: 0.8348703384399414\n",
      "validation loss: 0.4134611505242537, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 685 -------------------\n",
      "average training loss: 0.374755917038629, training acc: 0.8394812941551208\n",
      "validation loss: 0.4175659280768188, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 686 -------------------\n",
      "average training loss: 0.372073179002454, training acc: 0.8334293961524963\n",
      "validation loss: 0.4168634503942481, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 687 -------------------\n",
      "average training loss: 0.37111423007005917, training acc: 0.8391931056976318\n",
      "validation loss: 0.4146871532437988, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 688 -------------------\n",
      "average training loss: 0.3806281475924621, training acc: 0.831123948097229\n",
      "validation loss: 0.414929996163065, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 689 -------------------\n",
      "average training loss: 0.3784124458729362, training acc: 0.8325648307800293\n",
      "validation loss: 0.4094125650445437, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 690 -------------------\n",
      "average training loss: 0.3768142220609813, training acc: 0.8360230326652527\n",
      "validation loss: 0.4124669506802537, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 691 -------------------\n",
      "average training loss: 0.3768077493229242, training acc: 0.8296830058097839\n",
      "validation loss: 0.415414118547044, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 692 -------------------\n",
      "average training loss: 0.37739301530016256, training acc: 0.8337175846099854\n",
      "validation loss: 0.42359192895999154, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 693 -------------------\n",
      "average training loss: 0.3738173721503112, training acc: 0.8331412076950073\n",
      "validation loss: 0.4150777898625844, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 694 -------------------\n",
      "average training loss: 0.3767588261396809, training acc: 0.8340057730674744\n",
      "validation loss: 0.41702034513247177, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 695 -------------------\n",
      "average training loss: 0.37110685228614365, training acc: 0.8331412076950073\n",
      "validation loss: 0.41623298762031413, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 696 -------------------\n",
      "average training loss: 0.38026566802596495, training acc: 0.8325648307800293\n",
      "validation loss: 0.41812698495003486, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 697 -------------------\n",
      "average training loss: 0.3669281929130169, training acc: 0.8374639749526978\n",
      "validation loss: 0.4205402882967127, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 698 -------------------\n",
      "average training loss: 0.3821632760745991, training acc: 0.8253602385520935\n",
      "validation loss: 0.4209752625309377, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 699 -------------------\n",
      "average training loss: 0.3688574807616407, training acc: 0.8354467153549194\n",
      "validation loss: 0.41815944888075374, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 700 -------------------\n",
      "average training loss: 0.3677140347552231, training acc: 0.8397694230079651\n",
      "validation loss: 0.4225983765268106, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 701 -------------------\n",
      "average training loss: 0.3801795397436928, training acc: 0.8293948173522949\n",
      "validation loss: 0.4185356137939312, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 702 -------------------\n",
      "average training loss: 0.3745051869397892, training acc: 0.830547571182251\n",
      "validation loss: 0.4226532019503106, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 703 -------------------\n",
      "average training loss: 0.38176209926605226, training acc: 0.8291066288948059\n",
      "validation loss: 0.41478524065237443, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 704 -------------------\n",
      "average training loss: 0.37287515851022185, training acc: 0.831123948097229\n",
      "validation loss: 0.4222080685575986, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 705 -------------------\n",
      "average training loss: 0.3630980223932596, training acc: 0.8386167287826538\n",
      "validation loss: 0.42061969624136997, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 706 -------------------\n",
      "average training loss: 0.37088956874110857, training acc: 0.8403457999229431\n",
      "validation loss: 0.4166125787018631, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 707 -------------------\n",
      "average training loss: 0.3751675771189698, training acc: 0.8342939615249634\n",
      "validation loss: 0.4147824566759821, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 708 -------------------\n",
      "average training loss: 0.3785305126427917, training acc: 0.830547571182251\n",
      "validation loss: 0.4157894036736906, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 709 -------------------\n",
      "average training loss: 0.3717159944240229, training acc: 0.83083575963974\n",
      "validation loss: 0.41718665355910906, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 710 -------------------\n",
      "average training loss: 0.36613316767840975, training acc: 0.831123948097229\n",
      "validation loss: 0.42647444776126314, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 711 -------------------\n",
      "average training loss: 0.3812388212175809, training acc: 0.8406339883804321\n",
      "validation loss: 0.4158221090444222, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 712 -------------------\n",
      "average training loss: 0.37391596133324184, training acc: 0.8337175846099854\n",
      "validation loss: 0.4251063813536947, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 713 -------------------\n",
      "average training loss: 0.3741253904547403, training acc: 0.8340057730674744\n",
      "validation loss: 0.41987744344544303, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 714 -------------------\n",
      "average training loss: 0.37792925202537336, training acc: 0.8354467153549194\n",
      "validation loss: 0.42071888633587395, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 715 -------------------\n",
      "average training loss: 0.37846673225463295, training acc: 0.830259382724762\n",
      "validation loss: 0.4164685413310055, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 716 -------------------\n",
      "average training loss: 0.37457123586011554, training acc: 0.8368875980377197\n",
      "validation loss: 0.41432862073045723, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 717 -------------------\n",
      "average training loss: 0.38010619682949626, training acc: 0.8285302519798279\n",
      "validation loss: 0.41907017722657197, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 718 -------------------\n",
      "average training loss: 0.36366001973921697, training acc: 0.8389049172401428\n",
      "validation loss: 0.4202049393807688, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 719 -------------------\n",
      "average training loss: 0.3691753517310283, training acc: 0.8348703384399414\n",
      "validation loss: 0.41564580070258283, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 720 -------------------\n",
      "average training loss: 0.38212333196178294, training acc: 0.8239192962646484\n",
      "validation loss: 0.419159936465426, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 721 -------------------\n",
      "average training loss: 0.36804995928442785, training acc: 0.8458213210105896\n",
      "validation loss: 0.41673295096867646, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 722 -------------------\n",
      "average training loss: 0.3779199344280474, training acc: 0.8371757864952087\n",
      "validation loss: 0.41755325439888213, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 723 -------------------\n",
      "average training loss: 0.3736604684024448, training acc: 0.8342939615249634\n",
      "validation loss: 0.4194059012122967, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 724 -------------------\n",
      "average training loss: 0.3806586161642322, training acc: 0.8282420635223389\n",
      "validation loss: 0.4213897187588951, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 725 -------------------\n",
      "average training loss: 0.3659366276490929, training acc: 0.8394812941551208\n",
      "validation loss: 0.4139995743876778, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 726 -------------------\n",
      "average training loss: 0.379565345279078, training acc: 0.8391931056976318\n",
      "validation loss: 0.41483927899241996, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 727 -------------------\n",
      "average training loss: 0.36832725689115714, training acc: 0.8409221768379211\n",
      "validation loss: 0.41065596820022654, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 728 -------------------\n",
      "average training loss: 0.3677438354028405, training acc: 0.8348703384399414\n",
      "validation loss: 0.4138726045459097, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 729 -------------------\n",
      "average training loss: 0.3739580654273459, training acc: 0.8383285403251648\n",
      "validation loss: 0.4130154133941721, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 730 -------------------\n",
      "average training loss: 0.3640733104961406, training acc: 0.8403457999229431\n",
      "validation loss: 0.41570193124806276, validation acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 731 -------------------\n",
      "average training loss: 0.37703784419926856, training acc: 0.8288184404373169\n",
      "validation loss: 0.4251563290846513, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 732 -------------------\n",
      "average training loss: 0.3673845701842899, training acc: 0.8383285403251648\n",
      "validation loss: 0.4099779030145039, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 733 -------------------\n",
      "average training loss: 0.3786498886020451, training acc: 0.8380403518676758\n",
      "validation loss: 0.41409678983798226, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 734 -------------------\n",
      "average training loss: 0.3715069680461279, training acc: 0.8371757864952087\n",
      "validation loss: 0.41374324488749703, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 735 -------------------\n",
      "average training loss: 0.3715421008273573, training acc: 0.8348703384399414\n",
      "validation loss: 0.40996921941431985, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 736 -------------------\n",
      "average training loss: 0.3630471229037909, training acc: 0.8363112211227417\n",
      "validation loss: 0.4140199545067027, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 737 -------------------\n",
      "average training loss: 0.37700733691883365, training acc: 0.8337175846099854\n",
      "validation loss: 0.41158297424492196, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 738 -------------------\n",
      "average training loss: 0.37835926676346177, training acc: 0.8325648307800293\n",
      "validation loss: 0.41024412111752595, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 739 -------------------\n",
      "average training loss: 0.377278359719587, training acc: 0.8279538750648499\n",
      "validation loss: 0.4096132200983812, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 740 -------------------\n",
      "average training loss: 0.36820654975577805, training acc: 0.8348703384399414\n",
      "validation loss: 0.4115639068014611, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 741 -------------------\n",
      "average training loss: 0.3765561749337386, training acc: 0.8365994095802307\n",
      "validation loss: 0.4107703209472691, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 742 -------------------\n",
      "average training loss: 0.3785562561121729, training acc: 0.8285302519798279\n",
      "validation loss: 0.4165465785061709, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 743 -------------------\n",
      "average training loss: 0.37180569314475703, training acc: 0.8380403518676758\n",
      "validation loss: 0.4134473747097402, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 744 -------------------\n",
      "average training loss: 0.3819938582886193, training acc: 0.8291066288948059\n",
      "validation loss: 0.41584560659623915, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 745 -------------------\n",
      "average training loss: 0.37181538247237633, training acc: 0.8374639749526978\n",
      "validation loss: 0.41398047988865233, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 746 -------------------\n",
      "average training loss: 0.37664039619374345, training acc: 0.8319884538650513\n",
      "validation loss: 0.41338691060444177, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 747 -------------------\n",
      "average training loss: 0.3702074342742777, training acc: 0.8365994095802307\n",
      "validation loss: 0.4132153400078347, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 748 -------------------\n",
      "average training loss: 0.3704053573847161, training acc: 0.8383285403251648\n",
      "validation loss: 0.4156428749934869, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 749 -------------------\n",
      "average training loss: 0.3678904670803279, training acc: 0.8409221768379211\n",
      "validation loss: 0.4136197654882334, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 750 -------------------\n",
      "average training loss: 0.3708190373110153, training acc: 0.8403457999229431\n",
      "validation loss: 0.4131074021763516, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 751 -------------------\n",
      "average training loss: 0.36930419256432945, training acc: 0.8380403518676758\n",
      "validation loss: 0.4165618158705224, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 752 -------------------\n",
      "average training loss: 0.37131036238299325, training acc: 0.8371757864952087\n",
      "validation loss: 0.41513385132710506, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 753 -------------------\n",
      "average training loss: 0.3697563324134357, training acc: 0.8328530192375183\n",
      "validation loss: 0.414100136075701, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 754 -------------------\n",
      "average training loss: 0.36628963239598344, training acc: 0.8394812941551208\n",
      "validation loss: 0.414148455116606, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 755 -------------------\n",
      "average training loss: 0.38282641260012423, training acc: 0.8270893096923828\n",
      "validation loss: 0.4130611127148026, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 756 -------------------\n",
      "average training loss: 0.3723510999844466, training acc: 0.8351585268974304\n",
      "validation loss: 0.4120244755997636, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 757 -------------------\n",
      "average training loss: 0.37078640634886467, training acc: 0.83083575963974\n",
      "validation loss: 0.41072186374444564, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 758 -------------------\n",
      "average training loss: 0.3724552952418753, training acc: 0.8400576114654541\n",
      "validation loss: 0.4168407437713465, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 759 -------------------\n",
      "average training loss: 0.3800317241324471, training acc: 0.8391931056976318\n",
      "validation loss: 0.41255140963787307, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 760 -------------------\n",
      "average training loss: 0.3764710137411222, training acc: 0.8334293961524963\n",
      "validation loss: 0.4128546074788142, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 761 -------------------\n",
      "average training loss: 0.38223276421728325, training acc: 0.8282420635223389\n",
      "validation loss: 0.41093979343291254, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 762 -------------------\n",
      "average training loss: 0.3712957324744645, training acc: 0.8314120769500732\n",
      "validation loss: 0.4124609481903814, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 763 -------------------\n",
      "average training loss: 0.3787110971614332, training acc: 0.8285302519798279\n",
      "validation loss: 0.41516421755887395, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 764 -------------------\n",
      "average training loss: 0.3748681897904069, training acc: 0.8342939615249634\n",
      "validation loss: 0.4160276959019323, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 765 -------------------\n",
      "average training loss: 0.36911927432423025, training acc: 0.8417867422103882\n",
      "validation loss: 0.4134552797414191, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 766 -------------------\n",
      "average training loss: 0.3771003695317579, training acc: 0.8273774981498718\n",
      "validation loss: 0.4106719121680282, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 767 -------------------\n",
      "average training loss: 0.3746579570110662, training acc: 0.8334293961524963\n",
      "validation loss: 0.4166030037787653, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 768 -------------------\n",
      "average training loss: 0.3723047320883968, training acc: 0.8337175846099854\n",
      "validation loss: 0.41557897908896346, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 769 -------------------\n",
      "average training loss: 0.3762694631254982, training acc: 0.8293948173522949\n",
      "validation loss: 0.41573806113911116, validation acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 770 -------------------\n",
      "average training loss: 0.3703411024740175, training acc: 0.8391931056976318\n",
      "validation loss: 0.42744437313299577, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 771 -------------------\n",
      "average training loss: 0.3684244034785015, training acc: 0.8340057730674744\n",
      "validation loss: 0.4134112589644946, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 772 -------------------\n",
      "average training loss: 0.36615091438595776, training acc: 0.8420749306678772\n",
      "validation loss: 0.4199865430181477, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 773 -------------------\n",
      "average training loss: 0.3705021773703847, training acc: 0.830547571182251\n",
      "validation loss: 0.4140365075680517, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 774 -------------------\n",
      "average training loss: 0.36988000376767316, training acc: 0.8357348442077637\n",
      "validation loss: 0.41652620841281207, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 775 -------------------\n",
      "average training loss: 0.3742496911489998, training acc: 0.8337175846099854\n",
      "validation loss: 0.4143661873131853, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 776 -------------------\n",
      "average training loss: 0.3717862226433988, training acc: 0.8337175846099854\n",
      "validation loss: 0.4154352827280897, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 777 -------------------\n",
      "average training loss: 0.3644962307355589, training acc: 0.8383285403251648\n",
      "validation loss: 0.4144269745745417, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 778 -------------------\n",
      "average training loss: 0.3738508716955652, training acc: 0.8360230326652527\n",
      "validation loss: 0.41636153780919616, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 779 -------------------\n",
      "average training loss: 0.37134857449133046, training acc: 0.8363112211227417\n",
      "validation loss: 0.41212263950554456, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 780 -------------------\n",
      "average training loss: 0.36859764178479437, training acc: 0.8340057730674744\n",
      "validation loss: 0.41949134447058223, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 781 -------------------\n",
      "average training loss: 0.3707119859347082, training acc: 0.8340057730674744\n",
      "validation loss: 0.4115432382728647, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 782 -------------------\n",
      "average training loss: 0.3737218447308719, training acc: 0.8317002654075623\n",
      "validation loss: 0.4153627403046129, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 783 -------------------\n",
      "average training loss: 0.3649483185336638, training acc: 0.8334293961524963\n",
      "validation loss: 0.4193519726738952, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 784 -------------------\n",
      "average training loss: 0.36763163688203443, training acc: 0.8400576114654541\n",
      "validation loss: 0.41412513843879173, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 785 -------------------\n",
      "average training loss: 0.37232394457206947, training acc: 0.831123948097229\n",
      "validation loss: 0.4148551233902505, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 786 -------------------\n",
      "average training loss: 0.3741288562329427, training acc: 0.8325648307800293\n",
      "validation loss: 0.4134735322218337, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 787 -------------------\n",
      "average training loss: 0.3679515577530655, training acc: 0.8345821499824524\n",
      "validation loss: 0.41673112602277834, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 788 -------------------\n",
      "average training loss: 0.3773996214358195, training acc: 0.8342939615249634\n",
      "validation loss: 0.42177861544393724, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 789 -------------------\n",
      "average training loss: 0.37329786284169136, training acc: 0.8363112211227417\n",
      "validation loss: 0.4159459268442497, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 790 -------------------\n",
      "average training loss: 0.37078295054628113, training acc: 0.8354467153549194\n",
      "validation loss: 0.4134954764134324, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 791 -------------------\n",
      "average training loss: 0.36364588151747623, training acc: 0.8432276844978333\n",
      "validation loss: 0.41338641193055886, validation acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 792 -------------------\n",
      "average training loss: 0.3721777115414397, training acc: 0.8389049172401428\n",
      "validation loss: 0.4153655049163625, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 793 -------------------\n",
      "average training loss: 0.375598303187821, training acc: 0.8322766423225403\n",
      "validation loss: 0.4210889516612901, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 794 -------------------\n",
      "average training loss: 0.3660536236137753, training acc: 0.8368875980377197\n",
      "validation loss: 0.4162328327031729, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 795 -------------------\n",
      "average training loss: 0.36976776538733447, training acc: 0.8348703384399414\n",
      "validation loss: 0.4183985680204383, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 796 -------------------\n",
      "average training loss: 0.36529504751265907, training acc: 0.8406339883804321\n",
      "validation loss: 0.4148764803936954, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 797 -------------------\n",
      "average training loss: 0.3672475970615915, training acc: 0.8386167287826538\n",
      "validation loss: 0.41299427599401517, validation acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 798 -------------------\n",
      "average training loss: 0.3794201069417536, training acc: 0.83083575963974\n",
      "validation loss: 0.41686780840021126, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 799 -------------------\n",
      "average training loss: 0.3715501186998846, training acc: 0.8429394960403442\n",
      "validation loss: 0.41602257704405193, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 800 -------------------\n",
      "average training loss: 0.37026349232244904, training acc: 0.8365994095802307\n",
      "validation loss: 0.41744107310123707, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 801 -------------------\n",
      "average training loss: 0.3648763224096051, training acc: 0.8386167287826538\n",
      "validation loss: 0.418633688430083, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 802 -------------------\n",
      "average training loss: 0.3722782881871424, training acc: 0.8371757864952087\n",
      "validation loss: 0.41810236026614495, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 803 -------------------\n",
      "average training loss: 0.36057264079965157, training acc: 0.8412103652954102\n",
      "validation loss: 0.41741402069544464, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 804 -------------------\n",
      "average training loss: 0.36540911190791503, training acc: 0.8432276844978333\n",
      "validation loss: 0.41917880943843294, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 805 -------------------\n",
      "average training loss: 0.3655599607514373, training acc: 0.8368875980377197\n",
      "validation loss: 0.41533833714674145, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 806 -------------------\n",
      "average training loss: 0.37110424420503785, training acc: 0.8377521634101868\n",
      "validation loss: 0.4132831398792531, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 807 -------------------\n",
      "average training loss: 0.3694564248539872, training acc: 0.8400576114654541\n",
      "validation loss: 0.41827756578471803, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 808 -------------------\n",
      "average training loss: 0.36576215073423357, training acc: 0.8383285403251648\n",
      "validation loss: 0.41495173331779267, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 809 -------------------\n",
      "average training loss: 0.3665046675576257, training acc: 0.8368875980377197\n",
      "validation loss: 0.4141844629142691, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 810 -------------------\n",
      "average training loss: 0.3710302379014513, training acc: 0.8394812941551208\n",
      "validation loss: 0.41311980777072466, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 811 -------------------\n",
      "average training loss: 0.37184913146392756, training acc: 0.829971194267273\n",
      "validation loss: 0.41831710893437607, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 812 -------------------\n",
      "average training loss: 0.3643754397586031, training acc: 0.8365994095802307\n",
      "validation loss: 0.41407566521024924, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 813 -------------------\n",
      "average training loss: 0.36242878004178536, training acc: 0.8481268286705017\n",
      "validation loss: 0.41858673095703125, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 814 -------------------\n",
      "average training loss: 0.3688924663090912, training acc: 0.8389049172401428\n",
      "validation loss: 0.42362967737808754, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 815 -------------------\n",
      "average training loss: 0.36771657876563, training acc: 0.8446685671806335\n",
      "validation loss: 0.4127297433015938, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 816 -------------------\n",
      "average training loss: 0.37013426271055205, training acc: 0.8363112211227417\n",
      "validation loss: 0.41300297882150394, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 817 -------------------\n",
      "average training loss: 0.35979628618752924, training acc: 0.8397694230079651\n",
      "validation loss: 0.4109327515698798, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 818 -------------------\n",
      "average training loss: 0.37013329147261914, training acc: 0.8345821499824524\n",
      "validation loss: 0.4121641033256109, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 819 -------------------\n",
      "average training loss: 0.36504235161140947, training acc: 0.8438040614128113\n",
      "validation loss: 0.4146485564895489, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 820 -------------------\n",
      "average training loss: 0.3596193878382702, training acc: 0.8414985537528992\n",
      "validation loss: 0.41927785107067655, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 821 -------------------\n",
      "average training loss: 0.3727500920508712, training acc: 0.8319884538650513\n",
      "validation loss: 0.41484459946232455, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 822 -------------------\n",
      "average training loss: 0.36680382077906937, training acc: 0.8386167287826538\n",
      "validation loss: 0.4168693268079362, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 823 -------------------\n",
      "average training loss: 0.3604662203221912, training acc: 0.8429394960403442\n",
      "validation loss: 0.41489587415198576, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 824 -------------------\n",
      "average training loss: 0.3620542104374778, training acc: 0.8371757864952087\n",
      "validation loss: 0.4202075983796801, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 825 -------------------\n",
      "average training loss: 0.36525218331332854, training acc: 0.8389049172401428\n",
      "validation loss: 0.41530944482522075, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 826 -------------------\n",
      "average training loss: 0.37254629399659656, training acc: 0.8426513075828552\n",
      "validation loss: 0.41864657978857717, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 827 -------------------\n",
      "average training loss: 0.3688224097321975, training acc: 0.8414985537528992\n",
      "validation loss: 0.4199705987756703, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 828 -------------------\n",
      "average training loss: 0.3674041301269696, training acc: 0.8371757864952087\n",
      "validation loss: 0.4175620672340217, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 829 -------------------\n",
      "average training loss: 0.37387042749855637, training acc: 0.8354467153549194\n",
      "validation loss: 0.41423236073986175, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 830 -------------------\n",
      "average training loss: 0.36566544487771796, training acc: 0.8389049172401428\n",
      "validation loss: 0.4131034344846752, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 831 -------------------\n",
      "average training loss: 0.3700100512944312, training acc: 0.8406339883804321\n",
      "validation loss: 0.4219550982048984, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 832 -------------------\n",
      "average training loss: 0.3729967537891624, training acc: 0.8391931056976318\n",
      "validation loss: 0.4172046533378039, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 833 -------------------\n",
      "average training loss: 0.3711471770785384, training acc: 0.8334293961524963\n",
      "validation loss: 0.42409797019672835, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 834 -------------------\n",
      "average training loss: 0.36599614730142377, training acc: 0.8368875980377197\n",
      "validation loss: 0.4122289892989919, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 835 -------------------\n",
      "average training loss: 0.36185122307508066, training acc: 0.8406339883804321\n",
      "validation loss: 0.41298570006673785, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 836 -------------------\n",
      "average training loss: 0.36524742599523036, training acc: 0.8394812941551208\n",
      "validation loss: 0.41528361664939034, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 837 -------------------\n",
      "average training loss: 0.37340668773101454, training acc: 0.8371757864952087\n",
      "validation loss: 0.4162791154351652, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 838 -------------------\n",
      "average training loss: 0.37327037041400285, training acc: 0.8273774981498718\n",
      "validation loss: 0.4222252482917452, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 839 -------------------\n",
      "average training loss: 0.37053582211392755, training acc: 0.8380403518676758\n",
      "validation loss: 0.4135812444071616, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 840 -------------------\n",
      "average training loss: 0.3593118447391719, training acc: 0.8463976979255676\n",
      "validation loss: 0.4114913781117734, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 841 -------------------\n",
      "average training loss: 0.3656223909827406, training acc: 0.8371757864952087\n",
      "validation loss: 0.4121547838509907, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 842 -------------------\n",
      "average training loss: 0.36130169733113443, training acc: 0.8423631191253662\n",
      "validation loss: 0.41656124893970753, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 843 -------------------\n",
      "average training loss: 0.3721990344503771, training acc: 0.8331412076950073\n",
      "validation loss: 0.4126602386549321, validation acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 844 -------------------\n",
      "average training loss: 0.36726818359550895, training acc: 0.8409221768379211\n",
      "validation loss: 0.4158790829818919, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 845 -------------------\n",
      "average training loss: 0.36489464003345806, training acc: 0.8325648307800293\n",
      "validation loss: 0.41412537053982784, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 846 -------------------\n",
      "average training loss: 0.36054349392223084, training acc: 0.8409221768379211\n",
      "validation loss: 0.41577138425567733, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 847 -------------------\n",
      "average training loss: 0.35973426948706766, training acc: 0.8426513075828552\n",
      "validation loss: 0.4206454385810184, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 848 -------------------\n",
      "average training loss: 0.3718180673696122, training acc: 0.8363112211227417\n",
      "validation loss: 0.4154322503074523, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 849 -------------------\n",
      "average training loss: 0.3672628413359782, training acc: 0.8383285403251648\n",
      "validation loss: 0.4118900527053165, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 850 -------------------\n",
      "average training loss: 0.3745952295982185, training acc: 0.8365994095802307\n",
      "validation loss: 0.4167071759426099, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 851 -------------------\n",
      "average training loss: 0.3742868204797036, training acc: 0.8354467153549194\n",
      "validation loss: 0.4169041757484735, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 852 -------------------\n",
      "average training loss: 0.3614529809793753, training acc: 0.8412103652954102\n",
      "validation loss: 0.4135586608390105, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 853 -------------------\n",
      "average training loss: 0.3729965659486457, training acc: 0.8319884538650513\n",
      "validation loss: 0.41227105122557434, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 854 -------------------\n",
      "average training loss: 0.36104297567513216, training acc: 0.8446685671806335\n",
      "validation loss: 0.41641778921202033, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 855 -------------------\n",
      "average training loss: 0.37438406891025794, training acc: 0.8293948173522949\n",
      "validation loss: 0.4108862201189665, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 856 -------------------\n",
      "average training loss: 0.3626274249825079, training acc: 0.8371757864952087\n",
      "validation loss: 0.41064746176592215, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 857 -------------------\n",
      "average training loss: 0.36951564686099114, training acc: 0.8432276844978333\n",
      "validation loss: 0.40992886679513113, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 858 -------------------\n",
      "average training loss: 0.3661469532536498, training acc: 0.8438040614128113\n",
      "validation loss: 0.40987708862476085, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 859 -------------------\n",
      "average training loss: 0.3694354589373646, training acc: 0.8403457999229431\n",
      "validation loss: 0.4168062063131464, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 860 -------------------\n",
      "average training loss: 0.3555957803636875, training acc: 0.8429394960403442\n",
      "validation loss: 0.4123144560420568, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 861 -------------------\n",
      "average training loss: 0.3659781043055422, training acc: 0.8409221768379211\n",
      "validation loss: 0.4141237190516863, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 862 -------------------\n",
      "average training loss: 0.35686288000183763, training acc: 0.848991334438324\n",
      "validation loss: 0.41524700264227554, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 863 -------------------\n",
      "average training loss: 0.3628386821801793, training acc: 0.8432276844978333\n",
      "validation loss: 0.4134044921892579, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 864 -------------------\n",
      "average training loss: 0.36225578104728234, training acc: 0.8426513075828552\n",
      "validation loss: 0.4201231189587149, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 865 -------------------\n",
      "average training loss: 0.36072120626996507, training acc: 0.848414957523346\n",
      "validation loss: 0.416403995543581, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 866 -------------------\n",
      "average training loss: 0.3612506444756511, training acc: 0.8435158729553223\n",
      "validation loss: 0.41848025014323575, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 867 -------------------\n",
      "average training loss: 0.3622542856663723, training acc: 0.8446685671806335\n",
      "validation loss: 0.4138871200623051, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 868 -------------------\n",
      "average training loss: 0.36508204845942405, training acc: 0.8423631191253662\n",
      "validation loss: 0.41402395296206673, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 869 -------------------\n",
      "average training loss: 0.36430000910154337, training acc: 0.8374639749526978\n",
      "validation loss: 0.42584120389503266, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 870 -------------------\n",
      "average training loss: 0.3700269109233999, training acc: 0.8435158729553223\n",
      "validation loss: 0.4161152471595096, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 871 -------------------\n",
      "average training loss: 0.36351468297693157, training acc: 0.8391931056976318\n",
      "validation loss: 0.41400291526921884, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 872 -------------------\n",
      "average training loss: 0.36337358929238334, training acc: 0.8380403518676758\n",
      "validation loss: 0.41591686532244704, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 873 -------------------\n",
      "average training loss: 0.3636751679419097, training acc: 0.8412103652954102\n",
      "validation loss: 0.4114965856899314, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 874 -------------------\n",
      "average training loss: 0.3626645000592432, training acc: 0.8371757864952087\n",
      "validation loss: 0.41270194089357753, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 875 -------------------\n",
      "average training loss: 0.36596038772668205, training acc: 0.8438040614128113\n",
      "validation loss: 0.41215213487774544, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 876 -------------------\n",
      "average training loss: 0.3665439367466083, training acc: 0.8386167287826538\n",
      "validation loss: 0.4127006786210196, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 877 -------------------\n",
      "average training loss: 0.3746589186383943, training acc: 0.8328530192375183\n",
      "validation loss: 0.4122576875620723, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 878 -------------------\n",
      "average training loss: 0.36224616691255435, training acc: 0.8368875980377197\n",
      "validation loss: 0.4262537662334706, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 879 -------------------\n",
      "average training loss: 0.3713188105598307, training acc: 0.8389049172401428\n",
      "validation loss: 0.4153855176565285, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 880 -------------------\n",
      "average training loss: 0.3740447582532075, training acc: 0.8371757864952087\n",
      "validation loss: 0.41549995994787614, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 881 -------------------\n",
      "average training loss: 0.3690299802108182, training acc: 0.8377521634101868\n",
      "validation loss: 0.42460462602052823, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 882 -------------------\n",
      "average training loss: 0.3615347285092049, training acc: 0.8374639749526978\n",
      "validation loss: 0.4157190465707383, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 883 -------------------\n",
      "average training loss: 0.373318650193448, training acc: 0.8342939615249634\n",
      "validation loss: 0.41691344248534346, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 884 -------------------\n",
      "average training loss: 0.3680181018385489, training acc: 0.8360230326652527\n",
      "validation loss: 0.41615531397854677, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 885 -------------------\n",
      "average training loss: 0.36422271723362487, training acc: 0.8435158729553223\n",
      "validation loss: 0.4163004867217508, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 886 -------------------\n",
      "average training loss: 0.3770250160343709, training acc: 0.8340057730674744\n",
      "validation loss: 0.41253239864028546, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 887 -------------------\n",
      "average training loss: 0.36063211364430037, training acc: 0.8403457999229431\n",
      "validation loss: 0.42811068068451597, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 888 -------------------\n",
      "average training loss: 0.36403799642747003, training acc: 0.8469740748405457\n",
      "validation loss: 0.41790052204637484, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 889 -------------------\n",
      "average training loss: 0.368808606017907, training acc: 0.8394812941551208\n",
      "validation loss: 0.4159711861665348, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 890 -------------------\n",
      "average training loss: 0.3645578252135505, training acc: 0.8368875980377197\n",
      "validation loss: 0.40931781316133137, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 891 -------------------\n",
      "average training loss: 0.35891848436693635, training acc: 0.8461095094680786\n",
      "validation loss: 0.4116669766913911, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 892 -------------------\n",
      "average training loss: 0.36945793572866953, training acc: 0.8317002654075623\n",
      "validation loss: 0.4142961616065645, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 893 -------------------\n",
      "average training loss: 0.3640005160992702, training acc: 0.8383285403251648\n",
      "validation loss: 0.41288645174096805, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 894 -------------------\n",
      "average training loss: 0.3668157628015414, training acc: 0.8328530192375183\n",
      "validation loss: 0.41334647379712575, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 895 -------------------\n",
      "average training loss: 0.3662758615587218, training acc: 0.8417867422103882\n",
      "validation loss: 0.41253517245367377, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 896 -------------------\n",
      "average training loss: 0.3627213194493945, training acc: 0.8400576114654541\n",
      "validation loss: 0.4120493078012071, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 897 -------------------\n",
      "average training loss: 0.3676804512309753, training acc: 0.8386167287826538\n",
      "validation loss: 0.4091860742612918, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 898 -------------------\n",
      "average training loss: 0.37190919740055756, training acc: 0.8296830058097839\n",
      "validation loss: 0.4100092865080328, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 899 -------------------\n",
      "average training loss: 0.35856666319308433, training acc: 0.8446685671806335\n",
      "validation loss: 0.4125839232849086, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 900 -------------------\n",
      "average training loss: 0.3630857197111553, training acc: 0.8374639749526978\n",
      "validation loss: 0.4100107779975311, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 901 -------------------\n",
      "average training loss: 0.35962389068576034, training acc: 0.8443803787231445\n",
      "validation loss: 0.4120154187151913, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 902 -------------------\n",
      "average training loss: 0.3633375795842591, training acc: 0.8455331325531006\n",
      "validation loss: 0.4111350923089937, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 903 -------------------\n",
      "average training loss: 0.36542802130111013, training acc: 0.8463976979255676\n",
      "validation loss: 0.4175706667834163, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 904 -------------------\n",
      "average training loss: 0.3659550232055895, training acc: 0.8371757864952087\n",
      "validation loss: 0.40956773337680624, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 905 -------------------\n",
      "average training loss: 0.3639908790073065, training acc: 0.8426513075828552\n",
      "validation loss: 0.4128999127770349, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 906 -------------------\n",
      "average training loss: 0.36300442849181225, training acc: 0.8412103652954102\n",
      "validation loss: 0.4077572984629512, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 907 -------------------\n",
      "average training loss: 0.366677183101775, training acc: 0.8377521634101868\n",
      "validation loss: 0.41078761673193376, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 908 -------------------\n",
      "average training loss: 0.3649837544740792, training acc: 0.8368875980377197\n",
      "validation loss: 0.4095854834752149, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 909 -------------------\n",
      "average training loss: 0.36856271365190446, training acc: 0.8397694230079651\n",
      "validation loss: 0.4119223107665365, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 910 -------------------\n",
      "average training loss: 0.3635208365638936, training acc: 0.8435158729553223\n",
      "validation loss: 0.4122560083316768, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 911 -------------------\n",
      "average training loss: 0.3645209507571174, training acc: 0.8342939615249634\n",
      "validation loss: 0.41403040331080215, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 912 -------------------\n",
      "average training loss: 0.36159148179316725, training acc: 0.8440921902656555\n",
      "validation loss: 0.41234112966994535, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 913 -------------------\n",
      "average training loss: 0.3713573169983086, training acc: 0.8377521634101868\n",
      "validation loss: 0.41724606744155357, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 914 -------------------\n",
      "average training loss: 0.36704803198919517, training acc: 0.8389049172401428\n",
      "validation loss: 0.414328602052504, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 915 -------------------\n",
      "average training loss: 0.3726407909427665, training acc: 0.8342939615249634\n",
      "validation loss: 0.4138706812660815, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 916 -------------------\n",
      "average training loss: 0.3582652089746953, training acc: 0.8463976979255676\n",
      "validation loss: 0.4088015760968907, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 917 -------------------\n",
      "average training loss: 0.36163580496647857, training acc: 0.8406339883804321\n",
      "validation loss: 0.41296922103051215, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 918 -------------------\n",
      "average training loss: 0.3546723231286755, training acc: 0.8443803787231445\n",
      "validation loss: 0.42002389192031825, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 919 -------------------\n",
      "average training loss: 0.36355826413253545, training acc: 0.8417867422103882\n",
      "validation loss: 0.42090725486729, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 920 -------------------\n",
      "average training loss: 0.37167923512307643, training acc: 0.8322766423225403\n",
      "validation loss: 0.4303965591889922, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 921 -------------------\n",
      "average training loss: 0.3707335601622502, training acc: 0.8293948173522949\n",
      "validation loss: 0.4155482711605213, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 922 -------------------\n",
      "average training loss: 0.3697185686926333, training acc: 0.8365994095802307\n",
      "validation loss: 0.4219200469656474, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 923 -------------------\n",
      "average training loss: 0.365491162115971, training acc: 0.8426513075828552\n",
      "validation loss: 0.4110287680603941, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 924 -------------------\n",
      "average training loss: 0.36408941865997974, training acc: 0.8397694230079651\n",
      "validation loss: 0.4107312516133357, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 925 -------------------\n",
      "average training loss: 0.37049807019810854, training acc: 0.8397694230079651\n",
      "validation loss: 0.4115427553928393, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 926 -------------------\n",
      "average training loss: 0.36324381254591925, training acc: 0.8409221768379211\n",
      "validation loss: 0.41554150012780994, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 927 -------------------\n",
      "average training loss: 0.3703580569808696, training acc: 0.8391931056976318\n",
      "validation loss: 0.41332049578565605, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 928 -------------------\n",
      "average training loss: 0.36973297010237616, training acc: 0.8377521634101868\n",
      "validation loss: 0.4107234635935401, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 929 -------------------\n",
      "average training loss: 0.36354763987084976, training acc: 0.8357348442077637\n",
      "validation loss: 0.4108279891277788, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 930 -------------------\n",
      "average training loss: 0.3648530186081482, training acc: 0.8400576114654541\n",
      "validation loss: 0.4302432819994913, validation acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 931 -------------------\n",
      "average training loss: 0.3623237609004425, training acc: 0.8409221768379211\n",
      "validation loss: 0.4132367796886901, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 932 -------------------\n",
      "average training loss: 0.35593761194508083, training acc: 0.8461095094680786\n",
      "validation loss: 0.41168857101471196, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 933 -------------------\n",
      "average training loss: 0.3668873486326476, training acc: 0.8374639749526978\n",
      "validation loss: 0.41458450539320846, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 934 -------------------\n",
      "average training loss: 0.36750231548413764, training acc: 0.8383285403251648\n",
      "validation loss: 0.41977732068932, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 935 -------------------\n",
      "average training loss: 0.3647332802629608, training acc: 0.8368875980377197\n",
      "validation loss: 0.41854480417093376, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 936 -------------------\n",
      "average training loss: 0.3578903381693947, training acc: 0.8389049172401428\n",
      "validation loss: 0.4122789559825774, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 937 -------------------\n",
      "average training loss: 0.3641179853110904, training acc: 0.8414985537528992\n",
      "validation loss: 0.42410233191081453, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 938 -------------------\n",
      "average training loss: 0.365228536888227, training acc: 0.8389049172401428\n",
      "validation loss: 0.4247479052862264, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 939 -------------------\n",
      "average training loss: 0.36913682338311965, training acc: 0.8386167287826538\n",
      "validation loss: 0.408666106413037, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 940 -------------------\n",
      "average training loss: 0.3605285402505473, training acc: 0.8394812941551208\n",
      "validation loss: 0.4120494351134322, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 941 -------------------\n",
      "average training loss: 0.36740499101042406, training acc: 0.8432276844978333\n",
      "validation loss: 0.4115645705554892, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 942 -------------------\n",
      "average training loss: 0.3617062579657915, training acc: 0.8368875980377197\n",
      "validation loss: 0.42056178936760547, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 943 -------------------\n",
      "average training loss: 0.3512478264247306, training acc: 0.8446685671806335\n",
      "validation loss: 0.4301133014364726, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 944 -------------------\n",
      "average training loss: 0.3688680233117139, training acc: 0.8409221768379211\n",
      "validation loss: 0.4188549699871221, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 945 -------------------\n",
      "average training loss: 0.35862248806170155, training acc: 0.8417867422103882\n",
      "validation loss: 0.42087801796500035, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 946 -------------------\n",
      "average training loss: 0.3693269754177555, training acc: 0.8351585268974304\n",
      "validation loss: 0.41074669264977975, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 947 -------------------\n",
      "average training loss: 0.37167380569819414, training acc: 0.8360230326652527\n",
      "validation loss: 0.41332976005044403, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 948 -------------------\n",
      "average training loss: 0.37233007786425115, training acc: 0.8400576114654541\n",
      "validation loss: 0.4134043102165521, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 949 -------------------\n",
      "average training loss: 0.3614339784861298, training acc: 0.8406339883804321\n",
      "validation loss: 0.41374212256225024, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 950 -------------------\n",
      "average training loss: 0.35369852302912674, training acc: 0.8455331325531006\n",
      "validation loss: 0.44253170325459423, validation acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 951 -------------------\n",
      "average training loss: 0.3632844532944627, training acc: 0.8400576114654541\n",
      "validation loss: 0.4122268748448192, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 952 -------------------\n",
      "average training loss: 0.36319163697597273, training acc: 0.8354467153549194\n",
      "validation loss: 0.4113358712416091, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 953 -------------------\n",
      "average training loss: 0.35796789981274507, training acc: 0.8371757864952087\n",
      "validation loss: 0.41079442237379366, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 954 -------------------\n",
      "average training loss: 0.35682486680467806, training acc: 0.8412103652954102\n",
      "validation loss: 0.41140962100248735, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 955 -------------------\n",
      "average training loss: 0.3642685746081624, training acc: 0.8394812941551208\n",
      "validation loss: 0.4129593983498587, validation acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 956 -------------------\n",
      "average training loss: 0.35869551519152065, training acc: 0.8429394960403442\n",
      "validation loss: 0.4141810155958624, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 957 -------------------\n",
      "average training loss: 0.364016574157418, training acc: 0.8443803787231445\n",
      "validation loss: 0.41527453490665983, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 958 -------------------\n",
      "average training loss: 0.3671831457690478, training acc: 0.8386167287826538\n",
      "validation loss: 0.40711906469912024, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 959 -------------------\n",
      "average training loss: 0.3653996237073233, training acc: 0.8389049172401428\n",
      "validation loss: 0.4112059458884226, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 960 -------------------\n",
      "average training loss: 0.36360697750571136, training acc: 0.8389049172401428\n",
      "validation loss: 0.41944270062556466, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 961 -------------------\n",
      "average training loss: 0.3678490591152257, training acc: 0.8400576114654541\n",
      "validation loss: 0.4072965457692124, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 962 -------------------\n",
      "average training loss: 0.3657244572378373, training acc: 0.8365994095802307\n",
      "validation loss: 0.42154289006088186, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 963 -------------------\n",
      "average training loss: 0.359987766607007, training acc: 0.8429394960403442\n",
      "validation loss: 0.41199751946783286, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 964 -------------------\n",
      "average training loss: 0.36227646911522154, training acc: 0.8420749306678772\n",
      "validation loss: 0.408711516088055, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 965 -------------------\n",
      "average training loss: 0.35806666519009756, training acc: 0.85014408826828\n",
      "validation loss: 0.41924820435211957, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 966 -------------------\n",
      "average training loss: 0.38349763417793625, training acc: 0.8273774981498718\n",
      "validation loss: 0.41085438080097675, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 967 -------------------\n",
      "average training loss: 0.3674013495960565, training acc: 0.8394812941551208\n",
      "validation loss: 0.41009309942821204, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 968 -------------------\n",
      "average training loss: 0.3611559191595237, training acc: 0.8406339883804321\n",
      "validation loss: 0.40887198497622795, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 969 -------------------\n",
      "average training loss: 0.35979425991302955, training acc: 0.8386167287826538\n",
      "validation loss: 0.4151918231616921, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 970 -------------------\n",
      "average training loss: 0.36867449189125634, training acc: 0.8383285403251648\n",
      "validation loss: 0.4069616338624383, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 971 -------------------\n",
      "average training loss: 0.361655375095197, training acc: 0.8377521634101868\n",
      "validation loss: 0.41221812820654313, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 972 -------------------\n",
      "average training loss: 0.36678551634725304, training acc: 0.8403457999229431\n",
      "validation loss: 0.41645855123546266, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 973 -------------------\n",
      "average training loss: 0.3665842190599579, training acc: 0.8420749306678772\n",
      "validation loss: 0.41867303765863867, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 974 -------------------\n",
      "average training loss: 0.3646533129709942, training acc: 0.8423631191253662\n",
      "validation loss: 0.4111415676532253, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 975 -------------------\n",
      "average training loss: 0.35710642454603564, training acc: 0.8461095094680786\n",
      "validation loss: 0.41242557283370723, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 976 -------------------\n",
      "average training loss: 0.3607371715716051, training acc: 0.8440921902656555\n",
      "validation loss: 0.4073000510442092, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 977 -------------------\n",
      "average training loss: 0.35283515634557355, training acc: 0.8533141016960144\n",
      "validation loss: 0.4080804175770228, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 978 -------------------\n",
      "average training loss: 0.35678013327829433, training acc: 0.8438040614128113\n",
      "validation loss: 0.41042125005326513, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 979 -------------------\n",
      "average training loss: 0.3557677554809394, training acc: 0.8409221768379211\n",
      "validation loss: 0.409984053279947, validation acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 980 -------------------\n",
      "average training loss: 0.3631565345810882, training acc: 0.8403457999229431\n",
      "validation loss: 0.41519577808094466, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 981 -------------------\n",
      "average training loss: 0.3695616058726132, training acc: 0.8406339883804321\n",
      "validation loss: 0.41553156592878876, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 982 -------------------\n",
      "average training loss: 0.36245561001623744, training acc: 0.8458213210105896\n",
      "validation loss: 0.40868705566028296, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 983 -------------------\n",
      "average training loss: 0.36209602740724767, training acc: 0.8386167287826538\n",
      "validation loss: 0.41420208336570846, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 984 -------------------\n",
      "average training loss: 0.361268416210279, training acc: 0.8377521634101868\n",
      "validation loss: 0.4074673388960175, validation acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 985 -------------------\n",
      "average training loss: 0.3606096952724182, training acc: 0.8403457999229431\n",
      "validation loss: 0.4098976796947866, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 986 -------------------\n",
      "average training loss: 0.36224151969986623, training acc: 0.8420749306678772\n",
      "validation loss: 0.4143811329718559, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 987 -------------------\n",
      "average training loss: 0.36875465362834653, training acc: 0.8340057730674744\n",
      "validation loss: 0.4090462292669006, validation acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 988 -------------------\n",
      "average training loss: 0.35949498609094865, training acc: 0.8455331325531006\n",
      "validation loss: 0.4074336150274848, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 989 -------------------\n",
      "average training loss: 0.3608897731524036, training acc: 0.8391931056976318\n",
      "validation loss: 0.41674635542153216, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 990 -------------------\n",
      "average training loss: 0.36053938934370144, training acc: 0.8391931056976318\n",
      "validation loss: 0.43583644205524075, validation acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 991 -------------------\n",
      "average training loss: 0.357137397687442, training acc: 0.8472622632980347\n",
      "validation loss: 0.41137595495320683, validation acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 992 -------------------\n",
      "average training loss: 0.352874435540235, training acc: 0.8458213210105896\n",
      "validation loss: 0.4079005344672137, validation acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 993 -------------------\n",
      "average training loss: 0.3592265141113347, training acc: 0.8429394960403442\n",
      "validation loss: 0.4097244787600733, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 994 -------------------\n",
      "average training loss: 0.3613211848120868, training acc: 0.8432276844978333\n",
      "validation loss: 0.4049504608053216, validation acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 995 -------------------\n",
      "average training loss: 0.3597308358386889, training acc: 0.8426513075828552\n",
      "validation loss: 0.41326977113424906, validation acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 996 -------------------\n",
      "average training loss: 0.36507245058285054, training acc: 0.8342939615249634\n",
      "validation loss: 0.4107197424233784, validation acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 997 -------------------\n",
      "average training loss: 0.35848259750635547, training acc: 0.8351585268974304\n",
      "validation loss: 0.4106125469031971, validation acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 998 -------------------\n",
      "average training loss: 0.3682191321674616, training acc: 0.8351585268974304\n",
      "validation loss: 0.4116364216200218, validation acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 999 -------------------\n",
      "average training loss: 0.3652828272464296, training acc: 0.8363112211227417\n",
      "validation loss: 0.41255646696837817, validation acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 1000 -------------------\n",
      "average training loss: 0.3610486856626846, training acc: 0.8371757864952087\n",
      "validation loss: 0.4178546965122223, validation acc: 0.8294931054115295\n",
      "highest validation accuracy: 0.843317985534668 in epoch 238\n"
     ]
    }
   ],
   "source": [
    "gnn = networks.GraphGNN(features = train_dataset[0].x.shape[1], labels=2)       # temp.y.shape[0] is wrong!!! TODO: how do I get #labels from loader?? take from loader.dataset? Store with dataset\n",
    "\n",
    "# Applies xavier to nn.Linear. GraphConv weight init done in network\n",
    "gnn.apply(weights_init)\n",
    "\n",
    "gnn_optimizer = torch.optim.Adam(params = gnn.parameters(), lr = learning_rate_gnn)         # TODO: understand params\n",
    "\n",
    "print(f\"Training on {len(train_loader.dataset)} graphs with batch size {batch_size}\")\n",
    "\n",
    "early_stop_counter = 0\n",
    "min_val_loss = 1000.0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(0, epochs_gnn) :\n",
    "    print(f'\\n------------------ EPOCH {epoch + 1} -------------------')\n",
    "\n",
    "    gnn.train()\n",
    "\n",
    "    train_acc_sum = 0\n",
    "    num_batches = 0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        batch_size_ratio = len(data)/batch_size\n",
    "        num_batches += batch_size_ratio\n",
    "        \n",
    "        gnn_optimizer.zero_grad()       # Reset parameters\n",
    "\n",
    "        # get model embeddings (node representations)?\n",
    "        out = gnn.forward(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        # calc cross entropy(???)loss between real label and predicted label\n",
    "        # needs to be calculated across batch\n",
    "        currLoss = loss(out, data.y)\n",
    "\n",
    "        # loss backward\n",
    "        currLoss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(gnn.parameters(), max_norm=2)    # clip gradient above 2(for ba2motfis according to reimplementation) to stop \"overlearning\"?\n",
    "\n",
    "        # optimizer step\n",
    "        gnn_optimizer.step()\n",
    "\n",
    "        # predicted labels\n",
    "        preds = out.argmax(dim=1)\n",
    "        train_acc_sum += torch.sum(preds == data.y)                         # DONE: works with batches?\n",
    "        \n",
    "        train_loss += batch_size_ratio * currLoss.item()                    # use currLoss.item() instead of currLoss for numeric value\n",
    "\n",
    "    final_train_acc = train_acc_sum/(num_batches*batch_size)                # num_batches*batch_size = len(train_loader.dataset) = #graphs\n",
    "\n",
    "    gnn.eval()\n",
    "\n",
    "    # avg loss\n",
    "    print(f\"average training loss: {train_loss/num_batches}, training acc: {final_train_acc}\")\n",
    "\n",
    "    train_losses.append(train_loss/num_batches)\n",
    "    train_accuracies.append(final_train_acc)\n",
    "\n",
    "    val_acc, valLoss = evaluation.evaluateGraphGNN(gnn, val_loader)\n",
    "    \n",
    "    print(f\"validation loss: {valLoss}, validation acc: {val_acc}\")\n",
    "\n",
    "    val_losses.append(valLoss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    if(val_acc > best_val_acc):\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "    if(valLoss < min_val_loss):\n",
    "        min_val_loss = valLoss\n",
    "        early_stop_counter = 0\n",
    "    elif(valLoss > min_val_loss):\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stopping:\n",
    "            print(\"Stopping training due to early stopping threshold\")\n",
    "            break\n",
    "              \n",
    "print(f\"highest validation accuracy: {best_val_acc} in epoch {best_epoch}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCNConv instead of GraphConv\n",
    "average training loss: 0.3523677970215635, training acc: 0.8458213210105896\n",
    "validation loss: 0.47687009828431265, validation acc: 0.7921478152275085, test loss: 0.5093637616952993, test acc: 0.7695852518081665\n",
    "highest validation accuracy: 0.8152424693107605 in epoch 452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "Does not safe training/validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gnn.state_dict(), f\"models/MUTAG SAGEConv 82 test 83 val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn = networks.GraphGNN(features = train_dataset[0].x.shape[1], labels=2)\n",
    "gnn.load_state_dict(torch.load(\"models/MUTAG 86 highest val\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate test accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.2740898952404291, test acc: 0.8891454935073853\n"
     ]
    }
   ],
   "source": [
    "gnn.eval()\n",
    "\n",
    "test_acc, testLoss = evaluation.evaluateGraphGNN(gnn, test_loader)\n",
    "print(f\"test loss: {testLoss}, test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining, validation and test accuracy over epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_accuracies, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_accuracies, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mtest_acc, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_accuracies' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#   Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training, validation and test losses over epochs\")\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"validation\")\n",
    "plt.axhline(y=testLoss, linestyle='dashed', color = \"green\", label = \"test\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#   Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training, validation and test accuracy over epochs\")\n",
    "plt.plot(train_accuracies, label=\"train\")\n",
    "plt.plot(val_accuracies, label=\"validation\")\n",
    "plt.axhline(y=test_acc, linestyle='dashed', color = \"green\", label = \"test\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(edge_index=[2, 50], y=[25], edge_mask=[50], node_mask=[25], x=[25, 1])\n",
      "<torch.utils.data.dataset.ConcatDataset object at 0x0000023792843E60>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2,\n",
      "        3])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2,\n",
      "        3])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ExplainerDataset\n",
    "from torch_geometric.datasets.graph_generator import BAGraph\n",
    "from torch_geometric.datasets.motif_generator import HouseMotif\n",
    "from torch_geometric.datasets.motif_generator import CycleMotif\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset1 = ExplainerDataset(\n",
    "            graph_generator=BAGraph(20, 1),\n",
    "            motif_generator=HouseMotif(),\n",
    "            num_motifs=1,\n",
    "            num_graphs=400,\n",
    "            transform=T.Constant()      # appends value 1 node feature for every node\n",
    "        )\n",
    "\n",
    "dataset2 = ExplainerDataset(\n",
    "            graph_generator=BAGraph(20, 1),\n",
    "            motif_generator=CycleMotif(5),\n",
    "            num_motifs=1,\n",
    "            num_graphs=400,\n",
    "            transform=T.Constant()\n",
    "        )\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset([dataset1, dataset2])\n",
    "\n",
    "print(dataset[0])\n",
    "\n",
    "print(dataset)\n",
    "dataset[0].y = torch.tensor([0])\n",
    "\n",
    "print(dataset[0].y)\n",
    "\n",
    "train_loader = DataLoader(dataset1, batch_size = 1, shuffle = True)\n",
    "\n",
    "print(next(iter(train_loader)).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = ExplainerDataset(\n",
    "            graph_generator=BAGraph(20, 1),\n",
    "            motif_generator=HouseMotif(),\n",
    "            num_motifs=1,\n",
    "            num_graphs=1\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(edge_index=[2, 40], y=[23], edge_mask=[40], node_mask=[23])\n",
      "tensor([[ 0,  0,  0,  0,  0,  1,  1,  2,  3,  3,  3,  3,  5,  5,  5,  6,  7,  7,\n",
      "          8,  9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 21, 21,\n",
      "         22, 22,  4, 22],\n",
      "        [ 1,  5, 10, 17, 18,  0, 14,  6,  8,  9, 11, 16,  0,  7, 13,  2,  5, 19,\n",
      "          3,  3,  0,  3, 12, 15, 11,  5,  1, 11,  3,  0,  0,  7, 21, 22, 20, 22,\n",
      "         20, 21, 22,  4]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset1[0])\n",
    "print(dataset1[0].edge_index)\n",
    "g = torch_geometric.utils.to_networkx(dataset1[0], to_undirected=True)\n",
    "\n",
    "colors = []\n",
    "\n",
    "for i, j in enumerate(dataset1[0].y):\n",
    "    colors.append([j.item()])\n",
    "\n",
    "nx.draw(g, node_color = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1:\n",
      "9\n",
      "3\n",
      "5\n",
      "Set 2:\n",
      "2\n",
      "6\n",
      "4\n",
      "8\n",
      "7\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "generator2 = torch.Generator().manual_seed(42)\n",
    "set1, set2 = torch.utils.data.random_split(range(10), [3, 7])\n",
    "set3, set4, set5 = torch.utils.data.random_split(range(30), [0.3, 0.3, 0.4])\n",
    "\n",
    "print(\"Set 1:\")\n",
    "print(set1[0])\n",
    "print(set1[1])\n",
    "print(set1[2])\n",
    "print(\"Set 2:\")\n",
    "print(set2[0])\n",
    "print(set2[1])\n",
    "print(set2[2])\n",
    "print(set2[3])\n",
    "print(set2[4])\n",
    "print(set2[5])\n",
    "print(set2[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
