{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from 'c:\\\\Users\\\\trist\\\\Git_repos\\\\BT-ML-PGESAT\\\\code\\\\PGExplainer\\\\evaluation.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "import networks\n",
    "import datasetLoader\n",
    "import evaluation\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importlib.reload(datasetLoader)\n",
    "importlib.reload(networks)\n",
    "importlib.reload(evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64                 # 64 used for Graphs in PGE (PGExplainer/codes/forgraph/config.py)      1 takes forever in current model\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_gnn = 0.001        #0.001 on ADAM\n",
    "epochs_gnn = 1000\n",
    "early_stopping = 500\n",
    "\n",
    "\n",
    "learning_rate_mlp = 0.003        #0.003 on ADAM\n",
    "coefficientSizeReg = 0.05\n",
    "entropyReg = 1\n",
    "epochs_mlp = 30\n",
    "\n",
    "temperature =  0        #???\n",
    "\n",
    "\n",
    "# TODO: Xavier initialization (torch.nn.init.xavier_uniform_(tensor, gain=1.0, generator=None) or torch.nn.init.xavier_normal_(tensor, gain=1.0, generator=None))\n",
    "# lr scheduler? => not used in orig\n",
    "# softmax after linear layer?       -> check code\n",
    "\n",
    "# DONE: dropout     NOT USED IN OG\n",
    "# DONE: early stopping with validation set\n",
    "\n",
    "# cross validation?!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(module):\n",
    "    # TODO: GraphConv has no attribute weight!!\n",
    "    #if isinstance(module, gnn.GraphConv):\n",
    "    #    nn.init.xavier_normal_(module.weight.data)\n",
    "    #    if module.bias is not None:\n",
    "     #       nn.init.xavier_normal_(module.bias.data)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_normal_(module.weight.data)\n",
    "        #if module.bias is not None:            TODO: This does not work either\n",
    "        #    nn.init.xavier_normal_(module.bias.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop GraphGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3470 graphs with batch size 64\n",
      "\n",
      "------------------ EPOCH 1 -------------------\n",
      "average training loss: 0.6657513978501906, training acc: 0.5812680125236511\n",
      "validation loss: 0.6298005177128699, validation acc: 0.6096997857093811, test loss: 0.6109024220347954, test acc: 0.6221198439598083\n",
      "\n",
      "------------------ EPOCH 2 -------------------\n",
      "average training loss: 0.6205855575693444, training acc: 0.6524495482444763\n",
      "validation loss: 0.5869775555924885, validation acc: 0.6859122514724731, test loss: 0.562876262697756, test acc: 0.7096773982048035\n",
      "\n",
      "------------------ EPOCH 3 -------------------\n",
      "average training loss: 0.588515118357084, training acc: 0.6878962516784668\n",
      "validation loss: 0.5572813193094895, validation acc: 0.6882216930389404, test loss: 0.5370394480393229, test acc: 0.7027649879455566\n",
      "\n",
      "------------------ EPOCH 4 -------------------\n",
      "average training loss: 0.5658357291812512, training acc: 0.7020173072814941\n",
      "validation loss: 0.5395018528408718, validation acc: 0.7344110608100891, test loss: 0.5200816571437819, test acc: 0.7626727819442749\n",
      "\n",
      "------------------ EPOCH 5 -------------------\n",
      "average training loss: 0.5548821809999538, training acc: 0.7247838377952576\n",
      "validation loss: 0.520603332102024, validation acc: 0.7321016192436218, test loss: 0.5109414631320585, test acc: 0.7396313548088074\n",
      "\n",
      "------------------ EPOCH 6 -------------------\n",
      "average training loss: 0.5408587770778095, training acc: 0.7268011569976807\n",
      "validation loss: 0.514972385173569, validation acc: 0.7598152160644531, test loss: 0.5080446504777477, test acc: 0.764976978302002\n",
      "\n",
      "------------------ EPOCH 7 -------------------\n",
      "average training loss: 0.5361977700884816, training acc: 0.729971170425415\n",
      "validation loss: 0.5109593961645381, validation acc: 0.7228637337684631, test loss: 0.5135788975223419, test acc: 0.7373272180557251\n",
      "\n",
      "------------------ EPOCH 8 -------------------\n",
      "average training loss: 0.527183042445169, training acc: 0.7507204413414001\n",
      "validation loss: 0.49643888808615194, validation acc: 0.7690531015396118, test loss: 0.49335403678603984, test acc: 0.7626727819442749\n",
      "\n",
      "------------------ EPOCH 9 -------------------\n",
      "average training loss: 0.5198291798489925, training acc: 0.7432276606559753\n",
      "validation loss: 0.49180043732515677, validation acc: 0.7575057744979858, test loss: 0.4924636704306449, test acc: 0.7626727819442749\n",
      "\n",
      "------------------ EPOCH 10 -------------------\n",
      "average training loss: 0.5141671150493347, training acc: 0.7495677471160889\n",
      "validation loss: 0.4960411380512923, validation acc: 0.7852193713188171, test loss: 0.4983189807784173, test acc: 0.7857142686843872\n",
      "\n",
      "------------------ EPOCH 11 -------------------\n",
      "average training loss: 0.5156501037243121, training acc: 0.7489913702011108\n",
      "validation loss: 0.48432799748011995, validation acc: 0.7598152160644531, test loss: 0.48494186187120075, test acc: 0.7926267385482788\n",
      "\n",
      "------------------ EPOCH 12 -------------------\n",
      "average training loss: 0.5151368359667423, training acc: 0.7570605278015137\n",
      "validation loss: 0.48160558719239477, validation acc: 0.7528868317604065, test loss: 0.4808872251466672, test acc: 0.7695852518081665\n",
      "\n",
      "------------------ EPOCH 13 -------------------\n",
      "average training loss: 0.5000677557087769, training acc: 0.7610951066017151\n",
      "validation loss: 0.4761508111305501, validation acc: 0.7898383140563965, test loss: 0.48069077070956956, test acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 14 -------------------\n",
      "average training loss: 0.5105859406743338, training acc: 0.7515850067138672\n",
      "validation loss: 0.46841101952686837, validation acc: 0.7736720442771912, test loss: 0.47196102719153127, test acc: 0.7926267385482788\n",
      "\n",
      "------------------ EPOCH 15 -------------------\n",
      "average training loss: 0.49240518368630315, training acc: 0.770317018032074\n",
      "validation loss: 0.4629947251987897, validation acc: 0.7944572567939758, test loss: 0.4672540236727983, test acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 16 -------------------\n",
      "average training loss: 0.49218908026170316, training acc: 0.7688760757446289\n",
      "validation loss: 0.4665439759943342, validation acc: 0.8036951422691345, test loss: 0.4725981150079982, test acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 17 -------------------\n",
      "average training loss: 0.49484083867210477, training acc: 0.7625360488891602\n",
      "validation loss: 0.4545021725277747, validation acc: 0.7967667579650879, test loss: 0.4635004763779003, test acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 18 -------------------\n",
      "average training loss: 0.4847799435644397, training acc: 0.7740634083747864\n",
      "validation loss: 0.4516133336427574, validation acc: 0.7829099297523499, test loss: 0.4598322073984805, test acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 19 -------------------\n",
      "average training loss: 0.48626116096801647, training acc: 0.7723342776298523\n",
      "validation loss: 0.44925547023797363, validation acc: 0.7921478152275085, test loss: 0.460292655064763, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 20 -------------------\n",
      "average training loss: 0.4821634777169406, training acc: 0.7729106545448303\n",
      "validation loss: 0.44903617383148264, validation acc: 0.7852193713188171, test loss: 0.45814364283315595, test acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 21 -------------------\n",
      "average training loss: 0.476098698600912, training acc: 0.7769452333450317\n",
      "validation loss: 0.44389389750594915, validation acc: 0.8036951422691345, test loss: 0.45041945233323055, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 22 -------------------\n",
      "average training loss: 0.4775137627330912, training acc: 0.7798271179199219\n",
      "validation loss: 0.4413154296885987, validation acc: 0.8152424693107605, test loss: 0.4510427294513597, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 23 -------------------\n",
      "average training loss: 0.4727633296928076, training acc: 0.7809798121452332\n",
      "validation loss: 0.4418180756579896, validation acc: 0.8106235861778259, test loss: 0.4529278787874406, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 24 -------------------\n",
      "average training loss: 0.46708081156788367, training acc: 0.7907781004905701\n",
      "validation loss: 0.43846692591218905, validation acc: 0.8036951422691345, test loss: 0.44922255467159955, test acc: 0.8064516186714172\n",
      "\n",
      "------------------ EPOCH 25 -------------------\n",
      "average training loss: 0.4668862167627736, training acc: 0.7876080870628357\n",
      "validation loss: 0.43773489297809687, validation acc: 0.8175519704818726, test loss: 0.45249200073255375, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 26 -------------------\n",
      "average training loss: 0.47393464887520076, training acc: 0.7795389294624329\n",
      "validation loss: 0.4529509797760968, validation acc: 0.8083140850067139, test loss: 0.4706573865380705, test acc: 0.8018433451652527\n",
      "\n",
      "------------------ EPOCH 27 -------------------\n",
      "average training loss: 0.47474720579402935, training acc: 0.7772334218025208\n",
      "validation loss: 0.4448054049696241, validation acc: 0.8152424693107605, test loss: 0.45254657153160344, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 28 -------------------\n",
      "average training loss: 0.46688937491573584, training acc: 0.7870317101478577\n",
      "validation loss: 0.43135790540600705, validation acc: 0.8221709132194519, test loss: 0.4439467956668221, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 29 -------------------\n",
      "average training loss: 0.46642405225838984, training acc: 0.7861671447753906\n",
      "validation loss: 0.4330333929320085, validation acc: 0.8013857007026672, test loss: 0.44147978784851216, test acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 30 -------------------\n",
      "average training loss: 0.46368997181183325, training acc: 0.7841498851776123\n",
      "validation loss: 0.4293091823840471, validation acc: 0.8106235861778259, test loss: 0.44384589296881505, test acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 31 -------------------\n",
      "average training loss: 0.46135212004356496, training acc: 0.7858789563179016\n",
      "validation loss: 0.4302075431780881, validation acc: 0.8175519704818726, test loss: 0.4448807501847843, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 32 -------------------\n",
      "average training loss: 0.4735072440647598, training acc: 0.7838616967201233\n",
      "validation loss: 0.43868293273284137, validation acc: 0.7852193713188171, test loss: 0.456566813354668, test acc: 0.7995391488075256\n",
      "\n",
      "------------------ EPOCH 33 -------------------\n",
      "average training loss: 0.4604397693697245, training acc: 0.7838616967201233\n",
      "validation loss: 0.4346089026620311, validation acc: 0.8175519704818726, test loss: 0.44980968459410603, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 34 -------------------\n",
      "average training loss: 0.4596730454854388, training acc: 0.7876080870628357\n",
      "validation loss: 0.4395085933021686, validation acc: 0.8152424693107605, test loss: 0.4552165448390943, test acc: 0.804147481918335\n",
      "\n",
      "------------------ EPOCH 35 -------------------\n",
      "average training loss: 0.4570008761601077, training acc: 0.7881844639778137\n",
      "validation loss: 0.4352820097438751, validation acc: 0.8152424693107605, test loss: 0.4444289320075567, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 36 -------------------\n",
      "average training loss: 0.46208618171620436, training acc: 0.7870317101478577\n",
      "validation loss: 0.4277105681632521, validation acc: 0.8152424693107605, test loss: 0.4355398123989457, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 37 -------------------\n",
      "average training loss: 0.45725687635735063, training acc: 0.789337158203125\n",
      "validation loss: 0.42384778395775824, validation acc: 0.8221709132194519, test loss: 0.4361077056777093, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 38 -------------------\n",
      "average training loss: 0.4512290736440279, training acc: 0.7971181273460388\n",
      "validation loss: 0.4242787480628985, validation acc: 0.8290992975234985, test loss: 0.4356328765368132, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 39 -------------------\n",
      "average training loss: 0.4554377632800715, training acc: 0.7873198986053467\n",
      "validation loss: 0.42059148655783746, validation acc: 0.8221709132194519, test loss: 0.43008376129211917, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 40 -------------------\n",
      "average training loss: 0.4451365316635594, training acc: 0.8023054599761963\n",
      "validation loss: 0.42361344348999763, validation acc: 0.7944572567939758, test loss: 0.42994218268152756, test acc: 0.8087557554244995\n",
      "\n",
      "------------------ EPOCH 41 -------------------\n",
      "average training loss: 0.441794136553058, training acc: 0.7991354465484619\n",
      "validation loss: 0.4187373575252322, validation acc: 0.8337182402610779, test loss: 0.43183100978899663, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 42 -------------------\n",
      "average training loss: 0.44813209253360625, training acc: 0.7956772446632385\n",
      "validation loss: 0.41882513593968157, validation acc: 0.8198614120483398, test loss: 0.4214933072367022, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 43 -------------------\n",
      "average training loss: 0.44740873454970653, training acc: 0.7873198986053467\n",
      "validation loss: 0.41727367215167543, validation acc: 0.8036951422691345, test loss: 0.42555942554627696, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 44 -------------------\n",
      "average training loss: 0.44604395267255714, training acc: 0.7956772446632385\n",
      "validation loss: 0.4145166764061572, validation acc: 0.8175519704818726, test loss: 0.4276324321048051, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 45 -------------------\n",
      "average training loss: 0.4433375517298234, training acc: 0.7994236350059509\n",
      "validation loss: 0.413074595793601, validation acc: 0.8290992975234985, test loss: 0.4273642478725328, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 46 -------------------\n",
      "average training loss: 0.440177473211151, training acc: 0.7925072312355042\n",
      "validation loss: 0.41067188415109834, validation acc: 0.8406466245651245, test loss: 0.42609976994277143, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 47 -------------------\n",
      "average training loss: 0.4375716941672718, training acc: 0.801152765750885\n",
      "validation loss: 0.41026836537545724, validation acc: 0.8267898559570312, test loss: 0.4201335812219277, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 48 -------------------\n",
      "average training loss: 0.4451055237814054, training acc: 0.7942363023757935\n",
      "validation loss: 0.4086804685916769, validation acc: 0.8337182402610779, test loss: 0.4251310145525339, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 49 -------------------\n",
      "average training loss: 0.4375221786478411, training acc: 0.7913544774055481\n",
      "validation loss: 0.40896167547746737, validation acc: 0.8337182402610779, test loss: 0.42437672024498335, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 50 -------------------\n",
      "average training loss: 0.4303063341794852, training acc: 0.8037464022636414\n",
      "validation loss: 0.40759353786020236, validation acc: 0.8360277414321899, test loss: 0.41917969746523737, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 51 -------------------\n",
      "average training loss: 0.43511998648258726, training acc: 0.8069164156913757\n",
      "validation loss: 0.4087673573312671, validation acc: 0.8383371829986572, test loss: 0.42551861627860005, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 52 -------------------\n",
      "average training loss: 0.4443631913888695, training acc: 0.7971181273460388\n",
      "validation loss: 0.4125188178455775, validation acc: 0.8290992975234985, test loss: 0.42866831798157934, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 53 -------------------\n",
      "average training loss: 0.44087457254915485, training acc: 0.7988472580909729\n",
      "validation loss: 0.40979934342995217, validation acc: 0.8383371829986572, test loss: 0.42654339426673504, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 54 -------------------\n",
      "average training loss: 0.43092405096941794, training acc: 0.801152765750885\n",
      "validation loss: 0.40391358176958725, validation acc: 0.8175519704818726, test loss: 0.416826594397769, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 55 -------------------\n",
      "average training loss: 0.4338498870474461, training acc: 0.8057636618614197\n",
      "validation loss: 0.40930399470340273, validation acc: 0.8152424693107605, test loss: 0.4188458442962664, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 56 -------------------\n",
      "average training loss: 0.42898267431973724, training acc: 0.8037464022636414\n",
      "validation loss: 0.42748888255813705, validation acc: 0.7782909870147705, test loss: 0.4335638581333072, test acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 57 -------------------\n",
      "average training loss: 0.42910936885333545, training acc: 0.8028818368911743\n",
      "validation loss: 0.40791054894023226, validation acc: 0.8360277414321899, test loss: 0.41719077987604974, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 58 -------------------\n",
      "average training loss: 0.4379578798236352, training acc: 0.7956772446632385\n",
      "validation loss: 0.4075808727658839, validation acc: 0.8290992975234985, test loss: 0.4190621005225291, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 59 -------------------\n",
      "average training loss: 0.4326551683526218, training acc: 0.800288200378418\n",
      "validation loss: 0.4033171918397675, validation acc: 0.8452655673027039, test loss: 0.4229229349419818, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 60 -------------------\n",
      "average training loss: 0.4314452981742727, training acc: 0.800288200378418\n",
      "validation loss: 0.41355830204376975, validation acc: 0.8290992975234985, test loss: 0.42535779360801945, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 61 -------------------\n",
      "average training loss: 0.42883894206467554, training acc: 0.8115273714065552\n",
      "validation loss: 0.4022443006115575, validation acc: 0.8360277414321899, test loss: 0.41192891026422174, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 62 -------------------\n",
      "average training loss: 0.4269362276500515, training acc: 0.8051873445510864\n",
      "validation loss: 0.40573793292594945, validation acc: 0.8383371829986572, test loss: 0.4167351081349333, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 63 -------------------\n",
      "average training loss: 0.4307370850778794, training acc: 0.8025936484336853\n",
      "validation loss: 0.3990693132860869, validation acc: 0.8475750684738159, test loss: 0.4089988662350562, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 64 -------------------\n",
      "average training loss: 0.426909468136191, training acc: 0.8121037483215332\n",
      "validation loss: 0.39665914728619533, validation acc: 0.8452655673027039, test loss: 0.41371145679654064, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 65 -------------------\n",
      "average training loss: 0.4287659676686488, training acc: 0.8089337348937988\n",
      "validation loss: 0.41362614050713553, validation acc: 0.8290992975234985, test loss: 0.42222648447010375, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 66 -------------------\n",
      "average training loss: 0.42402047757113015, training acc: 0.8103746175765991\n",
      "validation loss: 0.4047875501867813, validation acc: 0.8360277414321899, test loss: 0.4100704620236076, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 67 -------------------\n",
      "average training loss: 0.42341778414050163, training acc: 0.8069164156913757\n",
      "validation loss: 0.39992753893548993, validation acc: 0.8267898559570312, test loss: 0.40526594063653376, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 68 -------------------\n",
      "average training loss: 0.4274668152462852, training acc: 0.8089337348937988\n",
      "validation loss: 0.39675638464189344, validation acc: 0.8429561257362366, test loss: 0.40679887170615836, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 69 -------------------\n",
      "average training loss: 0.4189962393096957, training acc: 0.8109509944915771\n",
      "validation loss: 0.3952019194029443, validation acc: 0.8452655673027039, test loss: 0.4070254764798599, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 70 -------------------\n",
      "average training loss: 0.42288011738477593, training acc: 0.8069164156913757\n",
      "validation loss: 0.40271620074724823, validation acc: 0.8429561257362366, test loss: 0.41928855944339033, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 71 -------------------\n",
      "average training loss: 0.42067871535202267, training acc: 0.8126801252365112\n",
      "validation loss: 0.4048437075818189, validation acc: 0.8360277414321899, test loss: 0.4216883665955012, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 72 -------------------\n",
      "average training loss: 0.43073591708449877, training acc: 0.8054755330085754\n",
      "validation loss: 0.39761230219069715, validation acc: 0.8429561257362366, test loss: 0.40352862757471847, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 73 -------------------\n",
      "average training loss: 0.4097932840458598, training acc: 0.8141210079193115\n",
      "validation loss: 0.390744599054486, validation acc: 0.8360277414321899, test loss: 0.40523988351843876, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 74 -------------------\n",
      "average training loss: 0.42072323696414055, training acc: 0.8118155598640442\n",
      "validation loss: 0.3985892741636197, validation acc: 0.8244803547859192, test loss: 0.4118637042935543, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 75 -------------------\n",
      "average training loss: 0.4227167384768769, training acc: 0.8060518503189087\n",
      "validation loss: 0.3948833255723874, validation acc: 0.8452655673027039, test loss: 0.4107380426973791, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 76 -------------------\n",
      "average training loss: 0.41194060068652677, training acc: 0.8141210079193115\n",
      "validation loss: 0.39437243486604384, validation acc: 0.8360277414321899, test loss: 0.40353406848995366, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 77 -------------------\n",
      "average training loss: 0.4183451095472495, training acc: 0.8080691695213318\n",
      "validation loss: 0.39399643729908673, validation acc: 0.8383371829986572, test loss: 0.40658664854440824, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 78 -------------------\n",
      "average training loss: 0.41710825885407177, training acc: 0.8129683136940002\n",
      "validation loss: 0.4101550853060138, validation acc: 0.8429561257362366, test loss: 0.4263452530456578, test acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 79 -------------------\n",
      "average training loss: 0.42011956347512236, training acc: 0.8100864291191101\n",
      "validation loss: 0.395248821391488, validation acc: 0.8175519704818726, test loss: 0.40246424120142715, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 80 -------------------\n",
      "average training loss: 0.42020221151604775, training acc: 0.8155619502067566\n",
      "validation loss: 0.3923040565944487, validation acc: 0.8290992975234985, test loss: 0.4046539256374957, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 81 -------------------\n",
      "average training loss: 0.4168707233856322, training acc: 0.8126801252365112\n",
      "validation loss: 0.4109108835321418, validation acc: 0.8452655673027039, test loss: 0.43015559999624153, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 82 -------------------\n",
      "average training loss: 0.4109537854661859, training acc: 0.8118155598640442\n",
      "validation loss: 0.39487325012134517, validation acc: 0.8337182402610779, test loss: 0.40725524647993977, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 83 -------------------\n",
      "average training loss: 0.42040379229471386, training acc: 0.8063400387763977\n",
      "validation loss: 0.4019066306852525, validation acc: 0.8429561257362366, test loss: 0.4215583882298887, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 84 -------------------\n",
      "average training loss: 0.41133611851535545, training acc: 0.8175792694091797\n",
      "validation loss: 0.4030559183815108, validation acc: 0.8406466245651245, test loss: 0.40830894439451154, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 85 -------------------\n",
      "average training loss: 0.4111905470361627, training acc: 0.818731963634491\n",
      "validation loss: 0.3946478459554883, validation acc: 0.8383371829986572, test loss: 0.40446300056123513, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 86 -------------------\n",
      "average training loss: 0.40875053647959264, training acc: 0.820461094379425\n",
      "validation loss: 0.40377851826254674, validation acc: 0.8452655673027039, test loss: 0.4185407355359073, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 87 -------------------\n",
      "average training loss: 0.4129198534687933, training acc: 0.8224784135818481\n",
      "validation loss: 0.3962135365756426, validation acc: 0.8475750684738159, test loss: 0.40719688872587845, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 88 -------------------\n",
      "average training loss: 0.40872584555609426, training acc: 0.8167147040367126\n",
      "validation loss: 0.38736452258402304, validation acc: 0.8314087986946106, test loss: 0.40226098153448325, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 89 -------------------\n",
      "average training loss: 0.4102648742947867, training acc: 0.8126801252365112\n",
      "validation loss: 0.3872766965819943, validation acc: 0.8337182402610779, test loss: 0.40414487972237545, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 90 -------------------\n",
      "average training loss: 0.4017497543642775, training acc: 0.8172910809516907\n",
      "validation loss: 0.387917062585255, validation acc: 0.8429561257362366, test loss: 0.40399852477460413, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 91 -------------------\n",
      "average training loss: 0.41254853559845805, training acc: 0.818731963634491\n",
      "validation loss: 0.39005571232962716, validation acc: 0.8429561257362366, test loss: 0.40301149067241476, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 92 -------------------\n",
      "average training loss: 0.4184753811668594, training acc: 0.8077809810638428\n",
      "validation loss: 0.39267010416852716, validation acc: 0.8521940112113953, test loss: 0.41831544371244545, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 93 -------------------\n",
      "average training loss: 0.4152815467514291, training acc: 0.8106628060340881\n",
      "validation loss: 0.3874848684819613, validation acc: 0.8360277414321899, test loss: 0.406836664759069, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 94 -------------------\n",
      "average training loss: 0.4048618563657535, training acc: 0.8224784135818481\n",
      "validation loss: 0.39313999738561395, validation acc: 0.8221709132194519, test loss: 0.41299043218111664, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 95 -------------------\n",
      "average training loss: 0.4104967539094023, training acc: 0.8158501386642456\n",
      "validation loss: 0.3971919782013388, validation acc: 0.8221709132194519, test loss: 0.41661762998950097, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 96 -------------------\n",
      "average training loss: 0.4129448055533923, training acc: 0.8100864291191101\n",
      "validation loss: 0.39939997685120404, validation acc: 0.8429561257362366, test loss: 0.4215319493124562, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 97 -------------------\n",
      "average training loss: 0.41419592893089274, training acc: 0.8097983002662659\n",
      "validation loss: 0.3940839531234882, validation acc: 0.8429561257362366, test loss: 0.41124200491311913, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 98 -------------------\n",
      "average training loss: 0.4054843564885494, training acc: 0.8213256597518921\n",
      "validation loss: 0.3874859312712322, validation acc: 0.8360277414321899, test loss: 0.40811730200244534, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 99 -------------------\n",
      "average training loss: 0.4063805090247382, training acc: 0.819884717464447\n",
      "validation loss: 0.3893344845914621, validation acc: 0.8429561257362366, test loss: 0.41634778424342106, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 100 -------------------\n",
      "average training loss: 0.4029797400624333, training acc: 0.8224784135818481\n",
      "validation loss: 0.38560139501149754, validation acc: 0.8452655673027039, test loss: 0.4092775966439928, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 101 -------------------\n",
      "average training loss: 0.4056465772112096, training acc: 0.8167147040367126\n",
      "validation loss: 0.38729737266417474, validation acc: 0.8498845100402832, test loss: 0.4056036892574504, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 102 -------------------\n",
      "average training loss: 0.4042778539726301, training acc: 0.8146973848342896\n",
      "validation loss: 0.3875390561769635, validation acc: 0.8429561257362366, test loss: 0.4101962956690019, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 103 -------------------\n",
      "average training loss: 0.4018423227738235, training acc: 0.8221902251243591\n",
      "validation loss: 0.3890213768603066, validation acc: 0.8406466245651245, test loss: 0.41053167548597136, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 104 -------------------\n",
      "average training loss: 0.40945748687649325, training acc: 0.8129683136940002\n",
      "validation loss: 0.38395019740827624, validation acc: 0.8360277414321899, test loss: 0.4038008310003764, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 105 -------------------\n",
      "average training loss: 0.4017747828527555, training acc: 0.8158501386642456\n",
      "validation loss: 0.38596623147138254, validation acc: 0.8429561257362366, test loss: 0.40708666092239765, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 106 -------------------\n",
      "average training loss: 0.4049819482162981, training acc: 0.820461094379425\n",
      "validation loss: 0.3880159522531219, validation acc: 0.8221709132194519, test loss: 0.4049126641816258, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 107 -------------------\n",
      "average training loss: 0.40640125911929764, training acc: 0.8135446906089783\n",
      "validation loss: 0.3858487471457451, validation acc: 0.8406466245651245, test loss: 0.40989010743281806, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 108 -------------------\n",
      "average training loss: 0.39525294054825644, training acc: 0.8213256597518921\n",
      "validation loss: 0.38490172018927915, validation acc: 0.8475750684738159, test loss: 0.4025090968553921, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 109 -------------------\n",
      "average training loss: 0.40719001300053226, training acc: 0.819308340549469\n",
      "validation loss: 0.38236551666589375, validation acc: 0.8475750684738159, test loss: 0.40805742803806533, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 110 -------------------\n",
      "average training loss: 0.39796834302910467, training acc: 0.8213256597518921\n",
      "validation loss: 0.38305065571437785, validation acc: 0.8244803547859192, test loss: 0.4064035489811875, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 111 -------------------\n",
      "average training loss: 0.3993426171434716, training acc: 0.8227665424346924\n",
      "validation loss: 0.38603202579757584, validation acc: 0.8452655673027039, test loss: 0.4038032198556557, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 112 -------------------\n",
      "average training loss: 0.397395379983039, training acc: 0.820461094379425\n",
      "validation loss: 0.38264222408769316, validation acc: 0.8337182402610779, test loss: 0.3968802159008343, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 113 -------------------\n",
      "average training loss: 0.4012399550645427, training acc: 0.8210374712944031\n",
      "validation loss: 0.3901763434096965, validation acc: 0.8175519704818726, test loss: 0.40822798933851007, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 114 -------------------\n",
      "average training loss: 0.40406342982730536, training acc: 0.8181556463241577\n",
      "validation loss: 0.3821832512243552, validation acc: 0.8383371829986572, test loss: 0.4110041686466762, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 115 -------------------\n",
      "average training loss: 0.40360889661552585, training acc: 0.819308340549469\n",
      "validation loss: 0.3818904560419821, validation acc: 0.8406466245651245, test loss: 0.40433992974219785, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 116 -------------------\n",
      "average training loss: 0.40047073216534484, training acc: 0.8242074847221375\n",
      "validation loss: 0.38476250049430655, validation acc: 0.8429561257362366, test loss: 0.4101015097259926, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 117 -------------------\n",
      "average training loss: 0.40114316746206036, training acc: 0.8213256597518921\n",
      "validation loss: 0.3809113005339275, validation acc: 0.8383371829986572, test loss: 0.40024474373061536, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 118 -------------------\n",
      "average training loss: 0.4001841965257606, training acc: 0.8253602385520935\n",
      "validation loss: 0.38362433050634676, validation acc: 0.8406466245651245, test loss: 0.40720593036594477, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 119 -------------------\n",
      "average training loss: 0.38917106474167334, training acc: 0.8276656866073608\n",
      "validation loss: 0.38501432153486437, validation acc: 0.8452655673027039, test loss: 0.40252898695282124, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 120 -------------------\n",
      "average training loss: 0.40510711273130146, training acc: 0.8181556463241577\n",
      "validation loss: 0.3837271455658196, validation acc: 0.8429561257362366, test loss: 0.39767244815277064, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 121 -------------------\n",
      "average training loss: 0.3923025121949935, training acc: 0.8282420635223389\n",
      "validation loss: 0.38266090053017787, validation acc: 0.8429561257362366, test loss: 0.3977385220989104, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 122 -------------------\n",
      "average training loss: 0.4029334521946371, training acc: 0.8155619502067566\n",
      "validation loss: 0.38669648896988634, validation acc: 0.8452655673027039, test loss: 0.40401033899201777, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 123 -------------------\n",
      "average training loss: 0.39247544028229947, training acc: 0.8276656866073608\n",
      "validation loss: 0.3824952446645306, validation acc: 0.8406466245651245, test loss: 0.4000680821557199, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 124 -------------------\n",
      "average training loss: 0.40193232577884574, training acc: 0.8172910809516907\n",
      "validation loss: 0.3863806262406336, validation acc: 0.8452655673027039, test loss: 0.3916439246472126, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 125 -------------------\n",
      "average training loss: 0.39396639447390863, training acc: 0.8227665424346924\n",
      "validation loss: 0.3856612600489146, validation acc: 0.8475750684738159, test loss: 0.40282699561888174, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 126 -------------------\n",
      "average training loss: 0.3936955060326744, training acc: 0.8285302519798279\n",
      "validation loss: 0.38068533966892876, validation acc: 0.8475750684738159, test loss: 0.39943789048678313, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 127 -------------------\n",
      "average training loss: 0.3975774290238746, training acc: 0.8256484270095825\n",
      "validation loss: 0.3800210690443417, validation acc: 0.8337182402610779, test loss: 0.39643472213349584, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 128 -------------------\n",
      "average training loss: 0.39538194377415464, training acc: 0.8242074847221375\n",
      "validation loss: 0.38211829088250615, validation acc: 0.8406466245651245, test loss: 0.4016902232499716, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 129 -------------------\n",
      "average training loss: 0.396643943487739, training acc: 0.8273774981498718\n",
      "validation loss: 0.4048185996058899, validation acc: 0.8429561257362366, test loss: 0.4310225106878764, test acc: 0.7972350120544434\n",
      "\n",
      "------------------ EPOCH 130 -------------------\n",
      "average training loss: 0.38817784040736875, training acc: 0.8262248039245605\n",
      "validation loss: 0.38298646247331997, validation acc: 0.8337182402610779, test loss: 0.40082286195271577, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 131 -------------------\n",
      "average training loss: 0.3887140582377354, training acc: 0.8253602385520935\n",
      "validation loss: 0.3901615353635929, validation acc: 0.8152424693107605, test loss: 0.4004510788049566, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 132 -------------------\n",
      "average training loss: 0.3937989387113698, training acc: 0.8210374712944031\n",
      "validation loss: 0.3830166450156594, validation acc: 0.8429561257362366, test loss: 0.40297191675906907, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 133 -------------------\n",
      "average training loss: 0.3982280719005409, training acc: 0.8296830058097839\n",
      "validation loss: 0.3861917898676912, validation acc: 0.8475750684738159, test loss: 0.39942292779821403, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 134 -------------------\n",
      "average training loss: 0.39056993652489413, training acc: 0.8273774981498718\n",
      "validation loss: 0.3826413882492874, validation acc: 0.8360277414321899, test loss: 0.40269384131453556, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 135 -------------------\n",
      "average training loss: 0.3847971660517135, training acc: 0.8279538750648499\n",
      "validation loss: 0.3844737606251844, validation acc: 0.8429561257362366, test loss: 0.401282678826064, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 136 -------------------\n",
      "average training loss: 0.39384499114940763, training acc: 0.820461094379425\n",
      "validation loss: 0.3985923560945669, validation acc: 0.8175519704818726, test loss: 0.4089315646255071, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 137 -------------------\n",
      "average training loss: 0.39260648928732966, training acc: 0.8210374712944031\n",
      "validation loss: 0.3884454248687639, validation acc: 0.8290992975234985, test loss: 0.39766932028229884, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 138 -------------------\n",
      "average training loss: 0.3837747258480413, training acc: 0.830547571182251\n",
      "validation loss: 0.3857822159330966, validation acc: 0.8568129539489746, test loss: 0.4038014422913301, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 139 -------------------\n",
      "average training loss: 0.390246518398568, training acc: 0.8262248039245605\n",
      "validation loss: 0.3855275260413297, validation acc: 0.8383371829986572, test loss: 0.4046813029847387, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 140 -------------------\n",
      "average training loss: 0.3924622498259421, training acc: 0.830547571182251\n",
      "validation loss: 0.38544633634354114, validation acc: 0.8545034527778625, test loss: 0.4074993801007073, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 141 -------------------\n",
      "average training loss: 0.3851488663930371, training acc: 0.830547571182251\n",
      "validation loss: 0.3843501311842747, validation acc: 0.8314087986946106, test loss: 0.39529701971238657, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 142 -------------------\n",
      "average training loss: 0.38107626075703405, training acc: 0.8331412076950073\n",
      "validation loss: 0.38756741617681795, validation acc: 0.8521940112113953, test loss: 0.4010183016001354, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 143 -------------------\n",
      "average training loss: 0.3913818972083265, training acc: 0.8213256597518921\n",
      "validation loss: 0.38543278747989285, validation acc: 0.8290992975234985, test loss: 0.3981276169625296, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 144 -------------------\n",
      "average training loss: 0.38350085994008637, training acc: 0.8276656866073608\n",
      "validation loss: 0.3882335620816402, validation acc: 0.8521940112113953, test loss: 0.4114116097924896, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 145 -------------------\n",
      "average training loss: 0.3941328532414065, training acc: 0.8230547308921814\n",
      "validation loss: 0.381897322249852, validation acc: 0.8429561257362366, test loss: 0.39652778627136337, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 146 -------------------\n",
      "average training loss: 0.3877022022300907, training acc: 0.8259366154670715\n",
      "validation loss: 0.38418727488287036, validation acc: 0.8545034527778625, test loss: 0.40199174913942537, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 147 -------------------\n",
      "average training loss: 0.39194681421136995, training acc: 0.8270893096923828\n",
      "validation loss: 0.38068281011097993, validation acc: 0.8475750684738159, test loss: 0.39734060890663603, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 148 -------------------\n",
      "average training loss: 0.38079013225839875, training acc: 0.8296830058097839\n",
      "validation loss: 0.38175132815738977, validation acc: 0.8545034527778625, test loss: 0.3945634216756865, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 149 -------------------\n",
      "average training loss: 0.3857071233414092, training acc: 0.8282420635223389\n",
      "validation loss: 0.3833408001381131, validation acc: 0.8521940112113953, test loss: 0.3923443526990952, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 150 -------------------\n",
      "average training loss: 0.3804379507512799, training acc: 0.8386167287826538\n",
      "validation loss: 0.38177788958022124, validation acc: 0.8475750684738159, test loss: 0.3962361776883701, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 151 -------------------\n",
      "average training loss: 0.39345252750929904, training acc: 0.8247838616371155\n",
      "validation loss: 0.3801102852491739, validation acc: 0.8498845100402832, test loss: 0.3953029529839617, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 152 -------------------\n",
      "average training loss: 0.39078462296501015, training acc: 0.8282420635223389\n",
      "validation loss: 0.37959572089157895, validation acc: 0.8383371829986572, test loss: 0.39271377954065523, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 153 -------------------\n",
      "average training loss: 0.39029079457524873, training acc: 0.8319884538650513\n",
      "validation loss: 0.38008683178282004, validation acc: 0.8452655673027039, test loss: 0.39554461150125425, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 154 -------------------\n",
      "average training loss: 0.38661614591175264, training acc: 0.8293948173522949\n",
      "validation loss: 0.3805509333923665, validation acc: 0.8498845100402832, test loss: 0.4000921166986914, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 155 -------------------\n",
      "average training loss: 0.38700131887317735, training acc: 0.8276656866073608\n",
      "validation loss: 0.37907677435655196, validation acc: 0.8498845100402832, test loss: 0.3929769529999676, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 156 -------------------\n",
      "average training loss: 0.3937646713998888, training acc: 0.8285302519798279\n",
      "validation loss: 0.3819414477469185, validation acc: 0.8475750684738159, test loss: 0.397299533478126, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 157 -------------------\n",
      "average training loss: 0.3845388024272424, training acc: 0.8296830058097839\n",
      "validation loss: 0.37964266552353787, validation acc: 0.8521940112113953, test loss: 0.4001483354150974, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 158 -------------------\n",
      "average training loss: 0.38659310273890535, training acc: 0.8279538750648499\n",
      "validation loss: 0.37772297769922264, validation acc: 0.8475750684738159, test loss: 0.3975355279061102, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 159 -------------------\n",
      "average training loss: 0.3825629140355058, training acc: 0.8230547308921814\n",
      "validation loss: 0.3775703629933744, validation acc: 0.8429561257362366, test loss: 0.3976355244487112, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 160 -------------------\n",
      "average training loss: 0.3870146081023326, training acc: 0.8296830058097839\n",
      "validation loss: 0.38107867676266877, validation acc: 0.8545034527778625, test loss: 0.40001098392745865, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 161 -------------------\n",
      "average training loss: 0.38947142814353153, training acc: 0.8276656866073608\n",
      "validation loss: 0.37649549681195466, validation acc: 0.8383371829986572, test loss: 0.3949187510573919, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 162 -------------------\n",
      "average training loss: 0.3883896707801379, training acc: 0.8345821499824524\n",
      "validation loss: 0.3772517436179697, validation acc: 0.8290992975234985, test loss: 0.39058012814016385, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 163 -------------------\n",
      "average training loss: 0.37415041710526525, training acc: 0.8391931056976318\n",
      "validation loss: 0.37572812683845996, validation acc: 0.8383371829986572, test loss: 0.39015833216328777, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 164 -------------------\n",
      "average training loss: 0.38613723561124774, training acc: 0.8322766423225403\n",
      "validation loss: 0.3872654920074797, validation acc: 0.8498845100402832, test loss: 0.3967709464411582, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 165 -------------------\n",
      "average training loss: 0.3810900175949338, training acc: 0.8337175846099854\n",
      "validation loss: 0.3851737859337011, validation acc: 0.8314087986946106, test loss: 0.3978737383943549, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 166 -------------------\n",
      "average training loss: 0.3838094038303716, training acc: 0.8317002654075623\n",
      "validation loss: 0.37879923418644934, validation acc: 0.8498845100402832, test loss: 0.39357407727549154, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 167 -------------------\n",
      "average training loss: 0.37948883105423675, training acc: 0.8328530192375183\n",
      "validation loss: 0.38650865173010235, validation acc: 0.8498845100402832, test loss: 0.41253354087952643, test acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 168 -------------------\n",
      "average training loss: 0.38190441019940446, training acc: 0.829971194267273\n",
      "validation loss: 0.3807304803676869, validation acc: 0.8568129539489746, test loss: 0.40192295521635063, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 169 -------------------\n",
      "average training loss: 0.3769779372971065, training acc: 0.8351585268974304\n",
      "validation loss: 0.37855691534857594, validation acc: 0.8452655673027039, test loss: 0.3923472965367928, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 170 -------------------\n",
      "average training loss: 0.38605032318435417, training acc: 0.83083575963974\n",
      "validation loss: 0.3814816000412137, validation acc: 0.8521940112113953, test loss: 0.3897075227328709, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 171 -------------------\n",
      "average training loss: 0.37826560352652494, training acc: 0.8363112211227417\n",
      "validation loss: 0.3806611986890916, validation acc: 0.8591223955154419, test loss: 0.389877679710564, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 172 -------------------\n",
      "average training loss: 0.3838074166424336, training acc: 0.8394812941551208\n",
      "validation loss: 0.3794110505262278, validation acc: 0.8521940112113953, test loss: 0.40288131948440303, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 173 -------------------\n",
      "average training loss: 0.38776119578125157, training acc: 0.83083575963974\n",
      "validation loss: 0.37776390789291275, validation acc: 0.8498845100402832, test loss: 0.39912096407556313, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 174 -------------------\n",
      "average training loss: 0.3851184218864276, training acc: 0.8420749306678772\n",
      "validation loss: 0.37496089859766896, validation acc: 0.8452655673027039, test loss: 0.39046295419816046, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 175 -------------------\n",
      "average training loss: 0.38388214375855945, training acc: 0.8279538750648499\n",
      "validation loss: 0.3731507852604862, validation acc: 0.8498845100402832, test loss: 0.39564434737653775, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 176 -------------------\n",
      "average training loss: 0.38239374404681864, training acc: 0.83083575963974\n",
      "validation loss: 0.37960833420951245, validation acc: 0.8498845100402832, test loss: 0.40373804368731064, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 177 -------------------\n",
      "average training loss: 0.3837897207448393, training acc: 0.831123948097229\n",
      "validation loss: 0.37875549896933514, validation acc: 0.8290992975234985, test loss: 0.394556862830017, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 178 -------------------\n",
      "average training loss: 0.3884291446002828, training acc: 0.8247838616371155\n",
      "validation loss: 0.37178920559619427, validation acc: 0.8568129539489746, test loss: 0.3951405680948688, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 179 -------------------\n",
      "average training loss: 0.3890412266384971, training acc: 0.8328530192375183\n",
      "validation loss: 0.3748811135918314, validation acc: 0.8568129539489746, test loss: 0.38925396791800926, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 180 -------------------\n",
      "average training loss: 0.38170866959376704, training acc: 0.8340057730674744\n",
      "validation loss: 0.37558876575412836, validation acc: 0.8545034527778625, test loss: 0.39866544546619537, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 181 -------------------\n",
      "average training loss: 0.37933067049004504, training acc: 0.8342939615249634\n",
      "validation loss: 0.3718155669177183, validation acc: 0.8475750684738159, test loss: 0.39703841418165214, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 182 -------------------\n",
      "average training loss: 0.3795967730218464, training acc: 0.8291066288948059\n",
      "validation loss: 0.3707125495930421, validation acc: 0.861431896686554, test loss: 0.3925715233049085, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 183 -------------------\n",
      "average training loss: 0.37822906307940524, training acc: 0.8365994095802307\n",
      "validation loss: 0.37907759495045185, validation acc: 0.8591223955154419, test loss: 0.39970323388477624, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 184 -------------------\n",
      "average training loss: 0.38475799752930745, training acc: 0.8265129923820496\n",
      "validation loss: 0.3779606498468856, validation acc: 0.8406466245651245, test loss: 0.3907124433099949, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 185 -------------------\n",
      "average training loss: 0.3848742506689572, training acc: 0.8291066288948059\n",
      "validation loss: 0.3780274016928563, validation acc: 0.8383371829986572, test loss: 0.39057387583266756, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 186 -------------------\n",
      "average training loss: 0.3761490920435111, training acc: 0.8374639749526978\n",
      "validation loss: 0.3799722507802023, validation acc: 0.8545034527778625, test loss: 0.39711931622522767, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 187 -------------------\n",
      "average training loss: 0.38983605033382557, training acc: 0.8268011808395386\n",
      "validation loss: 0.3860147701155755, validation acc: 0.8521940112113953, test loss: 0.39354097211415867, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 188 -------------------\n",
      "average training loss: 0.37771574011453635, training acc: 0.8383285403251648\n",
      "validation loss: 0.38207035831042696, validation acc: 0.8637413382530212, test loss: 0.39569713086027153, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 189 -------------------\n",
      "average training loss: 0.3756419762754303, training acc: 0.8389049172401428\n",
      "validation loss: 0.3760978232743004, validation acc: 0.8545034527778625, test loss: 0.3896769695842321, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 190 -------------------\n",
      "average training loss: 0.37417675346050205, training acc: 0.8371757864952087\n",
      "validation loss: 0.38039456994577486, validation acc: 0.8475750684738159, test loss: 0.38651908982184624, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 191 -------------------\n",
      "average training loss: 0.37601239500025163, training acc: 0.8365994095802307\n",
      "validation loss: 0.37443751790281815, validation acc: 0.8360277414321899, test loss: 0.3871526008102751, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 192 -------------------\n",
      "average training loss: 0.3720054474447234, training acc: 0.8371757864952087\n",
      "validation loss: 0.37758116293612715, validation acc: 0.8406466245651245, test loss: 0.3885181319603722, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 193 -------------------\n",
      "average training loss: 0.38719093325502246, training acc: 0.8270893096923828\n",
      "validation loss: 0.37887778919413345, validation acc: 0.8337182402610779, test loss: 0.3863802842006156, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 194 -------------------\n",
      "average training loss: 0.37597476852043216, training acc: 0.8377521634101868\n",
      "validation loss: 0.38216424214949807, validation acc: 0.8521940112113953, test loss: 0.3916478371290567, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 195 -------------------\n",
      "average training loss: 0.37646946161555966, training acc: 0.8325648307800293\n",
      "validation loss: 0.37982236501258637, validation acc: 0.8406466245651245, test loss: 0.38804909518237485, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 196 -------------------\n",
      "average training loss: 0.3796921550454599, training acc: 0.8314120769500732\n",
      "validation loss: 0.3775212132985691, validation acc: 0.8521940112113953, test loss: 0.3918305146529378, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 197 -------------------\n",
      "average training loss: 0.3806969148882528, training acc: 0.8357348442077637\n",
      "validation loss: 0.382193167020099, validation acc: 0.8591223955154419, test loss: 0.3932929422174181, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 198 -------------------\n",
      "average training loss: 0.37421980586965764, training acc: 0.8380403518676758\n",
      "validation loss: 0.38838979086842956, validation acc: 0.8452655673027039, test loss: 0.3970323373919808, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 199 -------------------\n",
      "average training loss: 0.3775939982030165, training acc: 0.8391931056976318\n",
      "validation loss: 0.37578947450708133, validation acc: 0.8475750684738159, test loss: 0.3866265782837494, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 200 -------------------\n",
      "average training loss: 0.3723976014155132, training acc: 0.8357348442077637\n",
      "validation loss: 0.37628297844240743, validation acc: 0.8267898559570312, test loss: 0.3860711576202498, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 201 -------------------\n",
      "average training loss: 0.3758575821128977, training acc: 0.8351585268974304\n",
      "validation loss: 0.3926383736908161, validation acc: 0.8175519704818726, test loss: 0.40357032789063346, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 202 -------------------\n",
      "average training loss: 0.378190729734877, training acc: 0.8322766423225403\n",
      "validation loss: 0.37484106668678846, validation acc: 0.8545034527778625, test loss: 0.38458888308243816, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 203 -------------------\n",
      "average training loss: 0.378564345390034, training acc: 0.8340057730674744\n",
      "validation loss: 0.37580022490518983, validation acc: 0.8429561257362366, test loss: 0.3906014034275635, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 204 -------------------\n",
      "average training loss: 0.379287769334117, training acc: 0.8293948173522949\n",
      "validation loss: 0.3820139202654087, validation acc: 0.8429561257362366, test loss: 0.3906193760133559, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 205 -------------------\n",
      "average training loss: 0.371792432090391, training acc: 0.8414985537528992\n",
      "validation loss: 0.3762511134078975, validation acc: 0.8498845100402832, test loss: 0.3863033183983394, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 206 -------------------\n",
      "average training loss: 0.36881499908843024, training acc: 0.8420749306678772\n",
      "validation loss: 0.3734384208642942, validation acc: 0.8545034527778625, test loss: 0.38466078578601787, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 207 -------------------\n",
      "average training loss: 0.37886069483990625, training acc: 0.8319884538650513\n",
      "validation loss: 0.36981274887988097, validation acc: 0.8521940112113953, test loss: 0.38859868489102833, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 208 -------------------\n",
      "average training loss: 0.36910724864912997, training acc: 0.8386167287826538\n",
      "validation loss: 0.376653025570553, validation acc: 0.8568129539489746, test loss: 0.39728848478211787, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 209 -------------------\n",
      "average training loss: 0.3871291655284871, training acc: 0.8322766423225403\n",
      "validation loss: 0.3786010317126727, validation acc: 0.8360277414321899, test loss: 0.3912136002619695, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 210 -------------------\n",
      "average training loss: 0.3723971257292228, training acc: 0.8420749306678772\n",
      "validation loss: 0.3786883288264824, validation acc: 0.8429561257362366, test loss: 0.3882837522139747, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 211 -------------------\n",
      "average training loss: 0.37271702253509326, training acc: 0.8368875980377197\n",
      "validation loss: 0.3781132272998309, validation acc: 0.8545034527778625, test loss: 0.38968985723460325, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 212 -------------------\n",
      "average training loss: 0.3754088397671922, training acc: 0.8400576114654541\n",
      "validation loss: 0.3762918848046509, validation acc: 0.8314087986946106, test loss: 0.3826298385446522, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 213 -------------------\n",
      "average training loss: 0.37947896737873726, training acc: 0.830259382724762\n",
      "validation loss: 0.37430259633448815, validation acc: 0.8429561257362366, test loss: 0.3871397057436578, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 214 -------------------\n",
      "average training loss: 0.3658680550990256, training acc: 0.8423631191253662\n",
      "validation loss: 0.3762186715542446, validation acc: 0.8475750684738159, test loss: 0.3836753689748351, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 215 -------------------\n",
      "average training loss: 0.3607971020493796, training acc: 0.848703145980835\n",
      "validation loss: 0.374749486107156, validation acc: 0.8475750684738159, test loss: 0.3885843203089754, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 216 -------------------\n",
      "average training loss: 0.3695845465666966, training acc: 0.8397694230079651\n",
      "validation loss: 0.37390090250474517, validation acc: 0.8545034527778625, test loss: 0.38932882338624947, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 217 -------------------\n",
      "average training loss: 0.37105855561299006, training acc: 0.8391931056976318\n",
      "validation loss: 0.3753711784833587, validation acc: 0.8498845100402832, test loss: 0.3834204470507011, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 218 -------------------\n",
      "average training loss: 0.3681437440152127, training acc: 0.8412103652954102\n",
      "validation loss: 0.37395481044246304, validation acc: 0.8452655673027039, test loss: 0.3882342668996978, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 219 -------------------\n",
      "average training loss: 0.37579627753334705, training acc: 0.8334293961524963\n",
      "validation loss: 0.3765757350328331, validation acc: 0.8475750684738159, test loss: 0.389836270962992, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 220 -------------------\n",
      "average training loss: 0.3766299670642666, training acc: 0.8322766423225403\n",
      "validation loss: 0.37706090757099714, validation acc: 0.8498845100402832, test loss: 0.39312276244163513, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 221 -------------------\n",
      "average training loss: 0.36481614702029597, training acc: 0.8368875980377197\n",
      "validation loss: 0.38505529924746484, validation acc: 0.8383371829986572, test loss: 0.4015277854857906, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 222 -------------------\n",
      "average training loss: 0.37056405549434146, training acc: 0.8345821499824524\n",
      "validation loss: 0.3751918810853211, validation acc: 0.8475750684738159, test loss: 0.3877734254856813, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 223 -------------------\n",
      "average training loss: 0.3701742664537787, training acc: 0.8357348442077637\n",
      "validation loss: 0.37564337507645656, validation acc: 0.8452655673027039, test loss: 0.3902988251178495, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 224 -------------------\n",
      "average training loss: 0.36449970685439426, training acc: 0.8446685671806335\n",
      "validation loss: 0.37986931369601307, validation acc: 0.8475750684738159, test loss: 0.39656274906501243, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 225 -------------------\n",
      "average training loss: 0.3697629808520721, training acc: 0.8412103652954102\n",
      "validation loss: 0.3729693503698446, validation acc: 0.8475750684738159, test loss: 0.39656561036263743, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 226 -------------------\n",
      "average training loss: 0.36606184245873596, training acc: 0.8420749306678772\n",
      "validation loss: 0.3764234418693226, validation acc: 0.8360277414321899, test loss: 0.38586924221658486, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 227 -------------------\n",
      "average training loss: 0.36569459990568737, training acc: 0.8420749306678772\n",
      "validation loss: 0.37097220617230586, validation acc: 0.8406466245651245, test loss: 0.391248979052091, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 228 -------------------\n",
      "average training loss: 0.36300436887857895, training acc: 0.8391931056976318\n",
      "validation loss: 0.3760447164285018, validation acc: 0.8498845100402832, test loss: 0.3934445831632834, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 229 -------------------\n",
      "average training loss: 0.3756670718577822, training acc: 0.8345821499824524\n",
      "validation loss: 0.36835487324246613, validation acc: 0.8498845100402832, test loss: 0.4000464922272115, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 230 -------------------\n",
      "average training loss: 0.3743247691853246, training acc: 0.8391931056976318\n",
      "validation loss: 0.3716072433280505, validation acc: 0.8429561257362366, test loss: 0.3980016180996521, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 231 -------------------\n",
      "average training loss: 0.3666085722467054, training acc: 0.8455331325531006\n",
      "validation loss: 0.3668103141856084, validation acc: 0.8591223955154419, test loss: 0.3922272023792091, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 232 -------------------\n",
      "average training loss: 0.3780449449157165, training acc: 0.8288184404373169\n",
      "validation loss: 0.3719909227526133, validation acc: 0.8452655673027039, test loss: 0.39200202331015593, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 233 -------------------\n",
      "average training loss: 0.37102189508913574, training acc: 0.8357348442077637\n",
      "validation loss: 0.37146027338120247, validation acc: 0.8475750684738159, test loss: 0.3929623487632945, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 234 -------------------\n",
      "average training loss: 0.36776249863915894, training acc: 0.8452449440956116\n",
      "validation loss: 0.37162490312679575, validation acc: 0.8498845100402832, test loss: 0.39770878377598, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 235 -------------------\n",
      "average training loss: 0.3667702081567616, training acc: 0.8368875980377197\n",
      "validation loss: 0.3715655941018311, validation acc: 0.8521940112113953, test loss: 0.391750925559602, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 236 -------------------\n",
      "average training loss: 0.3681949439928236, training acc: 0.8417867422103882\n",
      "validation loss: 0.37133928501660923, validation acc: 0.8521940112113953, test loss: 0.3919641842490517, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 237 -------------------\n",
      "average training loss: 0.3676148563022229, training acc: 0.8394812941551208\n",
      "validation loss: 0.3726779576133473, validation acc: 0.8521940112113953, test loss: 0.39077304269311613, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 238 -------------------\n",
      "average training loss: 0.36915697855633345, training acc: 0.8440921902656555\n",
      "validation loss: 0.38397503798733107, validation acc: 0.8452655673027039, test loss: 0.392177747553944, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 239 -------------------\n",
      "average training loss: 0.37077483205012013, training acc: 0.8377521634101868\n",
      "validation loss: 0.3739869565046328, validation acc: 0.8452655673027039, test loss: 0.39061279972577423, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 240 -------------------\n",
      "average training loss: 0.36151334226818527, training acc: 0.8394812941551208\n",
      "validation loss: 0.37726736789749515, validation acc: 0.8360277414321899, test loss: 0.39714096479701555, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 241 -------------------\n",
      "average training loss: 0.3727272087112284, training acc: 0.8377521634101868\n",
      "validation loss: 0.3714212745702761, validation acc: 0.8498845100402832, test loss: 0.391629444701331, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 242 -------------------\n",
      "average training loss: 0.3661046019462756, training acc: 0.8377521634101868\n",
      "validation loss: 0.3705033082429165, validation acc: 0.8406466245651245, test loss: 0.39831495573443754, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 243 -------------------\n",
      "average training loss: 0.3596688471197738, training acc: 0.8420749306678772\n",
      "validation loss: 0.3776174274183089, validation acc: 0.8475750684738159, test loss: 0.3918314242417911, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 244 -------------------\n",
      "average training loss: 0.3670821573617479, training acc: 0.8389049172401428\n",
      "validation loss: 0.3745238441064061, validation acc: 0.8406466245651245, test loss: 0.3921122791305665, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 245 -------------------\n",
      "average training loss: 0.3666733737465971, training acc: 0.8374639749526978\n",
      "validation loss: 0.37175335086161093, validation acc: 0.8360277414321899, test loss: 0.39169196695226677, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 246 -------------------\n",
      "average training loss: 0.37237465478673104, training acc: 0.8426513075828552\n",
      "validation loss: 0.3724594601013693, validation acc: 0.8452655673027039, test loss: 0.3919181516093592, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 247 -------------------\n",
      "average training loss: 0.3701563649287485, training acc: 0.8403457999229431\n",
      "validation loss: 0.37662690589504855, validation acc: 0.8406466245651245, test loss: 0.39162925558705486, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 248 -------------------\n",
      "average training loss: 0.36738863597685734, training acc: 0.8438040614128113\n",
      "validation loss: 0.37335092234446704, validation acc: 0.8475750684738159, test loss: 0.39612760727856017, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 249 -------------------\n",
      "average training loss: 0.36379012568539776, training acc: 0.8440921902656555\n",
      "validation loss: 0.37146402284296975, validation acc: 0.8383371829986572, test loss: 0.3956899645691094, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 250 -------------------\n",
      "average training loss: 0.37654302018863667, training acc: 0.8325648307800293\n",
      "validation loss: 0.3821606712956582, validation acc: 0.8290992975234985, test loss: 0.39359096283187517, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 251 -------------------\n",
      "average training loss: 0.36817580222739954, training acc: 0.8417867422103882\n",
      "validation loss: 0.3767141561766374, validation acc: 0.8545034527778625, test loss: 0.39741639497642695, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 252 -------------------\n",
      "average training loss: 0.37913482833320883, training acc: 0.8334293961524963\n",
      "validation loss: 0.37386533089222446, validation acc: 0.8406466245651245, test loss: 0.39935949925453434, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 253 -------------------\n",
      "average training loss: 0.3654997214546121, training acc: 0.8374639749526978\n",
      "validation loss: 0.3737011218125919, validation acc: 0.8337182402610779, test loss: 0.3956733561605902, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 254 -------------------\n",
      "average training loss: 0.36179536197989404, training acc: 0.849567711353302\n",
      "validation loss: 0.3751295515881156, validation acc: 0.8498845100402832, test loss: 0.40104197412042575, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 255 -------------------\n",
      "average training loss: 0.3625403747091376, training acc: 0.8394812941551208\n",
      "validation loss: 0.374154063963121, validation acc: 0.8475750684738159, test loss: 0.39172399716992534, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 256 -------------------\n",
      "average training loss: 0.3586969476440111, training acc: 0.8423631191253662\n",
      "validation loss: 0.37468904792438457, validation acc: 0.8545034527778625, test loss: 0.39119934596224315, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 257 -------------------\n",
      "average training loss: 0.3605917074838358, training acc: 0.8417867422103882\n",
      "validation loss: 0.37243725208368167, validation acc: 0.8475750684738159, test loss: 0.38965642836786085, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 258 -------------------\n",
      "average training loss: 0.3610089497195197, training acc: 0.8455331325531006\n",
      "validation loss: 0.37081448768141084, validation acc: 0.8429561257362366, test loss: 0.38847916810193917, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 259 -------------------\n",
      "average training loss: 0.3585862955717257, training acc: 0.8475504517555237\n",
      "validation loss: 0.37437710447520156, validation acc: 0.8498845100402832, test loss: 0.3884556209711435, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 260 -------------------\n",
      "average training loss: 0.3662836936090453, training acc: 0.8426513075828552\n",
      "validation loss: 0.3751516801558332, validation acc: 0.8452655673027039, test loss: 0.3909943432027843, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 261 -------------------\n",
      "average training loss: 0.36570566538775, training acc: 0.8420749306678772\n",
      "validation loss: 0.37196735275505877, validation acc: 0.8429561257362366, test loss: 0.39906526229897954, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 262 -------------------\n",
      "average training loss: 0.3669024417139268, training acc: 0.8400576114654541\n",
      "validation loss: 0.38472669231726825, validation acc: 0.8406466245651245, test loss: 0.4011050108391019, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 263 -------------------\n",
      "average training loss: 0.3537759562905996, training acc: 0.8475504517555237\n",
      "validation loss: 0.37118025405615707, validation acc: 0.8521940112113953, test loss: 0.38873182353885494, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 264 -------------------\n",
      "average training loss: 0.37170497967461685, training acc: 0.8389049172401428\n",
      "validation loss: 0.3789891795628631, validation acc: 0.8290992975234985, test loss: 0.395787422146116, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 265 -------------------\n",
      "average training loss: 0.36781672082991695, training acc: 0.8345821499824524\n",
      "validation loss: 0.3733186179317088, validation acc: 0.8475750684738159, test loss: 0.3856537607133663, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 266 -------------------\n",
      "average training loss: 0.3553040410324888, training acc: 0.8420749306678772\n",
      "validation loss: 0.3720999598365775, validation acc: 0.8452655673027039, test loss: 0.39801003512698935, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 267 -------------------\n",
      "average training loss: 0.37424161784587057, training acc: 0.8342939615249634\n",
      "validation loss: 0.3668823032747216, validation acc: 0.8406466245651245, test loss: 0.3893401760110108, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 268 -------------------\n",
      "average training loss: 0.3685048115442397, training acc: 0.8363112211227417\n",
      "validation loss: 0.3702874761847307, validation acc: 0.8568129539489746, test loss: 0.39434276047390177, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 269 -------------------\n",
      "average training loss: 0.36073820510240384, training acc: 0.8449567556381226\n",
      "validation loss: 0.3745693745700994, validation acc: 0.8545034527778625, test loss: 0.3973021132330741, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 270 -------------------\n",
      "average training loss: 0.36601805461930265, training acc: 0.8377521634101868\n",
      "validation loss: 0.37026892362102387, validation acc: 0.8314087986946106, test loss: 0.3889663847086067, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 271 -------------------\n",
      "average training loss: 0.3697747690018041, training acc: 0.8360230326652527\n",
      "validation loss: 0.37037670687871044, validation acc: 0.8475750684738159, test loss: 0.3876039623390145, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 272 -------------------\n",
      "average training loss: 0.3549482603925106, training acc: 0.848414957523346\n",
      "validation loss: 0.3717327982461947, validation acc: 0.8360277414321899, test loss: 0.3916523305501806, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 273 -------------------\n",
      "average training loss: 0.36184399693087815, training acc: 0.8472622632980347\n",
      "validation loss: 0.37649813280676914, validation acc: 0.8360277414321899, test loss: 0.3860630116979098, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 274 -------------------\n",
      "average training loss: 0.3598255623486269, training acc: 0.8455331325531006\n",
      "validation loss: 0.3693513864745742, validation acc: 0.8475750684738159, test loss: 0.3872867012353537, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 275 -------------------\n",
      "average training loss: 0.36072305665923127, training acc: 0.8475504517555237\n",
      "validation loss: 0.3670068073519913, validation acc: 0.8452655673027039, test loss: 0.39200262581148454, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 276 -------------------\n",
      "average training loss: 0.3554631492590011, training acc: 0.8438040614128113\n",
      "validation loss: 0.36540294332163675, validation acc: 0.8521940112113953, test loss: 0.3951053188143787, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 277 -------------------\n",
      "average training loss: 0.36208802272675705, training acc: 0.8414985537528992\n",
      "validation loss: 0.3692709400494527, validation acc: 0.8568129539489746, test loss: 0.38622089135482013, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 278 -------------------\n",
      "average training loss: 0.3580255505846282, training acc: 0.8380403518676758\n",
      "validation loss: 0.37399499077126724, validation acc: 0.8314087986946106, test loss: 0.38748003315815727, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 279 -------------------\n",
      "average training loss: 0.35612339009812655, training acc: 0.8446685671806335\n",
      "validation loss: 0.37069967979659685, validation acc: 0.8521940112113953, test loss: 0.38771368158028424, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 280 -------------------\n",
      "average training loss: 0.3566178449292691, training acc: 0.8414985537528992\n",
      "validation loss: 0.36735369828164854, validation acc: 0.8545034527778625, test loss: 0.3895535054294744, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 281 -------------------\n",
      "average training loss: 0.35233639164341973, training acc: 0.848414957523346\n",
      "validation loss: 0.3676057041790079, validation acc: 0.8475750684738159, test loss: 0.3915354870431434, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 282 -------------------\n",
      "average training loss: 0.35232685340584524, training acc: 0.8458213210105896\n",
      "validation loss: 0.3692860201619188, validation acc: 0.8521940112113953, test loss: 0.39562966238518466, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 283 -------------------\n",
      "average training loss: 0.34664231901210046, training acc: 0.8582132458686829\n",
      "validation loss: 0.36862677500544605, validation acc: 0.8545034527778625, test loss: 0.3880926161867133, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 284 -------------------\n",
      "average training loss: 0.3608432737997698, training acc: 0.8461095094680786\n",
      "validation loss: 0.36559918340862074, validation acc: 0.8498845100402832, test loss: 0.38595003438984743, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 285 -------------------\n",
      "average training loss: 0.35811591646513263, training acc: 0.8452449440956116\n",
      "validation loss: 0.36989782311125285, validation acc: 0.8568129539489746, test loss: 0.39206856104635424, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 286 -------------------\n",
      "average training loss: 0.36769321011191486, training acc: 0.8334293961524963\n",
      "validation loss: 0.37129895622554465, validation acc: 0.8545034527778625, test loss: 0.38571148698780394, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 287 -------------------\n",
      "average training loss: 0.3600322598768586, training acc: 0.8363112211227417\n",
      "validation loss: 0.3765799472546248, validation acc: 0.8545034527778625, test loss: 0.3923414510241302, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 288 -------------------\n",
      "average training loss: 0.3601286343951047, training acc: 0.8363112211227417\n",
      "validation loss: 0.37042181214429265, validation acc: 0.8429561257362366, test loss: 0.3859928250312805, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 289 -------------------\n",
      "average training loss: 0.35878164247751926, training acc: 0.8475504517555237\n",
      "validation loss: 0.3687341295629053, validation acc: 0.8475750684738159, test loss: 0.38761647862772786, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 290 -------------------\n",
      "average training loss: 0.36352785314709724, training acc: 0.8455331325531006\n",
      "validation loss: 0.3738831712559621, validation acc: 0.8545034527778625, test loss: 0.3965328061086242, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 291 -------------------\n",
      "average training loss: 0.3596886076913443, training acc: 0.8409221768379211\n",
      "validation loss: 0.36394014727959434, validation acc: 0.8545034527778625, test loss: 0.3870375311594405, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 292 -------------------\n",
      "average training loss: 0.3607030572911848, training acc: 0.8443803787231445\n",
      "validation loss: 0.3600313210267625, validation acc: 0.8568129539489746, test loss: 0.39164107612201143, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 293 -------------------\n",
      "average training loss: 0.3560445695342523, training acc: 0.8458213210105896\n",
      "validation loss: 0.3738685503670697, validation acc: 0.8545034527778625, test loss: 0.40139292654353903, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 294 -------------------\n",
      "average training loss: 0.373446692762526, training acc: 0.8377521634101868\n",
      "validation loss: 0.36628997744777786, validation acc: 0.8429561257362366, test loss: 0.3927600323329873, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 295 -------------------\n",
      "average training loss: 0.3551653671161586, training acc: 0.8507204651832581\n",
      "validation loss: 0.37015855662559033, validation acc: 0.8568129539489746, test loss: 0.3916760707780513, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 296 -------------------\n",
      "average training loss: 0.354193922198815, training acc: 0.8429394960403442\n",
      "validation loss: 0.3682386369749148, validation acc: 0.8429561257362366, test loss: 0.396429838672761, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 297 -------------------\n",
      "average training loss: 0.3623117834415491, training acc: 0.8438040614128113\n",
      "validation loss: 0.3635726911681039, validation acc: 0.8568129539489746, test loss: 0.38800704053470064, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 298 -------------------\n",
      "average training loss: 0.36569558677480957, training acc: 0.8391931056976318\n",
      "validation loss: 0.36861364749444797, validation acc: 0.8545034527778625, test loss: 0.39115720643975216, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 299 -------------------\n",
      "average training loss: 0.3566550531545359, training acc: 0.8400576114654541\n",
      "validation loss: 0.3716336784000221, validation acc: 0.8498845100402832, test loss: 0.3990631571837834, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 300 -------------------\n",
      "average training loss: 0.3499718593417396, training acc: 0.8478386402130127\n",
      "validation loss: 0.36684520885966343, validation acc: 0.8545034527778625, test loss: 0.392973404600873, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 301 -------------------\n",
      "average training loss: 0.3521496188056572, training acc: 0.8536022901535034\n",
      "validation loss: 0.37756203005116107, validation acc: 0.8475750684738159, test loss: 0.39008836249052653, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 302 -------------------\n",
      "average training loss: 0.34991900651186963, training acc: 0.8533141016960144\n",
      "validation loss: 0.36185359673291306, validation acc: 0.8637413382530212, test loss: 0.39237250792815387, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 303 -------------------\n",
      "average training loss: 0.3469755091052234, training acc: 0.849855899810791\n",
      "validation loss: 0.3638191961335696, validation acc: 0.8452655673027039, test loss: 0.3878307516948419, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 304 -------------------\n",
      "average training loss: 0.36894581010430966, training acc: 0.8397694230079651\n",
      "validation loss: 0.3693790658278399, validation acc: 0.8637413382530212, test loss: 0.3918946335941965, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 305 -------------------\n",
      "average training loss: 0.36154773185507366, training acc: 0.8463976979255676\n",
      "validation loss: 0.3639876017098053, validation acc: 0.8545034527778625, test loss: 0.39452711970026044, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 306 -------------------\n",
      "average training loss: 0.35978579473083233, training acc: 0.8403457999229431\n",
      "validation loss: 0.3643135242335807, validation acc: 0.8568129539489746, test loss: 0.39336908467903664, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 307 -------------------\n",
      "average training loss: 0.35467331386265216, training acc: 0.8515850305557251\n",
      "validation loss: 0.3676873017703333, validation acc: 0.8591223955154419, test loss: 0.3880651530032883, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 308 -------------------\n",
      "average training loss: 0.3570491026732695, training acc: 0.8423631191253662\n",
      "validation loss: 0.3680563065725537, validation acc: 0.8521940112113953, test loss: 0.39282520245846514, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 309 -------------------\n",
      "average training loss: 0.35369371730587323, training acc: 0.848414957523346\n",
      "validation loss: 0.36660876616080235, validation acc: 0.8521940112113953, test loss: 0.39451614063456314, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 310 -------------------\n",
      "average training loss: 0.36301164240589745, training acc: 0.8403457999229431\n",
      "validation loss: 0.37277759893149276, validation acc: 0.8591223955154419, test loss: 0.39273963161327874, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 311 -------------------\n",
      "average training loss: 0.36312125588013044, training acc: 0.8429394960403442\n",
      "validation loss: 0.36680396625660533, validation acc: 0.8521940112113953, test loss: 0.3903542439783773, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 312 -------------------\n",
      "average training loss: 0.3560633095952894, training acc: 0.8455331325531006\n",
      "validation loss: 0.3678268056174028, validation acc: 0.8475750684738159, test loss: 0.3893206399706651, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 313 -------------------\n",
      "average training loss: 0.3557376576775433, training acc: 0.8409221768379211\n",
      "validation loss: 0.37190020805405033, validation acc: 0.8568129539489746, test loss: 0.3934652177694206, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 314 -------------------\n",
      "average training loss: 0.35992700071087486, training acc: 0.8423631191253662\n",
      "validation loss: 0.3653892429742945, validation acc: 0.8452655673027039, test loss: 0.3884834222804566, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 315 -------------------\n",
      "average training loss: 0.35496336393466255, training acc: 0.848414957523346\n",
      "validation loss: 0.37275612539684716, validation acc: 0.8521940112113953, test loss: 0.39179266817558744, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 316 -------------------\n",
      "average training loss: 0.35181978074377485, training acc: 0.8443803787231445\n",
      "validation loss: 0.3698692493449708, validation acc: 0.8521940112113953, test loss: 0.39502055853742607, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 317 -------------------\n",
      "average training loss: 0.3533707141790335, training acc: 0.849279522895813\n",
      "validation loss: 0.3655035736099366, validation acc: 0.8452655673027039, test loss: 0.39606962692902387, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 318 -------------------\n",
      "average training loss: 0.35739182919177953, training acc: 0.8446685671806335\n",
      "validation loss: 0.3683572363468908, validation acc: 0.8521940112113953, test loss: 0.3932762985130609, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 319 -------------------\n",
      "average training loss: 0.35451832204112405, training acc: 0.8463976979255676\n",
      "validation loss: 0.36516233276112287, validation acc: 0.8568129539489746, test loss: 0.38922262109369726, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 320 -------------------\n",
      "average training loss: 0.3555696534663868, training acc: 0.848991334438324\n",
      "validation loss: 0.36922343926770346, validation acc: 0.8637413382530212, test loss: 0.38823110757884893, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 321 -------------------\n",
      "average training loss: 0.3581656830798652, training acc: 0.8423631191253662\n",
      "validation loss: 0.36790047874373777, validation acc: 0.8521940112113953, test loss: 0.3880146919032945, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 322 -------------------\n",
      "average training loss: 0.35657722101431416, training acc: 0.8461095094680786\n",
      "validation loss: 0.37067884515782107, validation acc: 0.8452655673027039, test loss: 0.383173186520827, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 323 -------------------\n",
      "average training loss: 0.3472345111349474, training acc: 0.8524495959281921\n",
      "validation loss: 0.37114742549333707, validation acc: 0.8498845100402832, test loss: 0.39021132453795404, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 324 -------------------\n",
      "average training loss: 0.35454643174619427, training acc: 0.8466858863830566\n",
      "validation loss: 0.3690018686830723, validation acc: 0.8452655673027039, test loss: 0.39110092207583413, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 325 -------------------\n",
      "average training loss: 0.35810807919296134, training acc: 0.8438040614128113\n",
      "validation loss: 0.36445521443120893, validation acc: 0.8521940112113953, test loss: 0.38563882714043013, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 326 -------------------\n",
      "average training loss: 0.35227628169897995, training acc: 0.850432276725769\n",
      "validation loss: 0.3703350965877832, validation acc: 0.8568129539489746, test loss: 0.39264545860927774, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 327 -------------------\n",
      "average training loss: 0.35566861364958263, training acc: 0.8449567556381226\n",
      "validation loss: 0.3708663086325342, validation acc: 0.8452655673027039, test loss: 0.38539193398941496, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 328 -------------------\n",
      "average training loss: 0.35030167767568693, training acc: 0.8533141016960144\n",
      "validation loss: 0.3673530001931476, validation acc: 0.8498845100402832, test loss: 0.38837809222085135, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 329 -------------------\n",
      "average training loss: 0.35448178927218194, training acc: 0.850432276725769\n",
      "validation loss: 0.3662224173683175, validation acc: 0.8521940112113953, test loss: 0.38916433283260893, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 330 -------------------\n",
      "average training loss: 0.35753953487797496, training acc: 0.8440921902656555\n",
      "validation loss: 0.3701109433641082, validation acc: 0.8452655673027039, test loss: 0.3972142749393041, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 331 -------------------\n",
      "average training loss: 0.35630155423876186, training acc: 0.849279522895813\n",
      "validation loss: 0.3708805610095301, validation acc: 0.8452655673027039, test loss: 0.39874829633444686, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 332 -------------------\n",
      "average training loss: 0.3539666586289832, training acc: 0.849855899810791\n",
      "validation loss: 0.3631055749231769, validation acc: 0.8498845100402832, test loss: 0.3928300454045221, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 333 -------------------\n",
      "average training loss: 0.35211582653632423, training acc: 0.848703145980835\n",
      "validation loss: 0.3678466632344206, validation acc: 0.8521940112113953, test loss: 0.38093211807413585, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 334 -------------------\n",
      "average training loss: 0.3556681047255436, training acc: 0.8527377247810364\n",
      "validation loss: 0.3684701952516758, validation acc: 0.8406466245651245, test loss: 0.39029478834521386, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 335 -------------------\n",
      "average training loss: 0.3474682128137402, training acc: 0.85014408826828\n",
      "validation loss: 0.3700405643557623, validation acc: 0.8452655673027039, test loss: 0.3887899865477865, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 336 -------------------\n",
      "average training loss: 0.35398777574730195, training acc: 0.8512968420982361\n",
      "validation loss: 0.368128797975004, validation acc: 0.8521940112113953, test loss: 0.3933525751537991, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 337 -------------------\n",
      "average training loss: 0.34188859899037166, training acc: 0.8512968420982361\n",
      "validation loss: 0.3664185250959089, validation acc: 0.8475750684738159, test loss: 0.3871612465052011, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 338 -------------------\n",
      "average training loss: 0.3508297529790862, training acc: 0.8466858863830566\n",
      "validation loss: 0.36942185633193514, validation acc: 0.8498845100402832, test loss: 0.39236477511819057, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 339 -------------------\n",
      "average training loss: 0.355701258048544, training acc: 0.8461095094680786\n",
      "validation loss: 0.3641323980098496, validation acc: 0.8429561257362366, test loss: 0.3885969836865702, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 340 -------------------\n",
      "average training loss: 0.35126376440614376, training acc: 0.8536022901535034\n",
      "validation loss: 0.36817280673486297, validation acc: 0.8406466245651245, test loss: 0.39295051174779094, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 341 -------------------\n",
      "average training loss: 0.3504958715665581, training acc: 0.8478386402130127\n",
      "validation loss: 0.36928454577098796, validation acc: 0.8360277414321899, test loss: 0.3872726673629427, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 342 -------------------\n",
      "average training loss: 0.3515848022029448, training acc: 0.8533141016960144\n",
      "validation loss: 0.36690614163051555, validation acc: 0.8498845100402832, test loss: 0.3848407801395188, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 343 -------------------\n",
      "average training loss: 0.3485099210175726, training acc: 0.848991334438324\n",
      "validation loss: 0.36615129577399397, validation acc: 0.8360277414321899, test loss: 0.3883748081971973, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 344 -------------------\n",
      "average training loss: 0.36235296193735744, training acc: 0.8363112211227417\n",
      "validation loss: 0.3643373933530623, validation acc: 0.8452655673027039, test loss: 0.38270106018962946, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 345 -------------------\n",
      "average training loss: 0.3532547019572354, training acc: 0.8440921902656555\n",
      "validation loss: 0.36272419968508357, validation acc: 0.8452655673027039, test loss: 0.3826867409290806, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 346 -------------------\n",
      "average training loss: 0.34371557357675403, training acc: 0.8559077978134155\n",
      "validation loss: 0.3646202791259036, validation acc: 0.8383371829986572, test loss: 0.3881107218529222, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 347 -------------------\n",
      "average training loss: 0.35302852542496554, training acc: 0.8478386402130127\n",
      "validation loss: 0.37203191502303024, validation acc: 0.8360277414321899, test loss: 0.3897382777682098, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 348 -------------------\n",
      "average training loss: 0.3586227441040171, training acc: 0.8394812941551208\n",
      "validation loss: 0.3716145306138948, validation acc: 0.8429561257362366, test loss: 0.38649920370721597, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 349 -------------------\n",
      "average training loss: 0.35747434088063856, training acc: 0.8446685671806335\n",
      "validation loss: 0.3684794421432205, validation acc: 0.8452655673027039, test loss: 0.3837176918434108, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 350 -------------------\n",
      "average training loss: 0.35187688715519755, training acc: 0.8455331325531006\n",
      "validation loss: 0.370828465863307, validation acc: 0.8383371829986572, test loss: 0.3834084589635172, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 351 -------------------\n",
      "average training loss: 0.34661320463381173, training acc: 0.8561959862709045\n",
      "validation loss: 0.3730951697320982, validation acc: 0.8429561257362366, test loss: 0.39138876883664986, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 352 -------------------\n",
      "average training loss: 0.34636164154717836, training acc: 0.8550432324409485\n",
      "validation loss: 0.36517913241265554, validation acc: 0.8360277414321899, test loss: 0.38795606084682976, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 353 -------------------\n",
      "average training loss: 0.35636726572293714, training acc: 0.8553314208984375\n",
      "validation loss: 0.37187290500660647, validation acc: 0.8406466245651245, test loss: 0.38855669712690716, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 354 -------------------\n",
      "average training loss: 0.35209838663810267, training acc: 0.8472622632980347\n",
      "validation loss: 0.37027280451515304, validation acc: 0.8498845100402832, test loss: 0.3878966269130531, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 355 -------------------\n",
      "average training loss: 0.3513566652017643, training acc: 0.848414957523346\n",
      "validation loss: 0.3721180232027159, validation acc: 0.8429561257362366, test loss: 0.3994024195429367, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 356 -------------------\n",
      "average training loss: 0.35580992302736564, training acc: 0.848703145980835\n",
      "validation loss: 0.36913718976732773, validation acc: 0.8337182402610779, test loss: 0.399347085145212, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 357 -------------------\n",
      "average training loss: 0.3599427630131801, training acc: 0.8472622632980347\n",
      "validation loss: 0.3656878669141075, validation acc: 0.8452655673027039, test loss: 0.3911783895734268, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 358 -------------------\n",
      "average training loss: 0.34388201015139863, training acc: 0.8510086536407471\n",
      "validation loss: 0.3699864183428101, validation acc: 0.8475750684738159, test loss: 0.38994718875203815, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 359 -------------------\n",
      "average training loss: 0.3545725947670016, training acc: 0.8452449440956116\n",
      "validation loss: 0.3638705839209842, validation acc: 0.8498845100402832, test loss: 0.38921064330685523, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 360 -------------------\n",
      "average training loss: 0.3482504045413619, training acc: 0.8472622632980347\n",
      "validation loss: 0.3697167656938052, validation acc: 0.8521940112113953, test loss: 0.39746886903789186, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 361 -------------------\n",
      "average training loss: 0.3488932743367956, training acc: 0.85014408826828\n",
      "validation loss: 0.37229888642438547, validation acc: 0.8314087986946106, test loss: 0.4002123361084318, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 362 -------------------\n",
      "average training loss: 0.3540748368422648, training acc: 0.8461095094680786\n",
      "validation loss: 0.3735291569875682, validation acc: 0.8429561257362366, test loss: 0.40055610685853915, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 363 -------------------\n",
      "average training loss: 0.34470619030232386, training acc: 0.8524495959281921\n",
      "validation loss: 0.3696345868198553, validation acc: 0.8383371829986572, test loss: 0.3941221716491857, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 364 -------------------\n",
      "average training loss: 0.3493291021423999, training acc: 0.8423631191253662\n",
      "validation loss: 0.36696393705458136, validation acc: 0.8521940112113953, test loss: 0.39297622071433175, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 365 -------------------\n",
      "average training loss: 0.3612513074957328, training acc: 0.8406339883804321\n",
      "validation loss: 0.3645404421376742, validation acc: 0.8360277414321899, test loss: 0.39261175080927835, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 366 -------------------\n",
      "average training loss: 0.3540145627875149, training acc: 0.849567711353302\n",
      "validation loss: 0.36664691646390246, validation acc: 0.8475750684738159, test loss: 0.3962291557393316, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 367 -------------------\n",
      "average training loss: 0.35294088221420816, training acc: 0.8429394960403442\n",
      "validation loss: 0.37599969116224125, validation acc: 0.8475750684738159, test loss: 0.3972571293055187, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 368 -------------------\n",
      "average training loss: 0.3565693981365787, training acc: 0.8423631191253662\n",
      "validation loss: 0.3719659834962836, validation acc: 0.8498845100402832, test loss: 0.4003052872172149, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 369 -------------------\n",
      "average training loss: 0.34407053758156747, training acc: 0.849567711353302\n",
      "validation loss: 0.382495615202161, validation acc: 0.8475750684738159, test loss: 0.40209031915335064, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 370 -------------------\n",
      "average training loss: 0.3463290277578645, training acc: 0.8547550439834595\n",
      "validation loss: 0.3636237384948862, validation acc: 0.8429561257362366, test loss: 0.3936777568083205, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 371 -------------------\n",
      "average training loss: 0.3566885444977098, training acc: 0.8406339883804321\n",
      "validation loss: 0.37238525231862396, validation acc: 0.8337182402610779, test loss: 0.39709954863319746, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 372 -------------------\n",
      "average training loss: 0.3506910799989096, training acc: 0.8466858863830566\n",
      "validation loss: 0.36757697872302497, validation acc: 0.8429561257362366, test loss: 0.3930369386200531, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 373 -------------------\n",
      "average training loss: 0.35196611584091736, training acc: 0.8452449440956116\n",
      "validation loss: 0.36398830872526916, validation acc: 0.8498845100402832, test loss: 0.3905882709037324, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 374 -------------------\n",
      "average training loss: 0.34566575256136034, training acc: 0.849567711353302\n",
      "validation loss: 0.3648600081831629, validation acc: 0.8545034527778625, test loss: 0.3979563783116055, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 375 -------------------\n",
      "average training loss: 0.35406426204212804, training acc: 0.849567711353302\n",
      "validation loss: 0.3699058682275807, validation acc: 0.8591223955154419, test loss: 0.39775427887516634, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 376 -------------------\n",
      "average training loss: 0.34668972784229246, training acc: 0.8481268286705017\n",
      "validation loss: 0.3712471107939421, validation acc: 0.8452655673027039, test loss: 0.3947613570272648, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 377 -------------------\n",
      "average training loss: 0.3470395941040358, training acc: 0.8481268286705017\n",
      "validation loss: 0.37069272692851757, validation acc: 0.8475750684738159, test loss: 0.39372826075773637, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 378 -------------------\n",
      "average training loss: 0.3525836159069875, training acc: 0.8449567556381226\n",
      "validation loss: 0.37360606242984123, validation acc: 0.8360277414321899, test loss: 0.38768510678396795, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 379 -------------------\n",
      "average training loss: 0.3518788725567139, training acc: 0.8452449440956116\n",
      "validation loss: 0.3746118025708308, validation acc: 0.8383371829986572, test loss: 0.3862967760332169, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 380 -------------------\n",
      "average training loss: 0.35045139178075435, training acc: 0.850432276725769\n",
      "validation loss: 0.3714356302253662, validation acc: 0.8337182402610779, test loss: 0.388287886633851, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 381 -------------------\n",
      "average training loss: 0.34144581679136676, training acc: 0.8524495959281921\n",
      "validation loss: 0.373417787425529, validation acc: 0.8360277414321899, test loss: 0.39812059721089726, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 382 -------------------\n",
      "average training loss: 0.3396080594069676, training acc: 0.8527377247810364\n",
      "validation loss: 0.37808558104499695, validation acc: 0.8452655673027039, test loss: 0.3935432832361916, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 383 -------------------\n",
      "average training loss: 0.3516486127713228, training acc: 0.8449567556381226\n",
      "validation loss: 0.3750379128115518, validation acc: 0.8429561257362366, test loss: 0.3898338683739236, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 384 -------------------\n",
      "average training loss: 0.3507298244351269, training acc: 0.848703145980835\n",
      "validation loss: 0.3900183580712789, validation acc: 0.8152424693107605, test loss: 0.4064929029359246, test acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 385 -------------------\n",
      "average training loss: 0.3455847452799937, training acc: 0.848703145980835\n",
      "validation loss: 0.37510372931781455, validation acc: 0.8452655673027039, test loss: 0.40230694303314807, test acc: 0.8110598921775818\n",
      "\n",
      "------------------ EPOCH 386 -------------------\n",
      "average training loss: 0.3496085507553661, training acc: 0.849855899810791\n",
      "validation loss: 0.36934259897827554, validation acc: 0.8475750684738159, test loss: 0.39319950040034984, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 387 -------------------\n",
      "average training loss: 0.3421570486740695, training acc: 0.8530259132385254\n",
      "validation loss: 0.3684223779747563, validation acc: 0.8452655673027039, test loss: 0.3991684581277557, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 388 -------------------\n",
      "average training loss: 0.3484665520596573, training acc: 0.8458213210105896\n",
      "validation loss: 0.3744538363223801, validation acc: 0.8383371829986572, test loss: 0.3970114827705418, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 389 -------------------\n",
      "average training loss: 0.3495515237624089, training acc: 0.8547550439834595\n",
      "validation loss: 0.3694948906310692, validation acc: 0.8521940112113953, test loss: 0.3881818808718211, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 390 -------------------\n",
      "average training loss: 0.3482215217966855, training acc: 0.8541786670684814\n",
      "validation loss: 0.3727070719415691, validation acc: 0.8383371829986572, test loss: 0.39261429581773993, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 391 -------------------\n",
      "average training loss: 0.3563809922174349, training acc: 0.8406339883804321\n",
      "validation loss: 0.3695889497132895, validation acc: 0.8383371829986572, test loss: 0.3859191193558653, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 392 -------------------\n",
      "average training loss: 0.3494829705194369, training acc: 0.8469740748405457\n",
      "validation loss: 0.3726948232557367, validation acc: 0.8452655673027039, test loss: 0.3930934638746323, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 393 -------------------\n",
      "average training loss: 0.3647282949699792, training acc: 0.8394812941551208\n",
      "validation loss: 0.37511706819182716, validation acc: 0.8383371829986572, test loss: 0.3906828630629772, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 394 -------------------\n",
      "average training loss: 0.3441674613385791, training acc: 0.8472622632980347\n",
      "validation loss: 0.3743480257518281, validation acc: 0.8406466245651245, test loss: 0.39962899671172214, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 395 -------------------\n",
      "average training loss: 0.34609727579509836, training acc: 0.8556196093559265\n",
      "validation loss: 0.37111468819154575, validation acc: 0.8360277414321899, test loss: 0.394464725722915, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 396 -------------------\n",
      "average training loss: 0.3510796273132566, training acc: 0.8469740748405457\n",
      "validation loss: 0.37321026595781476, validation acc: 0.8406466245651245, test loss: 0.39759075545495554, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 397 -------------------\n",
      "average training loss: 0.3513648250604569, training acc: 0.849279522895813\n",
      "validation loss: 0.37794959524534816, validation acc: 0.8429561257362366, test loss: 0.4023581920406236, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 398 -------------------\n",
      "average training loss: 0.34166147613130315, training acc: 0.8556196093559265\n",
      "validation loss: 0.37799481086192593, validation acc: 0.8406466245651245, test loss: 0.39855127331847967, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 399 -------------------\n",
      "average training loss: 0.339202742720887, training acc: 0.8570604920387268\n",
      "validation loss: 0.37644818596850893, validation acc: 0.8337182402610779, test loss: 0.4024020901748112, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 400 -------------------\n",
      "average training loss: 0.348986850485678, training acc: 0.8469740748405457\n",
      "validation loss: 0.36630105560276366, validation acc: 0.8337182402610779, test loss: 0.3943337502842125, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 401 -------------------\n",
      "average training loss: 0.34719376749538894, training acc: 0.8472622632980347\n",
      "validation loss: 0.3658801469660025, validation acc: 0.8383371829986572, test loss: 0.3932784207954934, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 402 -------------------\n",
      "average training loss: 0.3387391021770428, training acc: 0.8533141016960144\n",
      "validation loss: 0.369811410934145, validation acc: 0.8383371829986572, test loss: 0.39692923234355065, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 403 -------------------\n",
      "average training loss: 0.3505514817382142, training acc: 0.85014408826828\n",
      "validation loss: 0.3744327777541728, validation acc: 0.8498845100402832, test loss: 0.3985951231097296, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 404 -------------------\n",
      "average training loss: 0.34579952067188297, training acc: 0.8472622632980347\n",
      "validation loss: 0.37845598291691546, validation acc: 0.8406466245651245, test loss: 0.4012393966523184, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 405 -------------------\n",
      "average training loss: 0.3455391231977974, training acc: 0.849279522895813\n",
      "validation loss: 0.37593688125709235, validation acc: 0.8383371829986572, test loss: 0.39471453675476637, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 406 -------------------\n",
      "average training loss: 0.34696634214274824, training acc: 0.8455331325531006\n",
      "validation loss: 0.3786279493899939, validation acc: 0.8314087986946106, test loss: 0.39812247132376044, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 407 -------------------\n",
      "average training loss: 0.3337833726612223, training acc: 0.860230565071106\n",
      "validation loss: 0.3771806514139549, validation acc: 0.8452655673027039, test loss: 0.4025759773869668, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 408 -------------------\n",
      "average training loss: 0.34367899576937433, training acc: 0.8521614074707031\n",
      "validation loss: 0.3758622256841528, validation acc: 0.8406466245651245, test loss: 0.4013540294313211, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 409 -------------------\n",
      "average training loss: 0.3586494783503178, training acc: 0.8446685671806335\n",
      "validation loss: 0.3742061375472952, validation acc: 0.8452655673027039, test loss: 0.39495528348579934, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 410 -------------------\n",
      "average training loss: 0.34479812027226264, training acc: 0.8481268286705017\n",
      "validation loss: 0.3792753795050256, validation acc: 0.8383371829986572, test loss: 0.40079082390679743, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 411 -------------------\n",
      "average training loss: 0.34444932121708344, training acc: 0.849855899810791\n",
      "validation loss: 0.38287157232310914, validation acc: 0.8429561257362366, test loss: 0.4077055560004327, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 412 -------------------\n",
      "average training loss: 0.34824607444427885, training acc: 0.8478386402130127\n",
      "validation loss: 0.37697264552116394, validation acc: 0.8475750684738159, test loss: 0.3945748646687802, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 413 -------------------\n",
      "average training loss: 0.345718066286972, training acc: 0.8507204651832581\n",
      "validation loss: 0.37812763706605007, validation acc: 0.8383371829986572, test loss: 0.40033023711723115, test acc: 0.8156682252883911\n",
      "\n",
      "------------------ EPOCH 414 -------------------\n",
      "average training loss: 0.3396865558555559, training acc: 0.8527377247810364\n",
      "validation loss: 0.37328690929072245, validation acc: 0.8406466245651245, test loss: 0.39455568872838526, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 415 -------------------\n",
      "average training loss: 0.35384769165722024, training acc: 0.8472622632980347\n",
      "validation loss: 0.38764135244255243, validation acc: 0.8452655673027039, test loss: 0.4132696759590905, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 416 -------------------\n",
      "average training loss: 0.3434834841005397, training acc: 0.8541786670684814\n",
      "validation loss: 0.37724742976613856, validation acc: 0.8337182402610779, test loss: 0.40048931024041595, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 417 -------------------\n",
      "average training loss: 0.35003348317544813, training acc: 0.8466858863830566\n",
      "validation loss: 0.37120105696988, validation acc: 0.8452655673027039, test loss: 0.39882480507622114, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 418 -------------------\n",
      "average training loss: 0.3414937763976776, training acc: 0.8567723631858826\n",
      "validation loss: 0.372308055960363, validation acc: 0.8383371829986572, test loss: 0.39292164922859263, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 419 -------------------\n",
      "average training loss: 0.34661453711539936, training acc: 0.8512968420982361\n",
      "validation loss: 0.3752998679464314, validation acc: 0.8406466245651245, test loss: 0.39657747772981494, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 420 -------------------\n",
      "average training loss: 0.3428275596511467, training acc: 0.85014408826828\n",
      "validation loss: 0.37555247435371997, validation acc: 0.8406466245651245, test loss: 0.3959395193284558, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 421 -------------------\n",
      "average training loss: 0.3408996480170863, training acc: 0.850432276725769\n",
      "validation loss: 0.37974487574693794, validation acc: 0.8545034527778625, test loss: 0.40053904537231694, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 422 -------------------\n",
      "average training loss: 0.34735585282790216, training acc: 0.8440921902656555\n",
      "validation loss: 0.3724905404215035, validation acc: 0.8360277414321899, test loss: 0.40014162426170663, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 423 -------------------\n",
      "average training loss: 0.3441464771283119, training acc: 0.8472622632980347\n",
      "validation loss: 0.369712604630378, validation acc: 0.8383371829986572, test loss: 0.397532057240262, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 424 -------------------\n",
      "average training loss: 0.3479875786417843, training acc: 0.8469740748405457\n",
      "validation loss: 0.3768548648203573, validation acc: 0.8360277414321899, test loss: 0.39968833725573283, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 425 -------------------\n",
      "average training loss: 0.34946426613530096, training acc: 0.849567711353302\n",
      "validation loss: 0.3741312848258128, validation acc: 0.8475750684738159, test loss: 0.3994891047477722, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 426 -------------------\n",
      "average training loss: 0.34294145861345343, training acc: 0.85014408826828\n",
      "validation loss: 0.36887828696707975, validation acc: 0.8521940112113953, test loss: 0.39095085845564914, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 427 -------------------\n",
      "average training loss: 0.34656341919294353, training acc: 0.8455331325531006\n",
      "validation loss: 0.3744900536976652, validation acc: 0.8498845100402832, test loss: 0.3999387988571747, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 428 -------------------\n",
      "average training loss: 0.325775924745829, training acc: 0.8579250574111938\n",
      "validation loss: 0.3674245785046283, validation acc: 0.8406466245651245, test loss: 0.386489168290169, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 429 -------------------\n",
      "average training loss: 0.3446085717904808, training acc: 0.8518732190132141\n",
      "validation loss: 0.3713610924883372, validation acc: 0.8521940112113953, test loss: 0.3946262652972876, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 430 -------------------\n",
      "average training loss: 0.35037823741992546, training acc: 0.848414957523346\n",
      "validation loss: 0.371056473612236, validation acc: 0.8521940112113953, test loss: 0.3909106098012441, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 431 -------------------\n",
      "average training loss: 0.3356844715666702, training acc: 0.8550432324409485\n",
      "validation loss: 0.3762609099600172, validation acc: 0.8475750684738159, test loss: 0.3958531624985181, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 432 -------------------\n",
      "average training loss: 0.34386655262292976, training acc: 0.8518732190132141\n",
      "validation loss: 0.37765190506585733, validation acc: 0.8429561257362366, test loss: 0.39720972878043004, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 433 -------------------\n",
      "average training loss: 0.33854408757143817, training acc: 0.8518732190132141\n",
      "validation loss: 0.3772768820485761, validation acc: 0.8498845100402832, test loss: 0.39484048493996193, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 434 -------------------\n",
      "average training loss: 0.3406162695857221, training acc: 0.8541786670684814\n",
      "validation loss: 0.37269355830508993, validation acc: 0.8429561257362366, test loss: 0.3915890291813881, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 435 -------------------\n",
      "average training loss: 0.3371117678860079, training acc: 0.8567723631858826\n",
      "validation loss: 0.3734546737736821, validation acc: 0.8429561257362366, test loss: 0.3887116573922645, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 436 -------------------\n",
      "average training loss: 0.3432329018452669, training acc: 0.8518732190132141\n",
      "validation loss: 0.37111919754386496, validation acc: 0.8475750684738159, test loss: 0.3916180207982041, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 437 -------------------\n",
      "average training loss: 0.3434151710969227, training acc: 0.8518732190132141\n",
      "validation loss: 0.37395403043191006, validation acc: 0.8406466245651245, test loss: 0.3934750805527384, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 438 -------------------\n",
      "average training loss: 0.34054268607145083, training acc: 0.8507204651832581\n",
      "validation loss: 0.3749936666631479, validation acc: 0.8452655673027039, test loss: 0.39465486357838325, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 439 -------------------\n",
      "average training loss: 0.33912916752034716, training acc: 0.848414957523346\n",
      "validation loss: 0.37720256013804315, validation acc: 0.8360277414321899, test loss: 0.3953936998195912, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 440 -------------------\n",
      "average training loss: 0.34707034620153115, training acc: 0.8530259132385254\n",
      "validation loss: 0.3768533270479897, validation acc: 0.8383371829986572, test loss: 0.3933596251197674, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 441 -------------------\n",
      "average training loss: 0.3422395949404934, training acc: 0.8524495959281921\n",
      "validation loss: 0.38019279126198063, validation acc: 0.8452655673027039, test loss: 0.39598985023212874, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 442 -------------------\n",
      "average training loss: 0.33988234167140224, training acc: 0.849567711353302\n",
      "validation loss: 0.3782052169747067, validation acc: 0.8475750684738159, test loss: 0.39226495958693014, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 443 -------------------\n",
      "average training loss: 0.34326673280608755, training acc: 0.8515850305557251\n",
      "validation loss: 0.37100273006797385, validation acc: 0.8521940112113953, test loss: 0.3901631811522119, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 444 -------------------\n",
      "average training loss: 0.3487369324013548, training acc: 0.8394812941551208\n",
      "validation loss: 0.374909533951689, validation acc: 0.8406466245651245, test loss: 0.3860547734845069, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 445 -------------------\n",
      "average training loss: 0.33740534229306046, training acc: 0.8556196093559265\n",
      "validation loss: 0.37445072328440054, validation acc: 0.8429561257362366, test loss: 0.387675018354495, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 446 -------------------\n",
      "average training loss: 0.3492320191963262, training acc: 0.848703145980835\n",
      "validation loss: 0.3718584127689836, validation acc: 0.8383371829986572, test loss: 0.39344355683722254, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 447 -------------------\n",
      "average training loss: 0.34605953744921286, training acc: 0.8463976979255676\n",
      "validation loss: 0.3734083426300831, validation acc: 0.8452655673027039, test loss: 0.38774858476928853, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 448 -------------------\n",
      "average training loss: 0.34197626895451066, training acc: 0.8458213210105896\n",
      "validation loss: 0.37317510189548614, validation acc: 0.8498845100402832, test loss: 0.3871654005643959, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 449 -------------------\n",
      "average training loss: 0.3434884727344733, training acc: 0.8561959862709045\n",
      "validation loss: 0.3756705030867581, validation acc: 0.8475750684738159, test loss: 0.38910783998977205, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 450 -------------------\n",
      "average training loss: 0.34899046924340965, training acc: 0.8507204651832581\n",
      "validation loss: 0.3825371329960186, validation acc: 0.8429561257362366, test loss: 0.39021091279895626, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 451 -------------------\n",
      "average training loss: 0.33921938086792786, training acc: 0.8556196093559265\n",
      "validation loss: 0.37152649407287897, validation acc: 0.8383371829986572, test loss: 0.38983162262472687, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 452 -------------------\n",
      "average training loss: 0.33544600901411314, training acc: 0.8593659996986389\n",
      "validation loss: 0.37600457970447804, validation acc: 0.8383371829986572, test loss: 0.3896861986905199, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 453 -------------------\n",
      "average training loss: 0.333889661398676, training acc: 0.860230565071106\n",
      "validation loss: 0.37848952302734973, validation acc: 0.8429561257362366, test loss: 0.38636691779035576, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 454 -------------------\n",
      "average training loss: 0.3434171027855502, training acc: 0.8550432324409485\n",
      "validation loss: 0.38917763771549346, validation acc: 0.8267898559570312, test loss: 0.4001529676848293, test acc: 0.8133640289306641\n",
      "\n",
      "------------------ EPOCH 455 -------------------\n",
      "average training loss: 0.350228838910287, training acc: 0.8461095094680786\n",
      "validation loss: 0.37037588903156843, validation acc: 0.8383371829986572, test loss: 0.3898530521425783, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 456 -------------------\n",
      "average training loss: 0.33404664031366793, training acc: 0.8561959862709045\n",
      "validation loss: 0.36850990945567735, validation acc: 0.8475750684738159, test loss: 0.39507315194551845, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 457 -------------------\n",
      "average training loss: 0.33875954633830946, training acc: 0.8561959862709045\n",
      "validation loss: 0.3716196191887702, validation acc: 0.8406466245651245, test loss: 0.3908430050869691, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 458 -------------------\n",
      "average training loss: 0.3400766743706695, training acc: 0.848703145980835\n",
      "validation loss: 0.37618118586353444, validation acc: 0.8360277414321899, test loss: 0.38804125442482906, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 459 -------------------\n",
      "average training loss: 0.3410571409491366, training acc: 0.8541786670684814\n",
      "validation loss: 0.37778849034540113, validation acc: 0.8314087986946106, test loss: 0.38587281808325774, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 460 -------------------\n",
      "average training loss: 0.3425586347277639, training acc: 0.8533141016960144\n",
      "validation loss: 0.3753732710664723, validation acc: 0.8360277414321899, test loss: 0.38910154387148843, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 461 -------------------\n",
      "average training loss: 0.3416147592088331, training acc: 0.8510086536407471\n",
      "validation loss: 0.37733296191637417, validation acc: 0.8429561257362366, test loss: 0.38920440734256795, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 462 -------------------\n",
      "average training loss: 0.34443090424929296, training acc: 0.8481268286705017\n",
      "validation loss: 0.37735156680581755, validation acc: 0.8406466245651245, test loss: 0.39317148937607693, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 463 -------------------\n",
      "average training loss: 0.34049201776040044, training acc: 0.8550432324409485\n",
      "validation loss: 0.3723834143256262, validation acc: 0.8383371829986572, test loss: 0.3840006062512024, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 464 -------------------\n",
      "average training loss: 0.34117361160279697, training acc: 0.8515850305557251\n",
      "validation loss: 0.37019369596709856, validation acc: 0.8406466245651245, test loss: 0.39267350904952547, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 465 -------------------\n",
      "average training loss: 0.34012769594659725, training acc: 0.8481268286705017\n",
      "validation loss: 0.38224275760386944, validation acc: 0.8429561257362366, test loss: 0.3997325599193573, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 466 -------------------\n",
      "average training loss: 0.3443155371490061, training acc: 0.8524495959281921\n",
      "validation loss: 0.37863701787961795, validation acc: 0.8406466245651245, test loss: 0.38960553863630865, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 467 -------------------\n",
      "average training loss: 0.3381506197562479, training acc: 0.8541786670684814\n",
      "validation loss: 0.3690617557632209, validation acc: 0.8498845100402832, test loss: 0.38821904162108073, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 468 -------------------\n",
      "average training loss: 0.3388107656401928, training acc: 0.8481268286705017\n",
      "validation loss: 0.37897572868980023, validation acc: 0.8360277414321899, test loss: 0.3919679043205103, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 469 -------------------\n",
      "average training loss: 0.3457292053988069, training acc: 0.8533141016960144\n",
      "validation loss: 0.3773414629945008, validation acc: 0.8452655673027039, test loss: 0.3852120852140787, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 470 -------------------\n",
      "average training loss: 0.34160494440227146, training acc: 0.8541786670684814\n",
      "validation loss: 0.3804631080083583, validation acc: 0.8406466245651245, test loss: 0.38554153052343204, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 471 -------------------\n",
      "average training loss: 0.33502506321720155, training acc: 0.8533141016960144\n",
      "validation loss: 0.37556861059456925, validation acc: 0.8360277414321899, test loss: 0.3936274666940012, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 472 -------------------\n",
      "average training loss: 0.3508633347512666, training acc: 0.8475504517555237\n",
      "validation loss: 0.3726878895462933, validation acc: 0.8591223955154419, test loss: 0.39708698812168314, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 473 -------------------\n",
      "average training loss: 0.33740770809932125, training acc: 0.8524495959281921\n",
      "validation loss: 0.3735925209137701, validation acc: 0.8406466245651245, test loss: 0.3816295300485901, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 474 -------------------\n",
      "average training loss: 0.3369744359416302, training acc: 0.8538904786109924\n",
      "validation loss: 0.37641334602360355, validation acc: 0.8475750684738159, test loss: 0.38348532904128324, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 475 -------------------\n",
      "average training loss: 0.3381192638997729, training acc: 0.8527377247810364\n",
      "validation loss: 0.37060564385581124, validation acc: 0.8406466245651245, test loss: 0.3859334349082912, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 476 -------------------\n",
      "average training loss: 0.33752010741220084, training acc: 0.8585014343261719\n",
      "validation loss: 0.37220244528511154, validation acc: 0.8429561257362366, test loss: 0.3875305471332392, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 477 -------------------\n",
      "average training loss: 0.32949990195568424, training acc: 0.8561959862709045\n",
      "validation loss: 0.3751599718623447, validation acc: 0.8383371829986572, test loss: 0.38549044233862706, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 478 -------------------\n",
      "average training loss: 0.3366191917348664, training acc: 0.8561959862709045\n",
      "validation loss: 0.3755328167006717, validation acc: 0.8360277414321899, test loss: 0.3898420828278713, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 479 -------------------\n",
      "average training loss: 0.340146518921646, training acc: 0.8512968420982361\n",
      "validation loss: 0.3716331296664779, validation acc: 0.8475750684738159, test loss: 0.3864680219630492, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 480 -------------------\n",
      "average training loss: 0.33294975396879123, training acc: 0.8507204651832581\n",
      "validation loss: 0.37172023608662563, validation acc: 0.8452655673027039, test loss: 0.3923627938817723, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 481 -------------------\n",
      "average training loss: 0.3249506942047509, training acc: 0.8579250574111938\n",
      "validation loss: 0.38189611381374744, validation acc: 0.8429561257362366, test loss: 0.39056869846884557, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 482 -------------------\n",
      "average training loss: 0.3415264563876545, training acc: 0.8593659996986389\n",
      "validation loss: 0.38082428118600276, validation acc: 0.8452655673027039, test loss: 0.38928696691715226, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 483 -------------------\n",
      "average training loss: 0.33706595093784825, training acc: 0.8536022901535034\n",
      "validation loss: 0.3690457344055176, validation acc: 0.8452655673027039, test loss: 0.3808120325688393, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 484 -------------------\n",
      "average training loss: 0.3419744250925542, training acc: 0.8541786670684814\n",
      "validation loss: 0.37436965753405876, validation acc: 0.8452655673027039, test loss: 0.3912502145437601, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 485 -------------------\n",
      "average training loss: 0.3372066534561795, training acc: 0.8576368689537048\n",
      "validation loss: 0.3730310407651734, validation acc: 0.8383371829986572, test loss: 0.3880378095785044, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 486 -------------------\n",
      "average training loss: 0.34048886225271635, training acc: 0.8561959862709045\n",
      "validation loss: 0.37187298905739585, validation acc: 0.8406466245651245, test loss: 0.3883542356677868, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 487 -------------------\n",
      "average training loss: 0.3408793762025641, training acc: 0.8553314208984375\n",
      "validation loss: 0.38192156485972867, validation acc: 0.8452655673027039, test loss: 0.3852866466418939, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 488 -------------------\n",
      "average training loss: 0.34180702257912166, training acc: 0.8518732190132141\n",
      "validation loss: 0.3749363331750791, validation acc: 0.8475750684738159, test loss: 0.3831579884351124, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 489 -------------------\n",
      "average training loss: 0.34069577245100774, training acc: 0.848703145980835\n",
      "validation loss: 0.37801923070635113, validation acc: 0.8475750684738159, test loss: 0.3842784408050748, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 490 -------------------\n",
      "average training loss: 0.3336225457339191, training acc: 0.8579250574111938\n",
      "validation loss: 0.3770976407187326, validation acc: 0.8475750684738159, test loss: 0.38399264285091983, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 491 -------------------\n",
      "average training loss: 0.3410812322962868, training acc: 0.8515850305557251\n",
      "validation loss: 0.37649287695434236, validation acc: 0.8429561257362366, test loss: 0.38607735458057596, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 492 -------------------\n",
      "average training loss: 0.3254666174866624, training acc: 0.8631123900413513\n",
      "validation loss: 0.3810747242468293, validation acc: 0.8452655673027039, test loss: 0.3901289869014019, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 493 -------------------\n",
      "average training loss: 0.33206587760180495, training acc: 0.8579250574111938\n",
      "validation loss: 0.37938955666557433, validation acc: 0.8429561257362366, test loss: 0.3878372770300659, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 494 -------------------\n",
      "average training loss: 0.32925095924039394, training acc: 0.860518753528595\n",
      "validation loss: 0.38137015178456285, validation acc: 0.8452655673027039, test loss: 0.38531156179542364, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 495 -------------------\n",
      "average training loss: 0.33428298765712927, training acc: 0.8550432324409485\n",
      "validation loss: 0.3789382469818889, validation acc: 0.8383371829986572, test loss: 0.3840571457889223, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 496 -------------------\n",
      "average training loss: 0.33656966243078795, training acc: 0.8573486804962158\n",
      "validation loss: 0.3830028627462651, validation acc: 0.8475750684738159, test loss: 0.38460486344478095, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 497 -------------------\n",
      "average training loss: 0.3368517954772075, training acc: 0.8533141016960144\n",
      "validation loss: 0.3831390293512476, validation acc: 0.8383371829986572, test loss: 0.3886047634660923, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 498 -------------------\n",
      "average training loss: 0.3458883025288925, training acc: 0.8472622632980347\n",
      "validation loss: 0.3872079686497763, validation acc: 0.8429561257362366, test loss: 0.38817725299690176, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 499 -------------------\n",
      "average training loss: 0.33933910631308983, training acc: 0.8564841747283936\n",
      "validation loss: 0.3805725779126866, validation acc: 0.8498845100402832, test loss: 0.3867759424420546, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 500 -------------------\n",
      "average training loss: 0.34633829611694433, training acc: 0.8512968420982361\n",
      "validation loss: 0.37193477140044284, validation acc: 0.8521940112113953, test loss: 0.3858157775369108, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 501 -------------------\n",
      "average training loss: 0.3370940466950881, training acc: 0.8564841747283936\n",
      "validation loss: 0.38182170565501883, validation acc: 0.8452655673027039, test loss: 0.40024360135403647, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 502 -------------------\n",
      "average training loss: 0.34344643307178785, training acc: 0.8544668555259705\n",
      "validation loss: 0.3933454798663267, validation acc: 0.8406466245651245, test loss: 0.3969446259984223, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 503 -------------------\n",
      "average training loss: 0.32919177707574554, training acc: 0.8616714477539062\n",
      "validation loss: 0.3770524404839986, validation acc: 0.8475750684738159, test loss: 0.3874936083220117, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 504 -------------------\n",
      "average training loss: 0.34441410552184243, training acc: 0.8452449440956116\n",
      "validation loss: 0.37590311089968353, validation acc: 0.8498845100402832, test loss: 0.39110347092975667, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 505 -------------------\n",
      "average training loss: 0.3386314800390249, training acc: 0.8573486804962158\n",
      "validation loss: 0.3734137246960319, validation acc: 0.8475750684738159, test loss: 0.39214929169224155, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 506 -------------------\n",
      "average training loss: 0.3357065148758957, training acc: 0.8564841747283936\n",
      "validation loss: 0.3678391302854235, validation acc: 0.8498845100402832, test loss: 0.3921480925951136, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 507 -------------------\n",
      "average training loss: 0.3306377107111109, training acc: 0.8553314208984375\n",
      "validation loss: 0.3724745218792269, validation acc: 0.8452655673027039, test loss: 0.39587065426435336, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 508 -------------------\n",
      "average training loss: 0.34137269375303636, training acc: 0.8510086536407471\n",
      "validation loss: 0.37049623403681037, validation acc: 0.8475750684738159, test loss: 0.3946583662439601, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 509 -------------------\n",
      "average training loss: 0.3344802490142993, training acc: 0.8570604920387268\n",
      "validation loss: 0.371562866777319, validation acc: 0.8406466245651245, test loss: 0.38564291472808554, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 510 -------------------\n",
      "average training loss: 0.34298993195339994, training acc: 0.849279522895813\n",
      "validation loss: 0.37871264237137986, validation acc: 0.8406466245651245, test loss: 0.3900206720774075, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 511 -------------------\n",
      "average training loss: 0.3422257739288319, training acc: 0.8478386402130127\n",
      "validation loss: 0.3733275551949778, validation acc: 0.8545034527778625, test loss: 0.3924245834350586, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 512 -------------------\n",
      "average training loss: 0.334689403336055, training acc: 0.8576368689537048\n",
      "validation loss: 0.3782640496431957, validation acc: 0.8383371829986572, test loss: 0.3921675268680819, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 513 -------------------\n",
      "average training loss: 0.3324391274957217, training acc: 0.8593659996986389\n",
      "validation loss: 0.369600109034969, validation acc: 0.8521940112113953, test loss: 0.386926799325899, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 514 -------------------\n",
      "average training loss: 0.3325234024256725, training acc: 0.8559077978134155\n",
      "validation loss: 0.3760083254581223, validation acc: 0.8452655673027039, test loss: 0.38919562609514335, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 515 -------------------\n",
      "average training loss: 0.35015411506640465, training acc: 0.8472622632980347\n",
      "validation loss: 0.3649214848120641, validation acc: 0.8521940112113953, test loss: 0.38022873972967475, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 516 -------------------\n",
      "average training loss: 0.33411392347098084, training acc: 0.8585014343261719\n",
      "validation loss: 0.37017072517476324, validation acc: 0.8498845100402832, test loss: 0.39074359264241937, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 517 -------------------\n",
      "average training loss: 0.34023226646421967, training acc: 0.8530259132385254\n",
      "validation loss: 0.3732672966158335, validation acc: 0.8452655673027039, test loss: 0.38568819736555426, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 518 -------------------\n",
      "average training loss: 0.3394292981549024, training acc: 0.8567723631858826\n",
      "validation loss: 0.37421153925256245, validation acc: 0.8429561257362366, test loss: 0.39089673043396067, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 519 -------------------\n",
      "average training loss: 0.32781345791019695, training acc: 0.8613832592964172\n",
      "validation loss: 0.3801155809982581, validation acc: 0.8429561257362366, test loss: 0.38662510808162426, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 520 -------------------\n",
      "average training loss: 0.3354881471790567, training acc: 0.8530259132385254\n",
      "validation loss: 0.37553511662966643, validation acc: 0.8383371829986572, test loss: 0.3787536956198205, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 521 -------------------\n",
      "average training loss: 0.33850288514788623, training acc: 0.8478386402130127\n",
      "validation loss: 0.3729408383369446, validation acc: 0.8475750684738159, test loss: 0.37641500671338374, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 522 -------------------\n",
      "average training loss: 0.3456938354872833, training acc: 0.8466858863830566\n",
      "validation loss: 0.37182905610805284, validation acc: 0.8406466245651245, test loss: 0.3738323384166313, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 523 -------------------\n",
      "average training loss: 0.33747111239419547, training acc: 0.849279522895813\n",
      "validation loss: 0.37720530346241965, validation acc: 0.8475750684738159, test loss: 0.3767406396602156, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 524 -------------------\n",
      "average training loss: 0.3390510407407964, training acc: 0.8570604920387268\n",
      "validation loss: 0.37968385535451127, validation acc: 0.8429561257362366, test loss: 0.38300108538794625, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 525 -------------------\n",
      "average training loss: 0.3369971583487321, training acc: 0.8585014343261719\n",
      "validation loss: 0.3808769903012684, validation acc: 0.8406466245651245, test loss: 0.38045458488750017, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 526 -------------------\n",
      "average training loss: 0.3259734513951997, training acc: 0.8639769554138184\n",
      "validation loss: 0.37688598963796816, validation acc: 0.8383371829986572, test loss: 0.3776566345021472, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 527 -------------------\n",
      "average training loss: 0.3297970093808188, training acc: 0.8585014343261719\n",
      "validation loss: 0.38432552723840635, validation acc: 0.8406466245651245, test loss: 0.37739257658681563, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 528 -------------------\n",
      "average training loss: 0.3338312756130606, training acc: 0.8564841747283936\n",
      "validation loss: 0.3828246883258292, validation acc: 0.8498845100402832, test loss: 0.39101514096633627, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 529 -------------------\n",
      "average training loss: 0.3385085097822744, training acc: 0.8538904786109924\n",
      "validation loss: 0.374226011713529, validation acc: 0.8452655673027039, test loss: 0.3802245150788039, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 530 -------------------\n",
      "average training loss: 0.3307602603085103, training acc: 0.8585014343261719\n",
      "validation loss: 0.37143253758206346, validation acc: 0.8429561257362366, test loss: 0.3869370200117612, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 531 -------------------\n",
      "average training loss: 0.33065884228398545, training acc: 0.8654178380966187\n",
      "validation loss: 0.37189078578201856, validation acc: 0.8545034527778625, test loss: 0.3818975604624243, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 532 -------------------\n",
      "average training loss: 0.3331020885482645, training acc: 0.8538904786109924\n",
      "validation loss: 0.37377533845363126, validation acc: 0.8429561257362366, test loss: 0.3910008218431253, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 533 -------------------\n",
      "average training loss: 0.33340907706650946, training acc: 0.8515850305557251\n",
      "validation loss: 0.3754704251954083, validation acc: 0.8383371829986572, test loss: 0.3854445239640601, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 534 -------------------\n",
      "average training loss: 0.3343006595926257, training acc: 0.8559077978134155\n",
      "validation loss: 0.37940311837031543, validation acc: 0.8337182402610779, test loss: 0.3917665073673846, test acc: 0.8179723620414734\n",
      "\n",
      "------------------ EPOCH 535 -------------------\n",
      "average training loss: 0.33504204536205756, training acc: 0.8550432324409485\n",
      "validation loss: 0.3779589124538931, validation acc: 0.8498845100402832, test loss: 0.38590266352974323, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 536 -------------------\n",
      "average training loss: 0.34270928040018, training acc: 0.8553314208984375\n",
      "validation loss: 0.3724269581967235, validation acc: 0.8452655673027039, test loss: 0.3964426459804658, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 537 -------------------\n",
      "average training loss: 0.330227694550921, training acc: 0.8567723631858826\n",
      "validation loss: 0.3764747495887466, validation acc: 0.8406466245651245, test loss: 0.38287220352805706, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 538 -------------------\n",
      "average training loss: 0.3422861192171443, training acc: 0.8510086536407471\n",
      "validation loss: 0.37543799223438384, validation acc: 0.8498845100402832, test loss: 0.3843916540596342, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 539 -------------------\n",
      "average training loss: 0.3296365185326733, training acc: 0.8559077978134155\n",
      "validation loss: 0.3720654344984463, validation acc: 0.8521940112113953, test loss: 0.3842360248214089, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 540 -------------------\n",
      "average training loss: 0.33523814987380496, training acc: 0.8538904786109924\n",
      "validation loss: 0.3767916815621512, validation acc: 0.8383371829986572, test loss: 0.3839243427949018, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 541 -------------------\n",
      "average training loss: 0.3301751624438536, training acc: 0.8648415207862854\n",
      "validation loss: 0.3719691803103768, validation acc: 0.8406466245651245, test loss: 0.3904915390201428, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 542 -------------------\n",
      "average training loss: 0.33669932864241364, training acc: 0.8507204651832581\n",
      "validation loss: 0.3750034440222973, validation acc: 0.8475750684738159, test loss: 0.3832315106271049, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 543 -------------------\n",
      "average training loss: 0.3358210758963648, training acc: 0.8553314208984375\n",
      "validation loss: 0.3707275071314403, validation acc: 0.8498845100402832, test loss: 0.38426800930554966, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 544 -------------------\n",
      "average training loss: 0.3357104451065448, training acc: 0.8561959862709045\n",
      "validation loss: 0.37258838014119233, validation acc: 0.8383371829986572, test loss: 0.381724242103814, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 545 -------------------\n",
      "average training loss: 0.3284000237668282, training acc: 0.8564841747283936\n",
      "validation loss: 0.37048753635949255, validation acc: 0.8406466245651245, test loss: 0.37963318989573536, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 546 -------------------\n",
      "average training loss: 0.3383535058422803, training acc: 0.8481268286705017\n",
      "validation loss: 0.378361134004483, validation acc: 0.8429561257362366, test loss: 0.38813205207547835, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 547 -------------------\n",
      "average training loss: 0.3304786046403286, training acc: 0.8559077978134155\n",
      "validation loss: 0.36865435506341643, validation acc: 0.8545034527778625, test loss: 0.3835470099602976, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 548 -------------------\n",
      "average training loss: 0.31972650572958183, training acc: 0.8619596362113953\n",
      "validation loss: 0.3728925195707154, validation acc: 0.8406466245651245, test loss: 0.3831280344916928, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 549 -------------------\n",
      "average training loss: 0.33515987205574077, training acc: 0.8559077978134155\n",
      "validation loss: 0.3702550748800902, validation acc: 0.8475750684738159, test loss: 0.3896011266565543, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 550 -------------------\n",
      "average training loss: 0.3331345215826282, training acc: 0.8556196093559265\n",
      "validation loss: 0.37514199254699565, validation acc: 0.8406466245651245, test loss: 0.39534123688249545, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 551 -------------------\n",
      "average training loss: 0.3240427594535289, training acc: 0.8599423766136169\n",
      "validation loss: 0.37144723768058463, validation acc: 0.8498845100402832, test loss: 0.39926370799816147, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 552 -------------------\n",
      "average training loss: 0.3322756346261467, training acc: 0.8556196093559265\n",
      "validation loss: 0.36959922354891556, validation acc: 0.8406466245651245, test loss: 0.3903947045451485, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 553 -------------------\n",
      "average training loss: 0.3351451941972507, training acc: 0.8536022901535034\n",
      "validation loss: 0.38300917980857707, validation acc: 0.8429561257362366, test loss: 0.3904812176656064, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 554 -------------------\n",
      "average training loss: 0.34534131970460547, training acc: 0.8507204651832581\n",
      "validation loss: 0.38880961288779564, validation acc: 0.8337182402610779, test loss: 0.4004957268040301, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 555 -------------------\n",
      "average training loss: 0.3317491480871305, training acc: 0.8576368689537048\n",
      "validation loss: 0.37513800013449883, validation acc: 0.8406466245651245, test loss: 0.3889545174787671, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 556 -------------------\n",
      "average training loss: 0.33144750826984043, training acc: 0.8622478246688843\n",
      "validation loss: 0.37015778334459404, validation acc: 0.8475750684738159, test loss: 0.39262432175847245, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 557 -------------------\n",
      "average training loss: 0.3407481553231605, training acc: 0.8536022901535034\n",
      "validation loss: 0.3790544232327817, validation acc: 0.8360277414321899, test loss: 0.38779651019979733, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 558 -------------------\n",
      "average training loss: 0.33078824037777244, training acc: 0.8579250574111938\n",
      "validation loss: 0.37725801017427224, validation acc: 0.8383371829986572, test loss: 0.38541332216856117, test acc: 0.8502303957939148\n",
      "\n",
      "------------------ EPOCH 559 -------------------\n",
      "average training loss: 0.3360379603221712, training acc: 0.8521614074707031\n",
      "validation loss: 0.3766258780582709, validation acc: 0.8498845100402832, test loss: 0.39139792954866787, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 560 -------------------\n",
      "average training loss: 0.3348697817463009, training acc: 0.8521614074707031\n",
      "validation loss: 0.37503986081220037, validation acc: 0.8452655673027039, test loss: 0.38963968907633134, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 561 -------------------\n",
      "average training loss: 0.3301226524695196, training acc: 0.8587896227836609\n",
      "validation loss: 0.3767175635983867, validation acc: 0.8475750684738159, test loss: 0.3868548918154932, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 562 -------------------\n",
      "average training loss: 0.3250852563968653, training acc: 0.8616714477539062\n",
      "validation loss: 0.38156121193263937, validation acc: 0.8429561257362366, test loss: 0.3940968663187071, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 563 -------------------\n",
      "average training loss: 0.3230878659902457, training acc: 0.8579250574111938\n",
      "validation loss: 0.3718026332591536, validation acc: 0.8521940112113953, test loss: 0.385582031742219, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 564 -------------------\n",
      "average training loss: 0.32710095011019913, training acc: 0.8628242015838623\n",
      "validation loss: 0.3819243274114099, validation acc: 0.8475750684738159, test loss: 0.39385485717777835, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 565 -------------------\n",
      "average training loss: 0.33366233907446735, training acc: 0.850432276725769\n",
      "validation loss: 0.38467354008129667, validation acc: 0.8383371829986572, test loss: 0.38799611489344304, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 566 -------------------\n",
      "average training loss: 0.33252171497867156, training acc: 0.8550432324409485\n",
      "validation loss: 0.3763717495351343, validation acc: 0.8452655673027039, test loss: 0.39254184142785137, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 567 -------------------\n",
      "average training loss: 0.32764701315923794, training acc: 0.8521614074707031\n",
      "validation loss: 0.3792999467130081, validation acc: 0.8452655673027039, test loss: 0.38353050592857574, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 568 -------------------\n",
      "average training loss: 0.33768840725895993, training acc: 0.8512968420982361\n",
      "validation loss: 0.3917343927555919, validation acc: 0.8429561257362366, test loss: 0.3950663656683012, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 569 -------------------\n",
      "average training loss: 0.3395988955449646, training acc: 0.8461095094680786\n",
      "validation loss: 0.3795135239576964, validation acc: 0.8383371829986572, test loss: 0.3882532732277971, test acc: 0.8202764987945557\n",
      "\n",
      "------------------ EPOCH 570 -------------------\n",
      "average training loss: 0.33115522207890874, training acc: 0.8576368689537048\n",
      "validation loss: 0.3848771249643669, validation acc: 0.8429561257362366, test loss: 0.3899163088765562, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 571 -------------------\n",
      "average training loss: 0.33410275624877095, training acc: 0.8648415207862854\n",
      "validation loss: 0.382680808344195, validation acc: 0.8475750684738159, test loss: 0.38672893786210616, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 572 -------------------\n",
      "average training loss: 0.3312588606684627, training acc: 0.8570604920387268\n",
      "validation loss: 0.3817347320406118, validation acc: 0.8406466245651245, test loss: 0.39032591240746634, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 573 -------------------\n",
      "average training loss: 0.32769940167407824, training acc: 0.8567723631858826\n",
      "validation loss: 0.3861221101838872, validation acc: 0.8429561257362366, test loss: 0.3876449623690223, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 574 -------------------\n",
      "average training loss: 0.3438175401701364, training acc: 0.8553314208984375\n",
      "validation loss: 0.38027350329858367, validation acc: 0.8452655673027039, test loss: 0.38539914683812226, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 575 -------------------\n",
      "average training loss: 0.341299015335116, training acc: 0.8538904786109924\n",
      "validation loss: 0.3802234685640731, validation acc: 0.8452655673027039, test loss: 0.37717474372156207, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 576 -------------------\n",
      "average training loss: 0.33716908135915696, training acc: 0.8556196093559265\n",
      "validation loss: 0.3774666180533747, validation acc: 0.8498845100402832, test loss: 0.3772864481820489, test acc: 0.8548387289047241\n",
      "\n",
      "------------------ EPOCH 577 -------------------\n",
      "average training loss: 0.33845048429986585, training acc: 0.8538904786109924\n",
      "validation loss: 0.3801708870357083, validation acc: 0.8429561257362366, test loss: 0.3810623181031047, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 578 -------------------\n",
      "average training loss: 0.32937664892041374, training acc: 0.8538904786109924\n",
      "validation loss: 0.38293363160801375, validation acc: 0.8429561257362366, test loss: 0.3867116902830414, test acc: 0.8225806355476379\n",
      "\n",
      "------------------ EPOCH 579 -------------------\n",
      "average training loss: 0.3363643102412265, training acc: 0.8556196093559265\n",
      "validation loss: 0.38723472598510955, validation acc: 0.8383371829986572, test loss: 0.39152881915118837, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 580 -------------------\n",
      "average training loss: 0.33396678864097046, training acc: 0.8524495959281921\n",
      "validation loss: 0.3792258860191442, validation acc: 0.8406466245651245, test loss: 0.385269891419169, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 581 -------------------\n",
      "average training loss: 0.31978695699220433, training acc: 0.8680115342140198\n",
      "validation loss: 0.3850704783118815, validation acc: 0.8452655673027039, test loss: 0.38518617820629875, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 582 -------------------\n",
      "average training loss: 0.333347900301991, training acc: 0.8570604920387268\n",
      "validation loss: 0.3776630524391403, validation acc: 0.8383371829986572, test loss: 0.39003725260633476, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 583 -------------------\n",
      "average training loss: 0.32769931269653935, training acc: 0.861095130443573\n",
      "validation loss: 0.37716304253323285, validation acc: 0.8521940112113953, test loss: 0.3827217965631441, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 584 -------------------\n",
      "average training loss: 0.33229221443965046, training acc: 0.8538904786109924\n",
      "validation loss: 0.37782539454748004, validation acc: 0.8429561257362366, test loss: 0.38914952808261466, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 585 -------------------\n",
      "average training loss: 0.3225064415065974, training acc: 0.8619596362113953\n",
      "validation loss: 0.37645605508632923, validation acc: 0.8545034527778625, test loss: 0.3884588260255102, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 586 -------------------\n",
      "average training loss: 0.3235326529408051, training acc: 0.8556196093559265\n",
      "validation loss: 0.38166830115329287, validation acc: 0.8498845100402832, test loss: 0.3869848222501816, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 587 -------------------\n",
      "average training loss: 0.33791311998188667, training acc: 0.8530259132385254\n",
      "validation loss: 0.38311225326929227, validation acc: 0.8383371829986572, test loss: 0.39385421155235184, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 588 -------------------\n",
      "average training loss: 0.33061957912417583, training acc: 0.8573486804962158\n",
      "validation loss: 0.3802379325444248, validation acc: 0.8498845100402832, test loss: 0.38998927581145465, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 589 -------------------\n",
      "average training loss: 0.3280549485504799, training acc: 0.8585014343261719\n",
      "validation loss: 0.3823487424905399, validation acc: 0.8498845100402832, test loss: 0.38927196920742085, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 590 -------------------\n",
      "average training loss: 0.33183053932890766, training acc: 0.8579250574111938\n",
      "validation loss: 0.38318056211493534, validation acc: 0.8498845100402832, test loss: 0.40015102847380574, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 591 -------------------\n",
      "average training loss: 0.328312910273027, training acc: 0.8550432324409485\n",
      "validation loss: 0.37258454566727034, validation acc: 0.8498845100402832, test loss: 0.3882073603467458, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 592 -------------------\n",
      "average training loss: 0.34089245299784526, training acc: 0.8556196093559265\n",
      "validation loss: 0.36830678568457675, validation acc: 0.8521940112113953, test loss: 0.3866332045623234, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 593 -------------------\n",
      "average training loss: 0.32257441309755747, training acc: 0.8576368689537048\n",
      "validation loss: 0.37597892869452726, validation acc: 0.8452655673027039, test loss: 0.39315994695034995, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 594 -------------------\n",
      "average training loss: 0.32622977376671275, training acc: 0.8593659996986389\n",
      "validation loss: 0.38176121552419, validation acc: 0.8452655673027039, test loss: 0.3997944896946305, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 595 -------------------\n",
      "average training loss: 0.3328259376095076, training acc: 0.8530259132385254\n",
      "validation loss: 0.3852282112232551, validation acc: 0.8545034527778625, test loss: 0.39516954364315154, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 596 -------------------\n",
      "average training loss: 0.33536474651493325, training acc: 0.8544668555259705\n",
      "validation loss: 0.3802596627292545, validation acc: 0.8429561257362366, test loss: 0.3920992387604604, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 597 -------------------\n",
      "average training loss: 0.33648490994223945, training acc: 0.8579250574111938\n",
      "validation loss: 0.3801527434642414, validation acc: 0.8406466245651245, test loss: 0.38599561271579585, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 598 -------------------\n",
      "average training loss: 0.326348962924666, training acc: 0.861095130443573\n",
      "validation loss: 0.3730717612439037, validation acc: 0.8545034527778625, test loss: 0.3889640450202924, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 599 -------------------\n",
      "average training loss: 0.32932231000246165, training acc: 0.8587896227836609\n",
      "validation loss: 0.36890017436946043, validation acc: 0.8475750684738159, test loss: 0.3826234137407646, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 600 -------------------\n",
      "average training loss: 0.3352297613445551, training acc: 0.8512968420982361\n",
      "validation loss: 0.3780244164477845, validation acc: 0.8521940112113953, test loss: 0.38721327215845136, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 601 -------------------\n",
      "average training loss: 0.3405378827186414, training acc: 0.8544668555259705\n",
      "validation loss: 0.3721452142511095, validation acc: 0.8452655673027039, test loss: 0.38582696782828474, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 602 -------------------\n",
      "average training loss: 0.321706662157427, training acc: 0.8613832592964172\n",
      "validation loss: 0.3825324860998013, validation acc: 0.8475750684738159, test loss: 0.38921234176455555, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 603 -------------------\n",
      "average training loss: 0.3314136466821951, training acc: 0.8587896227836609\n",
      "validation loss: 0.3791421274847699, validation acc: 0.8452655673027039, test loss: 0.38450330413431616, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 604 -------------------\n",
      "average training loss: 0.3182881145381103, training acc: 0.8639769554138184\n",
      "validation loss: 0.381040488794652, validation acc: 0.8475750684738159, test loss: 0.38844015384050007, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 605 -------------------\n",
      "average training loss: 0.33166192747674, training acc: 0.8593659996986389\n",
      "validation loss: 0.3814912162343478, validation acc: 0.8475750684738159, test loss: 0.3853958553982221, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 606 -------------------\n",
      "average training loss: 0.32089917561849873, training acc: 0.8648415207862854\n",
      "validation loss: 0.3853057263084271, validation acc: 0.8475750684738159, test loss: 0.3925163531633017, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 607 -------------------\n",
      "average training loss: 0.3355268473583958, training acc: 0.8533141016960144\n",
      "validation loss: 0.3852917347360866, validation acc: 0.8406466245651245, test loss: 0.3830499252141346, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 608 -------------------\n",
      "average training loss: 0.3277598939041583, training acc: 0.860518753528595\n",
      "validation loss: 0.3829218646348347, validation acc: 0.8406466245651245, test loss: 0.38739716951748193, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 609 -------------------\n",
      "average training loss: 0.3251041435886185, training acc: 0.8570604920387268\n",
      "validation loss: 0.37951650188952546, validation acc: 0.8406466245651245, test loss: 0.3846028638050853, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 610 -------------------\n",
      "average training loss: 0.3239909739075202, training acc: 0.8596541881561279\n",
      "validation loss: 0.38066283953354657, validation acc: 0.8452655673027039, test loss: 0.3785131212478409, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 611 -------------------\n",
      "average training loss: 0.3419060265811788, training acc: 0.850432276725769\n",
      "validation loss: 0.3882733812117906, validation acc: 0.8360277414321899, test loss: 0.3846191285942007, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 612 -------------------\n",
      "average training loss: 0.3287669480362268, training acc: 0.8590778112411499\n",
      "validation loss: 0.37583679482684157, validation acc: 0.8383371829986572, test loss: 0.3814441884442958, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 613 -------------------\n",
      "average training loss: 0.3314015648206991, training acc: 0.8553314208984375\n",
      "validation loss: 0.37420105961610645, validation acc: 0.8452655673027039, test loss: 0.38144632899266784, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 614 -------------------\n",
      "average training loss: 0.32655310555218964, training acc: 0.8582132458686829\n",
      "validation loss: 0.3752898085639224, validation acc: 0.8429561257362366, test loss: 0.39484444342999964, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 615 -------------------\n",
      "average training loss: 0.31941107715928246, training acc: 0.860806941986084\n",
      "validation loss: 0.38213985760091085, validation acc: 0.8452655673027039, test loss: 0.3896452954837254, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 616 -------------------\n",
      "average training loss: 0.32803733565278287, training acc: 0.8550432324409485\n",
      "validation loss: 0.37978790315889543, validation acc: 0.8498845100402832, test loss: 0.3915966100956438, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 617 -------------------\n",
      "average training loss: 0.3349426211472547, training acc: 0.8556196093559265\n",
      "validation loss: 0.3790738114288875, validation acc: 0.8498845100402832, test loss: 0.38139810979640976, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 618 -------------------\n",
      "average training loss: 0.33702806962670095, training acc: 0.8541786670684814\n",
      "validation loss: 0.37991822967606204, validation acc: 0.8452655673027039, test loss: 0.38010124264774237, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 619 -------------------\n",
      "average training loss: 0.32613264665823505, training acc: 0.8536022901535034\n",
      "validation loss: 0.38407355052534886, validation acc: 0.8498845100402832, test loss: 0.3819847252511758, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 620 -------------------\n",
      "average training loss: 0.3197499588346619, training acc: 0.8642651438713074\n",
      "validation loss: 0.3856123554679106, validation acc: 0.8498845100402832, test loss: 0.38671230390873923, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 621 -------------------\n",
      "average training loss: 0.32154711203204106, training acc: 0.8527377247810364\n",
      "validation loss: 0.3839434989586404, validation acc: 0.8383371829986572, test loss: 0.3842774184618128, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 622 -------------------\n",
      "average training loss: 0.3302698539467985, training acc: 0.8616714477539062\n",
      "validation loss: 0.38209097197253583, validation acc: 0.8429561257362366, test loss: 0.3843799348800413, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 623 -------------------\n",
      "average training loss: 0.3308167165912881, training acc: 0.8550432324409485\n",
      "validation loss: 0.38324908699308124, validation acc: 0.8360277414321899, test loss: 0.3931300079767605, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 624 -------------------\n",
      "average training loss: 0.32670791198953086, training acc: 0.8559077978134155\n",
      "validation loss: 0.3728983944050178, validation acc: 0.8452655673027039, test loss: 0.38769918597788305, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 625 -------------------\n",
      "average training loss: 0.33114580501740537, training acc: 0.8556196093559265\n",
      "validation loss: 0.3734948256735428, validation acc: 0.8406466245651245, test loss: 0.38214518727245417, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 626 -------------------\n",
      "average training loss: 0.32378347560720416, training acc: 0.8631123900413513\n",
      "validation loss: 0.3726459488203998, validation acc: 0.8429561257362366, test loss: 0.3826325189682745, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 627 -------------------\n",
      "average training loss: 0.32818328712446887, training acc: 0.8541786670684814\n",
      "validation loss: 0.37806904920235207, validation acc: 0.8429561257362366, test loss: 0.3835155946043779, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 628 -------------------\n",
      "average training loss: 0.3347504946958778, training acc: 0.8547550439834595\n",
      "validation loss: 0.38052731855399047, validation acc: 0.8383371829986572, test loss: 0.3892912838590859, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 629 -------------------\n",
      "average training loss: 0.32782694922400485, training acc: 0.8544668555259705\n",
      "validation loss: 0.3781995585849208, validation acc: 0.8475750684738159, test loss: 0.3815434555853567, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 630 -------------------\n",
      "average training loss: 0.3366733069206864, training acc: 0.8512968420982361\n",
      "validation loss: 0.3822323578293972, validation acc: 0.8521940112113953, test loss: 0.3872666979715022, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 631 -------------------\n",
      "average training loss: 0.3335793167095019, training acc: 0.8596541881561279\n",
      "validation loss: 0.37988942332806125, validation acc: 0.8498845100402832, test loss: 0.3894570958779155, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 632 -------------------\n",
      "average training loss: 0.33672897130336815, training acc: 0.8530259132385254\n",
      "validation loss: 0.3806903417896016, validation acc: 0.8360277414321899, test loss: 0.38077265134055494, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 633 -------------------\n",
      "average training loss: 0.32920702683822567, training acc: 0.8547550439834595\n",
      "validation loss: 0.37669270495939916, validation acc: 0.8498845100402832, test loss: 0.37568228118430635, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 634 -------------------\n",
      "average training loss: 0.3324300737820716, training acc: 0.8547550439834595\n",
      "validation loss: 0.38633716147616165, validation acc: 0.8452655673027039, test loss: 0.38707891793294985, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 635 -------------------\n",
      "average training loss: 0.333070443755268, training acc: 0.849567711353302\n",
      "validation loss: 0.37763294158718, validation acc: 0.8429561257362366, test loss: 0.38442730477878023, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 636 -------------------\n",
      "average training loss: 0.32611121789522746, training acc: 0.8567723631858826\n",
      "validation loss: 0.3841908327582794, validation acc: 0.8429561257362366, test loss: 0.38663089165489795, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 637 -------------------\n",
      "average training loss: 0.3379171063989315, training acc: 0.8515850305557251\n",
      "validation loss: 0.37978968237127575, validation acc: 0.8521940112113953, test loss: 0.3832627941386491, test acc: 0.8502303957939148\n",
      "\n",
      "------------------ EPOCH 638 -------------------\n",
      "average training loss: 0.33071607588347507, training acc: 0.860806941986084\n",
      "validation loss: 0.3764220523532085, validation acc: 0.8429561257362366, test loss: 0.381069565011609, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 639 -------------------\n",
      "average training loss: 0.3328208319391916, training acc: 0.861095130443573\n",
      "validation loss: 0.37446068117420794, validation acc: 0.8406466245651245, test loss: 0.38649522942332076, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 640 -------------------\n",
      "average training loss: 0.3282340112611952, training acc: 0.8541786670684814\n",
      "validation loss: 0.3764213055097562, validation acc: 0.8498845100402832, test loss: 0.38804932865678987, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 641 -------------------\n",
      "average training loss: 0.3244343393560102, training acc: 0.8585014343261719\n",
      "validation loss: 0.3828855588139477, validation acc: 0.8314087986946106, test loss: 0.38305872005801045, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 642 -------------------\n",
      "average training loss: 0.31875179664202313, training acc: 0.860518753528595\n",
      "validation loss: 0.37907098151297064, validation acc: 0.8314087986946106, test loss: 0.37997630787884584, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 643 -------------------\n",
      "average training loss: 0.326489937374159, training acc: 0.8544668555259705\n",
      "validation loss: 0.3798659287976779, validation acc: 0.8475750684738159, test loss: 0.381642112534167, test acc: 0.8502303957939148\n",
      "\n",
      "------------------ EPOCH 644 -------------------\n",
      "average training loss: 0.32597491047224325, training acc: 0.8567723631858826\n",
      "validation loss: 0.38660144661703416, validation acc: 0.8360277414321899, test loss: 0.38109214130085184, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 645 -------------------\n",
      "average training loss: 0.328935146649564, training acc: 0.8590778112411499\n",
      "validation loss: 0.37888931651269236, validation acc: 0.8452655673027039, test loss: 0.38329102600225107, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 646 -------------------\n",
      "average training loss: 0.328579183528334, training acc: 0.8567723631858826\n",
      "validation loss: 0.3834311072178151, validation acc: 0.8429561257362366, test loss: 0.38020565515289656, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 647 -------------------\n",
      "average training loss: 0.33100610043026873, training acc: 0.8553314208984375\n",
      "validation loss: 0.38148871304527404, validation acc: 0.8452655673027039, test loss: 0.38282714296595843, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 648 -------------------\n",
      "average training loss: 0.32691940798367825, training acc: 0.8622478246688843\n",
      "validation loss: 0.37568753401529953, validation acc: 0.8498845100402832, test loss: 0.3853015291251345, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 649 -------------------\n",
      "average training loss: 0.34417054100064104, training acc: 0.8510086536407471\n",
      "validation loss: 0.38090303080147864, validation acc: 0.8475750684738159, test loss: 0.38598630450288274, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 650 -------------------\n",
      "average training loss: 0.3288821436486258, training acc: 0.8590778112411499\n",
      "validation loss: 0.386054529778419, validation acc: 0.8406466245651245, test loss: 0.3890052130145411, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 651 -------------------\n",
      "average training loss: 0.32782006270603764, training acc: 0.8613832592964172\n",
      "validation loss: 0.3807766348260888, validation acc: 0.8406466245651245, test loss: 0.3812402297274858, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 652 -------------------\n",
      "average training loss: 0.342424990507299, training acc: 0.8524495959281921\n",
      "validation loss: 0.3797263019645269, validation acc: 0.8475750684738159, test loss: 0.380953616123595, test acc: 0.8502303957939148\n",
      "\n",
      "------------------ EPOCH 653 -------------------\n",
      "average training loss: 0.32998508457148107, training acc: 0.8576368689537048\n",
      "validation loss: 0.37870783327911306, validation acc: 0.8545034527778625, test loss: 0.3836261903360692, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 654 -------------------\n",
      "average training loss: 0.32462306836840055, training acc: 0.8587896227836609\n",
      "validation loss: 0.37510474733493293, validation acc: 0.8545034527778625, test loss: 0.38460497345243183, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 655 -------------------\n",
      "average training loss: 0.3221461116924066, training acc: 0.8628242015838623\n",
      "validation loss: 0.3712743294129174, validation acc: 0.8498845100402832, test loss: 0.389697256313491, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 656 -------------------\n",
      "average training loss: 0.33197936634680725, training acc: 0.8544668555259705\n",
      "validation loss: 0.36669054490080627, validation acc: 0.8429561257362366, test loss: 0.3824964044830217, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 657 -------------------\n",
      "average training loss: 0.32854893791572504, training acc: 0.8564841747283936\n",
      "validation loss: 0.3771822231431161, validation acc: 0.8498845100402832, test loss: 0.3808438797150889, test acc: 0.8502303957939148\n",
      "\n",
      "------------------ EPOCH 658 -------------------\n",
      "average training loss: 0.33677516620853104, training acc: 0.8556196093559265\n",
      "validation loss: 0.37903874686786104, validation acc: 0.8429561257362366, test loss: 0.39030482623434287, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 659 -------------------\n",
      "average training loss: 0.3193139807119837, training acc: 0.8685879111289978\n",
      "validation loss: 0.38746636426119213, validation acc: 0.8383371829986572, test loss: 0.3936691135854765, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 660 -------------------\n",
      "average training loss: 0.32842754233811017, training acc: 0.8576368689537048\n",
      "validation loss: 0.38072363942998894, validation acc: 0.8429561257362366, test loss: 0.38950048998204245, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 661 -------------------\n",
      "average training loss: 0.3222033933706861, training acc: 0.8685879111289978\n",
      "validation loss: 0.3802392390054492, validation acc: 0.8429561257362366, test loss: 0.3851304882407738, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 662 -------------------\n",
      "average training loss: 0.32886838421697917, training acc: 0.860806941986084\n",
      "validation loss: 0.3813469256124189, validation acc: 0.8383371829986572, test loss: 0.38340887482265174, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 663 -------------------\n",
      "average training loss: 0.32109415697776617, training acc: 0.8671469688415527\n",
      "validation loss: 0.38077162226773625, validation acc: 0.8337182402610779, test loss: 0.38530645158983046, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 664 -------------------\n",
      "average training loss: 0.3174169334537358, training acc: 0.8593659996986389\n",
      "validation loss: 0.38100990048751304, validation acc: 0.8360277414321899, test loss: 0.38155294233752834, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 665 -------------------\n",
      "average training loss: 0.32193578327080014, training acc: 0.860806941986084\n",
      "validation loss: 0.3891237176233722, validation acc: 0.8568129539489746, test loss: 0.38968158784549906, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 666 -------------------\n",
      "average training loss: 0.3215760352202726, training acc: 0.8625360131263733\n",
      "validation loss: 0.37769014244118043, validation acc: 0.8406466245651245, test loss: 0.3822611001779407, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 667 -------------------\n",
      "average training loss: 0.33585467853875944, training acc: 0.8536022901535034\n",
      "validation loss: 0.37708195329811167, validation acc: 0.8337182402610779, test loss: 0.37957693203803033, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 668 -------------------\n",
      "average training loss: 0.33395530930170064, training acc: 0.8613832592964172\n",
      "validation loss: 0.3783090843857708, validation acc: 0.8521940112113953, test loss: 0.38264688712111267, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 669 -------------------\n",
      "average training loss: 0.3249333681909083, training acc: 0.8622478246688843\n",
      "validation loss: 0.37830763265559203, validation acc: 0.8521940112113953, test loss: 0.3845949575373654, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 670 -------------------\n",
      "average training loss: 0.33046878664740914, training acc: 0.8582132458686829\n",
      "validation loss: 0.3843679830500607, validation acc: 0.8383371829986572, test loss: 0.39149640864490914, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 671 -------------------\n",
      "average training loss: 0.33040718477466263, training acc: 0.8582132458686829\n",
      "validation loss: 0.3816809875349845, validation acc: 0.8521940112113953, test loss: 0.3833203918648206, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 672 -------------------\n",
      "average training loss: 0.3317051951840563, training acc: 0.8590778112411499\n",
      "validation loss: 0.37593833477266375, validation acc: 0.8545034527778625, test loss: 0.38670319758252614, test acc: 0.8525345325469971\n",
      "\n",
      "------------------ EPOCH 673 -------------------\n",
      "average training loss: 0.33483654839504695, training acc: 0.8466858863830566\n",
      "validation loss: 0.37997190716079854, validation acc: 0.8429561257362366, test loss: 0.3829026564200353, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 674 -------------------\n",
      "average training loss: 0.3326164759029916, training acc: 0.8518732190132141\n",
      "validation loss: 0.38338653592195376, validation acc: 0.8337182402610779, test loss: 0.39064401731513065, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 675 -------------------\n",
      "average training loss: 0.3286398624824172, training acc: 0.8593659996986389\n",
      "validation loss: 0.37902831722239744, validation acc: 0.8452655673027039, test loss: 0.39482466649899284, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 676 -------------------\n",
      "average training loss: 0.32353843428215995, training acc: 0.8622478246688843\n",
      "validation loss: 0.3814174034353775, validation acc: 0.8452655673027039, test loss: 0.3963332643157326, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 677 -------------------\n",
      "average training loss: 0.3339208623174288, training acc: 0.8524495959281921\n",
      "validation loss: 0.37432152609671315, validation acc: 0.8568129539489746, test loss: 0.3893102342906635, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 678 -------------------\n",
      "average training loss: 0.3213565755045036, training acc: 0.8622478246688843\n",
      "validation loss: 0.3829596565203733, validation acc: 0.8360277414321899, test loss: 0.38731760624366973, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 679 -------------------\n",
      "average training loss: 0.33264476610535504, training acc: 0.8573486804962158\n",
      "validation loss: 0.3829285196856969, validation acc: 0.8360277414321899, test loss: 0.3835760691473561, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 680 -------------------\n",
      "average training loss: 0.32581486693376766, training acc: 0.8570604920387268\n",
      "validation loss: 0.38163218039521424, validation acc: 0.8452655673027039, test loss: 0.3819477781996749, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 681 -------------------\n",
      "average training loss: 0.32761653378305244, training acc: 0.8622478246688843\n",
      "validation loss: 0.38397835565876853, validation acc: 0.8475750684738159, test loss: 0.3850279303465021, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 682 -------------------\n",
      "average training loss: 0.32505237083957245, training acc: 0.8553314208984375\n",
      "validation loss: 0.3861910393161158, validation acc: 0.8475750684738159, test loss: 0.38776261356019753, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 683 -------------------\n",
      "average training loss: 0.32429116370011474, training acc: 0.8616714477539062\n",
      "validation loss: 0.38787502180870775, validation acc: 0.8406466245651245, test loss: 0.3814999148043619, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 684 -------------------\n",
      "average training loss: 0.3260715762029807, training acc: 0.8553314208984375\n",
      "validation loss: 0.39345506273107045, validation acc: 0.8452655673027039, test loss: 0.3859410353245274, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 685 -------------------\n",
      "average training loss: 0.3260434942733314, training acc: 0.8541786670684814\n",
      "validation loss: 0.3904840313069831, validation acc: 0.8498845100402832, test loss: 0.3891464780827272, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 686 -------------------\n",
      "average training loss: 0.3277546706907344, training acc: 0.861095130443573\n",
      "validation loss: 0.38971871844909156, validation acc: 0.8475750684738159, test loss: 0.38485281011475947, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 687 -------------------\n",
      "average training loss: 0.31974598789421216, training acc: 0.8596541881561279\n",
      "validation loss: 0.39145342360169105, validation acc: 0.8406466245651245, test loss: 0.3813724545289844, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 688 -------------------\n",
      "average training loss: 0.33794471608630516, training acc: 0.8541786670684814\n",
      "validation loss: 0.38841551796357204, validation acc: 0.8383371829986572, test loss: 0.3815947181892835, test acc: 0.8525345325469971\n",
      "\n",
      "------------------ EPOCH 689 -------------------\n",
      "average training loss: 0.3228071453420161, training acc: 0.860806941986084\n",
      "validation loss: 0.3900092406206966, validation acc: 0.8360277414321899, test loss: 0.3892096638130153, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 690 -------------------\n",
      "average training loss: 0.3225282007404294, training acc: 0.861095130443573\n",
      "validation loss: 0.39056575363544827, validation acc: 0.8452655673027039, test loss: 0.386452755208389, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 691 -------------------\n",
      "average training loss: 0.3293484577442109, training acc: 0.8587896227836609\n",
      "validation loss: 0.3872185544484222, validation acc: 0.8429561257362366, test loss: 0.38263551334631607, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 692 -------------------\n",
      "average training loss: 0.31985396807234984, training acc: 0.8590778112411499\n",
      "validation loss: 0.38767970514736966, validation acc: 0.8360277414321899, test loss: 0.3856853355185777, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 693 -------------------\n",
      "average training loss: 0.3309846515786064, training acc: 0.8596541881561279\n",
      "validation loss: 0.3839197148513135, validation acc: 0.8475750684738159, test loss: 0.3856319881254627, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 694 -------------------\n",
      "average training loss: 0.3298811310134635, training acc: 0.8550432324409485\n",
      "validation loss: 0.3811415629590162, validation acc: 0.8452655673027039, test loss: 0.3857930239444504, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 695 -------------------\n",
      "average training loss: 0.3249102310247998, training acc: 0.8561959862709045\n",
      "validation loss: 0.3797342296569578, validation acc: 0.8475750684738159, test loss: 0.3842074707631142, test acc: 0.8456221222877502\n",
      "\n",
      "------------------ EPOCH 696 -------------------\n",
      "average training loss: 0.3193744132687104, training acc: 0.8622478246688843\n",
      "validation loss: 0.3842486528344967, validation acc: 0.8429561257362366, test loss: 0.3905178053038461, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 697 -------------------\n",
      "average training loss: 0.3278677097486831, training acc: 0.8590778112411499\n",
      "validation loss: 0.3825869229944071, validation acc: 0.8452655673027039, test loss: 0.3941844119454309, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 698 -------------------\n",
      "average training loss: 0.331632484422637, training acc: 0.8634005784988403\n",
      "validation loss: 0.37730251321320163, validation acc: 0.8429561257362366, test loss: 0.38941003141864655, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 699 -------------------\n",
      "average training loss: 0.3130162679152805, training acc: 0.8634005784988403\n",
      "validation loss: 0.3779449100318592, validation acc: 0.8498845100402832, test loss: 0.3906494130461996, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 700 -------------------\n",
      "average training loss: 0.33025661926791716, training acc: 0.8530259132385254\n",
      "validation loss: 0.3790724607107277, validation acc: 0.8383371829986572, test loss: 0.39154543689868415, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 701 -------------------\n",
      "average training loss: 0.3259979760097152, training acc: 0.8527377247810364\n",
      "validation loss: 0.38291519015066083, validation acc: 0.8498845100402832, test loss: 0.3916385849500032, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 702 -------------------\n",
      "average training loss: 0.32997938088793577, training acc: 0.8553314208984375\n",
      "validation loss: 0.38835475727709756, validation acc: 0.8314087986946106, test loss: 0.399090102054007, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 703 -------------------\n",
      "average training loss: 0.32762184056321897, training acc: 0.860518753528595\n",
      "validation loss: 0.38103627375743354, validation acc: 0.8429561257362366, test loss: 0.3879714311542599, test acc: 0.8479262590408325\n",
      "\n",
      "------------------ EPOCH 704 -------------------\n",
      "average training loss: 0.33740553964111925, training acc: 0.8561959862709045\n",
      "validation loss: 0.3801788763928523, validation acc: 0.8406466245651245, test loss: 0.39228826637641623, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 705 -------------------\n",
      "average training loss: 0.32557485881731213, training acc: 0.8582132458686829\n",
      "validation loss: 0.37654536056079074, validation acc: 0.8452655673027039, test loss: 0.38847636311284955, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 706 -------------------\n",
      "average training loss: 0.3295313326099764, training acc: 0.8547550439834595\n",
      "validation loss: 0.3766674437830525, validation acc: 0.8429561257362366, test loss: 0.3933165795792083, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 707 -------------------\n",
      "average training loss: 0.3233007060176014, training acc: 0.8561959862709045\n",
      "validation loss: 0.37939599935772234, validation acc: 0.8406466245651245, test loss: 0.39077214848610664, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 708 -------------------\n",
      "average training loss: 0.31750541116387426, training acc: 0.8636887669563293\n",
      "validation loss: 0.38448598397217587, validation acc: 0.8452655673027039, test loss: 0.3914482423237392, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 709 -------------------\n",
      "average training loss: 0.3269070785396037, training acc: 0.8576368689537048\n",
      "validation loss: 0.38505290022918154, validation acc: 0.8429561257362366, test loss: 0.389357939293857, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 710 -------------------\n",
      "average training loss: 0.3207124842518688, training acc: 0.8648415207862854\n",
      "validation loss: 0.3815499579164839, validation acc: 0.8429561257362366, test loss: 0.3928267598701512, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 711 -------------------\n",
      "average training loss: 0.3286965710972503, training acc: 0.8587896227836609\n",
      "validation loss: 0.38268353889614753, validation acc: 0.8498845100402832, test loss: 0.39034336558135424, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 712 -------------------\n",
      "average training loss: 0.3227696677621572, training acc: 0.8593659996986389\n",
      "validation loss: 0.382520460656711, validation acc: 0.8429561257362366, test loss: 0.3842195749008161, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 713 -------------------\n",
      "average training loss: 0.32505404751651223, training acc: 0.8593659996986389\n",
      "validation loss: 0.3753286539684243, validation acc: 0.8545034527778625, test loss: 0.38477743921741364, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 714 -------------------\n",
      "average training loss: 0.32590191432138, training acc: 0.8576368689537048\n",
      "validation loss: 0.38145019670235947, validation acc: 0.8383371829986572, test loss: 0.39095036458859245, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 715 -------------------\n",
      "average training loss: 0.31504140704097255, training acc: 0.8631123900413513\n",
      "validation loss: 0.38643884521475586, validation acc: 0.8498845100402832, test loss: 0.39393835985166137, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 716 -------------------\n",
      "average training loss: 0.32547814834014827, training acc: 0.8579250574111938\n",
      "validation loss: 0.3846417254154583, validation acc: 0.8452655673027039, test loss: 0.3907558744953525, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 717 -------------------\n",
      "average training loss: 0.33038437444212115, training acc: 0.8547550439834595\n",
      "validation loss: 0.37873119637713454, validation acc: 0.8383371829986572, test loss: 0.39113532974972703, test acc: 0.8248847723007202\n",
      "\n",
      "------------------ EPOCH 718 -------------------\n",
      "average training loss: 0.33834792518134765, training acc: 0.8541786670684814\n",
      "validation loss: 0.3872386600290026, validation acc: 0.8452655673027039, test loss: 0.39454221107443355, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 719 -------------------\n",
      "average training loss: 0.3316309743037485, training acc: 0.860230565071106\n",
      "validation loss: 0.3775317957324366, validation acc: 0.8498845100402832, test loss: 0.38947433301930057, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 720 -------------------\n",
      "average training loss: 0.3234586081175021, training acc: 0.8628242015838623\n",
      "validation loss: 0.3821173796455981, validation acc: 0.8475750684738159, test loss: 0.39218864421690663, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 721 -------------------\n",
      "average training loss: 0.3302726111855218, training acc: 0.8631123900413513\n",
      "validation loss: 0.38354907614020156, validation acc: 0.8406466245651245, test loss: 0.3960006725952922, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 722 -------------------\n",
      "average training loss: 0.31801710147679024, training acc: 0.8651297092437744\n",
      "validation loss: 0.3823191690074134, validation acc: 0.8475750684738159, test loss: 0.39636914864663153, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 723 -------------------\n",
      "average training loss: 0.32526642452571164, training acc: 0.860518753528595\n",
      "validation loss: 0.3835487378083067, validation acc: 0.8360277414321899, test loss: 0.3911037622234239, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 724 -------------------\n",
      "average training loss: 0.32175239505788433, training acc: 0.8570604920387268\n",
      "validation loss: 0.38767465173099447, validation acc: 0.8475750684738159, test loss: 0.39259238506791777, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 725 -------------------\n",
      "average training loss: 0.325042768514122, training acc: 0.8561959862709045\n",
      "validation loss: 0.394903194931795, validation acc: 0.8452655673027039, test loss: 0.3985727943033667, test acc: 0.8271889686584473\n",
      "\n",
      "------------------ EPOCH 726 -------------------\n",
      "average training loss: 0.32847267169430205, training acc: 0.8587896227836609\n",
      "validation loss: 0.381286300547112, validation acc: 0.8475750684738159, test loss: 0.38843917695608005, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 727 -------------------\n",
      "average training loss: 0.3305436284810047, training acc: 0.8599423766136169\n",
      "validation loss: 0.3784559076557511, validation acc: 0.8475750684738159, test loss: 0.3910996481295555, test acc: 0.843317985534668\n",
      "\n",
      "------------------ EPOCH 728 -------------------\n",
      "average training loss: 0.3350259345099974, training acc: 0.8541786670684814\n",
      "validation loss: 0.3864027684048024, validation acc: 0.8452655673027039, test loss: 0.3886176068936625, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 729 -------------------\n",
      "average training loss: 0.32317200225780607, training acc: 0.8631123900413513\n",
      "validation loss: 0.38318708374203625, validation acc: 0.8406466245651245, test loss: 0.3904023508322404, test acc: 0.8317972421646118\n",
      "\n",
      "------------------ EPOCH 730 -------------------\n",
      "average training loss: 0.31489602921675536, training acc: 0.8711815476417542\n",
      "validation loss: 0.3853326031963946, validation acc: 0.8429561257362366, test loss: 0.39422076185178095, test acc: 0.8294931054115295\n",
      "\n",
      "------------------ EPOCH 731 -------------------\n",
      "average training loss: 0.3317847639751709, training acc: 0.860518753528595\n",
      "validation loss: 0.39100109033870256, validation acc: 0.8360277414321899, test loss: 0.3965559531741428, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 732 -------------------\n",
      "average training loss: 0.3192254595608807, training acc: 0.8556196093559265\n",
      "validation loss: 0.39530820595229277, validation acc: 0.8337182402610779, test loss: 0.39303820048059734, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 733 -------------------\n",
      "average training loss: 0.32022539686400886, training acc: 0.8544668555259705\n",
      "validation loss: 0.393051541895361, validation acc: 0.8406466245651245, test loss: 0.39273115141051157, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 734 -------------------\n",
      "average training loss: 0.3200169738242537, training acc: 0.8639769554138184\n",
      "validation loss: 0.39254144678742103, validation acc: 0.8383371829986572, test loss: 0.397096717000557, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 735 -------------------\n",
      "average training loss: 0.3182247116861151, training acc: 0.8582132458686829\n",
      "validation loss: 0.3841634131796349, validation acc: 0.8475750684738159, test loss: 0.3926702122534475, test acc: 0.8387096524238586\n",
      "\n",
      "------------------ EPOCH 736 -------------------\n",
      "average training loss: 0.32096876124140167, training acc: 0.861095130443573\n",
      "validation loss: 0.3838253877541986, validation acc: 0.8475750684738159, test loss: 0.39259208663268025, test acc: 0.8410138487815857\n",
      "\n",
      "------------------ EPOCH 737 -------------------\n",
      "average training loss: 0.3291751585707541, training acc: 0.8576368689537048\n",
      "validation loss: 0.38219952061429, validation acc: 0.8406466245651245, test loss: 0.3978454713722528, test acc: 0.8341013789176941\n",
      "\n",
      "------------------ EPOCH 738 -------------------\n",
      "average training loss: 0.3315344487384005, training acc: 0.8576368689537048\n",
      "validation loss: 0.3845871114923108, validation acc: 0.8429561257362366, test loss: 0.3952156045744496, test acc: 0.8364055156707764\n",
      "\n",
      "------------------ EPOCH 739 -------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     28\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_index, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     31\u001b[0m     batch_size_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m/\u001b[39mbatch_size\n\u001b[0;32m     32\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size_ratio\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(\n\u001b[0;32m     28\u001b[0m         batch,\n\u001b[0;32m     29\u001b[0m         follow_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch,\n\u001b[0;32m     30\u001b[0m         exclude_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys,\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m collate(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     99\u001b[0m         data_list\u001b[38;5;241m=\u001b[39mdata_list,\n\u001b[0;32m    100\u001b[0m         increment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m         add_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_list[\u001b[38;5;241m0\u001b[39m], Batch),\n\u001b[0;32m    102\u001b[0m         follow_batch\u001b[38;5;241m=\u001b[39mfollow_batch,\n\u001b[0;32m    103\u001b[0m         exclude_keys\u001b[38;5;241m=\u001b[39mexclude_keys,\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch_geometric\\data\\collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[0;32m    110\u001b[0m                                increment)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch_geometric\\data\\collate.py:167\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    165\u001b[0m     values \u001b[38;5;241m=\u001b[39m [value\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[0;32m    166\u001b[0m sizes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([value\u001b[38;5;241m.\u001b[39msize(cat_dim \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values])\n\u001b[1;32m--> 167\u001b[0m slices \u001b[38;5;241m=\u001b[39m cumsum(sizes)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[0;32m    169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m get_incs(key, values, data_list, stores)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\Lib\\site-packages\\torch_geometric\\utils\\functions.py:21\u001b[0m, in \u001b[0;36mcumsum\u001b[1;34m(x, dim)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the cumulative sum of elements of :obj:`x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mIn contrast to :meth:`torch.cumsum`, prepends the output with zero.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:dim] \u001b[38;5;241m+\u001b[39m (x\u001b[38;5;241m.\u001b[39msize(dim) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, ) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnew_empty(size)\n\u001b[0;32m     23\u001b[0m out\u001b[38;5;241m.\u001b[39mnarrow(dim, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mzero_()\n\u001b[0;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39mcumsum(x, dim\u001b[38;5;241m=\u001b[39mdim, out\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mnarrow(dim, \u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(dim)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = datasetLoader.loadDataset('MUTAG', batch_size)               # TODO: adjs matrix is not compatible with GraphConv. Needs to be converted to edge_index (see RE_PGE datasets/utils)\n",
    "\n",
    "temp = next(iter(train_loader))\n",
    "gnn = networks.GraphGNN(features = temp.x.shape[1], labels=2)       # temp.y.shape[0] is wrong!!! TODO: how do I get #labels from loader?? take from loader.dataset?\n",
    "\n",
    "gnn.apply(weights_init)\n",
    "\n",
    "gnn_optimizer = torch.optim.Adam(params = gnn.parameters(), lr = learning_rate_gnn)         # TODO: understand params\n",
    "\n",
    "print(f\"Training on {len(train_loader.dataset)} graphs with batch size {batch_size}\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()           # cross entropy loss?!\n",
    "\n",
    "early_stop_counter = 0\n",
    "min_val_loss = 1000.0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(0, epochs_gnn) :\n",
    "    print(f'\\n------------------ EPOCH {epoch + 1} -------------------')\n",
    "\n",
    "    gnn.train()\n",
    "\n",
    "    train_acc_sum = 0\n",
    "    num_batches = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        batch_size_ratio = len(data)/batch_size\n",
    "        num_batches += batch_size_ratio\n",
    "        \n",
    "        gnn_optimizer.zero_grad()       # Reset parameters\n",
    "\n",
    "        # real label\n",
    "        label = data.y\n",
    "\n",
    "        # get model embeddings (node representations)?\n",
    "        # predicted label\n",
    "        out = gnn.forward(data.x, data.edge_index, data.batch)\n",
    "\n",
    "        # calc cross entropy(???)loss between real label and predicted label\n",
    "        # needs to be calculated across batch\n",
    "        currLoss = loss(out, label)\n",
    "\n",
    "        #print(currLoss)\n",
    "\n",
    "        # loss backward\n",
    "        currLoss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(gnn.parameters(), max_norm=2)    # clip gradient above 2(for ba2motfis according to reimplementation) to stop \"overlearning\"?\n",
    "\n",
    "        # optimizer step\n",
    "        gnn_optimizer.step()\n",
    "\n",
    "        preds = out.argmax(dim=1)\n",
    "        train_acc_sum += torch.sum(preds == data.y)                     # TODO: works with batches?\n",
    "        \n",
    "        train_loss += batch_size_ratio * currLoss.item()                       # use currLoss instead of currLoss.item() for batches\n",
    "\n",
    "    final_train_acc = train_acc_sum/(num_batches*batch_size)                # num_batches*batch_size = len(train_loader.dataset) = #graphs\n",
    "\n",
    "    gnn.eval()\n",
    "\n",
    "    # avg loss\n",
    "    print(f\"average training loss: {train_loss/num_batches}, training acc: {final_train_acc}\")\n",
    "\n",
    "    val_acc, valLoss, test_acc, testLoss = evaluation.evaluateGNN(gnn, val_loader, test_loader)\n",
    "    print(f\"validation loss: {valLoss}, validation acc: {val_acc}, test loss: {testLoss}, test acc: {test_acc}\")\n",
    "\n",
    "    if(val_acc > best_val_acc):\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "    if(valLoss < min_val_loss):\n",
    "        min_val_loss = valLoss\n",
    "        early_stop_counter = 0\n",
    "    elif(valLoss > min_val_loss):\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stopping:\n",
    "            print(\"Stopping training due to early stopping threshold\")\n",
    "            print(f\"highest validation accuracy: {best_val_acc} in epoch {best_epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"highest validation accuracy: {best_val_acc} in epoch {best_epoch}\")\n",
    "\n",
    "\n",
    "# move training loop Explainer\n",
    "#mlp_optimizer = torch.optim.Adam(lr = learning_rate_mlp)\n",
    "\n",
    "\n",
    "\"\"\"for i in enumerate(adjs):\n",
    "    #out = gnn.forward(feas[i], adjs[i].nonzero().t().contiguous())\n",
    "\n",
    "for epoch in epochs_graphgnn:\n",
    "    for graph in adjs:\n",
    "        # calculate latent variables? MLP?\n",
    "        for k in # k in monte carlo sampling?!\n",
    "            # sammple graph\n",
    "            # pred label on sampled graph\n",
    "\n",
    "    # compute loss\n",
    "    # update params with backprop\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval values with batch size 64 and learning rate 0,001 on 1000 Epochs MUTAG\n",
    "average training loss: 0.12170956794397975, training acc: 0.9521613717079163\n",
    "validation loss: 0.7258547251949662, validation acc: 0.8198614120483398, test loss: 0.8935344749332024, test acc: 0.7995391488075256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCNConv instead of GraphConv\n",
    "average training loss: 0.3523677970215635, training acc: 0.8458213210105896\n",
    "validation loss: 0.47687009828431265, validation acc: 0.7921478152275085, test loss: 0.5093637616952993, test acc: 0.7695852518081665\n",
    "highest validation accuracy: 0.8152424693107605 in epoch 452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gnn.state_dict(), f\"models/BA2Motif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TheModelClass(*args, **kwargs)\n",
    "#model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "DataBatch(x=[25, 10], edge_index=[2, 52], y=[1], batch=[25], ptr=[2])\n",
      "test_loader contains 100 graphs with following labels:\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2440]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2392]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2350]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2379]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2447]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2868]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3183]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2349]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2182]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2408]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2530]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3427]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2202]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2978]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1891]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2166]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2485]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2011]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2230]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2641]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3771]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2312]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2306]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2393]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2234]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2376]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2263]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2599]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2563]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2202]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2506]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2361]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1916]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1995]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.4198]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2421]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3032]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2180]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2560]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3552]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2436]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2547]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2552]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2047]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3847]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2847]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2519]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2675]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2186]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2383]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2667]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2259]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3812]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2056]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2678]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2917]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2947]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3206]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2218]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2440]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2592]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2796]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2950]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2429]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1704]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2501]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3183]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2516]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1947]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2115]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1786]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1957]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3519]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2278]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2916]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2411]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2707]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3131]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2458]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2277]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2487]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2872]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2103]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2486]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2831]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.1943]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.3241]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2075]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2170]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2086]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2274]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2058]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.4103]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2465]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2720]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0])\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([[0.2821]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))\n",
    "\n",
    "print(next(iter(train_loader)))         # edge_index = \"map\" for edges, x = features, y = labels\n",
    "#print(next(iter(train_loader)).x)\n",
    "\n",
    "print(\"test_loader contains 100 graphs with following labels:\")\n",
    "for i, curr in enumerate(test_loader):\n",
    "    print(curr.y)\n",
    "    print(curr.x.shape[1])\n",
    "    print(curr.batch)\n",
    "\n",
    "    out = gnn.forward(curr.x, curr.edge_index, curr.batch)\n",
    "    print(out.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.ConcatDataset object at 0x000001ED56EB32C0>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2,\n",
      "        3])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2,\n",
      "        3])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ExplainerDataset\n",
    "from torch_geometric.datasets.graph_generator import BAGraph\n",
    "from torch_geometric.datasets.motif_generator import HouseMotif\n",
    "from torch_geometric.datasets.motif_generator import CycleMotif\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset1 = ExplainerDataset(\n",
    "            graph_generator=BAGraph(20, 1),\n",
    "            motif_generator=HouseMotif(),\n",
    "            num_motifs=1,\n",
    "            num_graphs=400,\n",
    "            transform=T.Constant()      # appends value 1 node feature for every node\n",
    "        )\n",
    "\n",
    "dataset2 = ExplainerDataset(\n",
    "            graph_generator=BAGraph(20, 1),\n",
    "            motif_generator=CycleMotif(5),\n",
    "            num_motifs=1,\n",
    "            num_graphs=400,\n",
    "            transform=T.Constant()\n",
    "        )\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset([dataset1, dataset2])\n",
    "\n",
    "print(dataset)\n",
    "dataset[0].y = torch.tensor([0])\n",
    "\n",
    "print(dataset[0].y)\n",
    "\n",
    "train_loader = DataLoader(dataset1, batch_size = 1, shuffle = True)\n",
    "\n",
    "print(next(iter(train_loader)).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1:\n",
      "9\n",
      "3\n",
      "5\n",
      "Set 2:\n",
      "2\n",
      "6\n",
      "4\n",
      "8\n",
      "7\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "generator2 = torch.Generator().manual_seed(42)\n",
    "set1, set2 = torch.utils.data.random_split(range(10), [3, 7])\n",
    "set3, set4, set5 = torch.utils.data.random_split(range(30), [0.3, 0.3, 0.4])\n",
    "\n",
    "print(\"Set 1:\")\n",
    "print(set1[0])\n",
    "print(set1[1])\n",
    "print(set1[2])\n",
    "print(\"Set 2:\")\n",
    "print(set2[0])\n",
    "print(set2[1])\n",
    "print(set2[2])\n",
    "print(set2[3])\n",
    "print(set2[4])\n",
    "print(set2[5])\n",
    "print(set2[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = datasetLoader.loadDataset('MUTAG', batch_size) \n",
    "temp = next(iter(train_loader))\n",
    "print(temp.y.argmax(dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
