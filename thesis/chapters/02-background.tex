\chapter{Background}
\label{ch:Background}
In this chapter we define the necessary background for understanding PGExplainer as well as the follow-up work regarding its application on the Boolean Satisfiability Problem (SAT).

\section{TODO Deep learning}
In this chapter we introduce Deep Learning (DL) in the context of Machine Learning (ML) and their concepts required for this work. \\
What is machine learning? What is Deep learning? \\
Types of tasks in machine learning; Classification task in our case; \\
Supervised vs unsupervised learning; \\
All definitions in this chapter follow Goodfellow et al.\cite{Goodfellow-et-al-2016}. 

\subsection{Deep Feedforward Networks/MLP}
A classical deep learning model is the multilayer perceptron (MLP) with the general goal of approximating a function $f^*$. In the case of classification we could define a function $y = f^*(x)$ that maps an input $x$ to a label $y$. The MLP then defines the mapping $y = f(x;\Theta)$ and learns the value of the parameters $\Theta$ that best approximate the function. These models are also referred to as feedforward neural networks, as they process information from $x$, through the intermediate computations that define $f$, to the output $y$ without feedback connections that would feed outputs back to itself. The name network is derived from their representation as a composition of multiple different functions, that are described by a directed acyclic graph. An example network is $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$ that consists of first layer $f^{(1)}$, second layer $f^{(2)}$ and output layer $f^{(3)}$. The length of this chain of functions is called depth and origin of the term "deep learning". The approximation is achieved by training our network with training data, that consists of approximated examples of $f^*(x)$ at different points in the training and labels $y\approx f^*(x)$. These training examples dictate the output layer to generate a value close to $y$ for each $x$. The learning algorithm then learns to utilize the other hidden layers, without specified behaviors, to achieve the best approximation. It is to note that the hidden layers are vector-valued, with each vector element, referred to as unit, loosely taking the role of a neuron in neuroscience.
\subsection{Gradient descent}

\subsection{Computational graph}

\subsection{Backpropagation}

\subsection{Regularization}

\subsection{Batchnorm, LayerNorm, ...}

\subsection{TODO Weight Matrix somewhere}

\subsection{Monte Carlo Sampling}
Goodfellow et al.\cite{Goodfellow-et-al-2016}[p.590] TODO: EXPLANATION \\
Let 
\begin{equation}
    s = \sum_x p(x)f(x)=E_p[f(x)]
\end{equation}
be the sum to estimate with $p$ being a probability distribution over a random variable $x$. Then $s$ can be approximated by drawing $n$ samples from $p$ and constructing the empirical average 
\begin{equation}
    \hat{s}_n=\frac{1}{n}\sum_{i=1}^n f(x^{(i)}).
\end{equation}


\section{Graph Theory}
These definitions will loosely follow Liu et al.\cite{Liu2020}. A graph is a data structure consisting of a set of nodes that are connected via edges, modeling objects and their relationships. It can be represented as $G=(V,E)$ with $V=\{v_1,v_2...v_n\}$ being the set of $n$ nodes, and $E \in V \times V$ the set of edges. An edge $e=(u,v)$ connects nodes $u$ and $v$, making them neighbours. Edges are either directed or undirected and lead to directed or undirected graphs if exclusively present. The degree of a node $v$ is the number of edges connected to $v$ and denoted by $d(v)$. $G$ can be described by an adjacency matrix $A \in \mathbb{R}^{n \times n}$, where
\begin{equation*}
    A_{ij}=\begin{cases}
        1 & \text{if } \{v_i,v_j\}\in E \text{ and } i \neq j, \\
        0 & \text{otherwise.}
    \end{cases}
\end{equation*}
If $G$ is an undirected Graph the adjacency matrix will be symmetrical. \\
Alternatively an undirected graph $ G=(V, E)$ with $n$ nodes and $m$ edges can be represented as an incidence matrix $M \in \mathbb{R}^{n \times m}$, where
\begin{equation*}
    M_{ij}=\begin{cases}
        1 & \text{if } \exists k \text{ s.t. } e_j = \{v_j, v_k\} \\
        0 & \text{otherwise.}
    \end{cases}
\end{equation*}
We adopt the conventions from Diestel\cite{Diestel2017} to refer to the node and edges set of any graph $G$ with $V(G)$ and $E(G)$ respectively, regardless of the actual names of the sets, as well as a referring to $G$ with node set $V$ as $G$ on $V$. $G$ is called a subgraph of another graph $G'=(V',E')$ if $V(G) \subseteq V(G')$ and $E(G) \subseteq E(G')$. This is denoted as $H \subseteq G$. The number of nodes in a graph $|V|$ is its order and the number of edges $|E|$ is its size.
We additionally define bipartite graphs according to Asratian et al.\cite{asratian1998}: A graph $G$ is bipartite if the set of nodes $V$ can be partitioned into two sets $V_1$ and $V_2$ so that no two nodes from the same set are adjacent. The sets $V_1$ and $V_2$ are called colour classes and $(V_1, V_2)$ is a bipartition of $G$. This means that if a graph is bipartite all nodes in $V$ can be coloured by at most two colours so that no two adjacent nodes share the same colour.\\
TODO: EDGE WEIGHTS, K-hop/computational graph?
\begin{figure}[h]
    \centering
    \begin{tikzpicture}[node distance=1.5cm, every node/.style={draw, circle}]
        % Define Nodes
        \node (1) {1};
        \node (2) [right of=1] {2};
        \node (4) [below of=2] {4};
        \node (5) [right of=2] {5};
        
        % Draw Edges
        \draw (1) -- (2);
        \draw (2) -- (4);
        \draw (1) -- (4);
        \draw (2) -- (5);
    \end{tikzpicture}
    \caption{A simple undirected graph $G$ with $V=\{1,...,5\}$ and $E=\{\{1,2\},\{2,4\},\{1,4\},\{2,5\}\}$}
    \label{fig:graph-example}
\end{figure}

\subsection{TODO Graph generation/Graph Generative Model/Random Graphs}
Erdos-Renyi model first model of random graphs, but slightly different from Gilbert. \bigskip

Gilbert\cite{} describes the process of generating a random graph of order $N$ by assigning a common probability to exist in the graph to each potential edge between two nodes. Note that these random selections are made independently of each other, effectively drawing from a Bernoulli distribution. \\
by performing independent experiments for each potential edge between two nodes of the graph. Since these experiments share a common probability, the process can be described as drawing from a Bernoulli distribution. \\
A random graph is further described by Diestel\cite{} as follows. Let $V = \{0,...,n-1\}$ be a fixed set of $n$ elements. Our goal is to define the set $\mathcal{G}$ of all graphs on $V$ as a probability space, which allows us to ask whether a Graph $G \in \mathcal{G}$ has a certain property. To generate our random graph we then decide from some random experiment whether $e$ shall be an edge of $G$ for each potential $e \in V \times V$. The probability of success - accepting $e$ as edge in $G$ - is defined as $p \in [0,1]$ for each experiment. TODO: Rewrite the accepting part. This leads to the probability of $G$ being a particualar graph $G_0$ on $V$ with e.g. $m$ edges being equal to $p^m q^{\binom{n}{2}-m}$ with $q:=1-p$. It follows our desired probability space $\mathcal{G}=(n,p)$ as the product space
$$\Omega := \prod_{e \in [V]^2} \Omega_e$$ with $\Omega_e := \{0_e,1_e\}$, $\mathbb{P}_e(\{1_e\}) := p$ and $\mathbb{P}_e(\{0_e\}) := q$.
$$E(G) = \{e | \omega(e) = 1_e\}$$
G is called a random graph on V with egde probability p. \bigskip

INSTEAD: Gilberts idea also assigns the same probability across all edges, so probably best to explain the general idea as presented in Diestel. Then explain the difference in PGE? PGEs appraoch mainly inspired by probabilistic graphical model/bayesian networks. Gilbert model mainly baseline for probabilistic graphs. PGExplainer mainly inspired by Gilbert, but "required" concept is PGM.

\section{Information Theory}
To fully understand the learning objective of PGExplainer it is necessary to define the concepts of entropy and mutual information. We follow the definitions by Cover et al.\cite{Cover2005}[p.13].

\subsection{Entropy}
TODO: REVISE THIS. Probably best to define with general expactation, for continous and discrete, according to Goodfellow. Derive conditional entropy for general case. Only apply discrete case where needed? (cross entropy in PGE) \bigskip

Entropy is used to describe the uncertainty of a random variable. It measures the amount of information required on average to describe a random variable. Let $X$ be a discrete random variable with alphabet $\mathcal{X}$ and probability mass function $p(x)=Pr\{X=x\}$ for $x\in X$.
The entropy $H(X)$, also written as $H(p)$, is defined as
\begin{equation}
    H(X) = -\sum_{x \in \mathcal{X}} p(x) \log p(x).
\end{equation}
TODO: WE USE NATURAL LOGARITHM IN CODE! The log is to the base $e$ and entropy is measured in nats. TODO: DEFINE EDGE CASES log 0 TODO: TOO MUTCH + SOURCE? A simple example is tossing two coins: There are four possible outcomes $\mathcal{X}=\{00,10,01,11\}$, 0 for heads and 1 for tails, each with a probability $p=0,25$. The resulting entropy $H(X)=2$ represents that two bits of information can be stored this way. \bigskip

%TODO: DIFFER MORE CLEARLY FROM CROSS? \\
%Analogously we define the joint entropy $H(X,Y)$ of a pair of discrete random variables $(X,Y)$ with a joint distribution $p(x,y)$ as follows:
%\begin{equation}
%    H(X,Y)=-\sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log p(x,y).
%\end{equation}
The conditional entropy of $Y$ given $X$ is defined as the expected value of the entropies of the conditional distributions, averaged over the conditioning random variable. If $(X,Y) \sim p(x,y)$ for a pair of discrete random variables $(X,Y)$ with joint distribution $p(x,y)$, the conditional entropy is defined as \\
\begin{align}
    H(Y|X)&= -\sum_{x \in \mathcal{X}} p(x) H(Y|X=x) \\
    &= - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}}p(x,y) \log p(y|x) \\
    &= -E \log p(Y|X) \text{ with E = Expectation}.
\end{align}

Elements of Information Theory: equation 2.26 describes KL distance/relative entropy \bigskip

The following definitions loosely follow Goodfellow et al.\cite{Goodfellow-et-al-2016}[p.74].
The relative entropy is a measure of the distance between two distributions.
"measure how different these two distributions are" \cite{Goodfellow-et-al-2016}
"In the case of discrete variables, it is the extra amount of information needed to send a message containing symbols drawn from probability distribution P, when we use a code that was designed to minimize the length of messages drawn from probability distribution Q."
"The KL divergence is 0 if and only if P and Q are the same distribution in the case of discrete variables"
non symmetrical.
"When computing many of these quantities, it is common to encounter expressions of the form 0 log 0. By convention, in the context of information theory, we treat these expressions as limx→0 x log x = 0. \\
We define the KL divergence or relative entropy between two probability distributions $P, Q$ as
\begin{equation}
    D_{KL}(P||Q) = \sum_{x \in \mathcal{X}} P(x)\log \frac{P(x)}{Q(x)}
\end{equation}

The cross entropy is closely related to KL distance and therefore defined as
\begin{align}
    H(P,Q) &= -\mathbb{E}_{x\sim P}\log Q(x) \\
    &= H(P) + D_{KL}(P||Q)
\end{align}

We derive for the discrete case with mass probability functions $p, q$ defined on the same support $\mathcal{X}$:
\begin{align}
    H(p,q) = H(p) + D_{KL}(p||q) &= -\sum_{x \in \mathcal{X}} p(x) \log p(x) + \sum_{x \in \mathcal{X}} p(x)\log \frac{p(x)}{q(x)} \\
    &= -\sum_{x \in \mathcal{X}} p(x) \log p(x) + \sum_{x \in \mathcal{X}} p(x) \log p(x) -\sum_{x \in \mathcal{X}} p(x) \log q(x) \\
    &= -\sum_{x \in \mathcal{X}} p(x) \log q(x)
\end{align}

The approach in PGExplainer is a common approach in ML for simplifying objectives? FIND LITERATURE THAT EXPLAINS APPROXIMATION OF COND. ENTROPY WITH CROSS ENTROPY. Explanation as simple as one formula for one graph variable example, cross entropy applied to whole distribution? \bigskip

"We can modify the conditional entropy objective in Equation 4 with a cross entropy objective between the label class and the model prediction" (GNNExplainer)

\subsection{Mutual Information}
Another closely related concept is mutual information (see Cover et al.\cite{Cover2005}[p.19]). It measures the amount of information that one random variable contains about another or the reduction in uncertainty of said variable due to knowing the other.
Let $X$ and $Y$ be two random variables with the joint probability mass function $p(x,y)$ and marginal probability mass functions $p(x)$ and $p(y)$. Mutual information $I(X;Y)$ is the relative entropy between the joint distribution and the product distribution $p(x)p(y)$: 
\begin{align}
    I(X;Y)&=\sum_{x \in \mathcal{X}}\sum_{y \in \mathcal{Y}} p(x,y)\log \frac{p(x,y)}{p(x)p(y)} \\
    &= H(X) - H(X|Y)
\end{align}

\section{TODO Graph Neural Networks}

The following definitions will loosely follow book/... (reference).
JEDE Variable einmal erklärt! Einheitliche Variablen aus meiner Sicht

Graph Neural Networks(GNNs)\cite{4700287} are a deep learning-based approach that operates on graphs, a data structure consisting of nodes and edges, representing objects and their relationships. Due to their unique non-Euclidean property, they find usage in classification, link prediction, and clustering tasks. Their high interpretability and strong performance have led to GNNs becoming a commonly employed method in graph analysis. They combine the key features of convolutional neural networks\cite{726791}, such as local connection, shared weights, and multi-layer usage, with the concept of graph embeddings\cite{cai2018comprehensive} to leverage the power of feature extraction and representation as low-dimensional vectors for graphs\cite{Liu2020}. \\
- difference node classification, graph classification (Scarselli) \\
- data preprocessed: mapping to simpler representation
- encode graph structure/topology to keep structural information
- directed/undirected?
- ...



\subsection{Convolutional Graph Neural Networks}
Explain? Used in architecture of downstream task, only slightly relevant

\section{Perturbation-based Explainability in GNNs}
Methods in deep learning have seen growth in performance in many tasks of artificial intelligence, including GNNs. However, the interpretability of these models is often limited due to their black-box design. Explainability methods aim to bypass this limitation by designing post-hoc techniques that provide insights into the decision-making process in the form of explanations. Such human-intelligible explanations are crucial for deploying models in real-world applications, especially when applied in interdisciplinary fields. There exist several different approaches for explaining predictions of deep graph models, that can be categorized into instance-level methods and model-level methods (see Yuan et al. \cite{yuan2022explainability}). Instance-level methods aim to explain each input-graph by identifying important input features for its prediction, leading to input-dependent explanations. These can further be grouped by their importance score calculation into gradients/feature-based, perturbation-based, decomposition methods and surrogate methods. Model-level methods, on the other hand, aim to explain GNNS without considering specific inputs, leading to input-independent, high-level explanations. \\
In this work we focus on the perturbation-based approach, more specifically the PGExplainer\cite{luo2020parameterized}, that aims to evaluate the change of prediction with respect to input perturbations. The intuition behind this is that when input information crucial to the prediction is kept, the new prediction should roughly align with the prediction from the original input. The general pipeline for different perturbation based approaches can be described as follows: First, the important features from the input graph are converted into a mask by our generation algorithm, depending on the explanation task at hand. These masks are applied to the input graph to highlight said features. Lastly, the masked graph is fed into the trained GNN to evaluate the mask and update the mask generation algorithm according to the similarity of the predictions. \\
It is important to distinguish between soft masks, discrete masks and approximated discrete masks. Soft masks take continuous values between $[0,1]$ which enables the graph algorithm to be updated via backpropagation. A downside of soft masks is that they suffer from the "introduced evidence" problem(see Dabkowski et al.\cite{ Dabkowski }). Any mask value that is non-zero or non-one may add new semantic meaning or noise to the input graph, since graph edges are by nature discrete. Discrete masks however always rely on non-differentiable operations, e.g. sampling. Thus, the approximated discrete masks utilize reparameterization tricks to avoid the "introduced evidence" problem while also enabling back-propagation. \\
Explanations can on the one hand be evaluated by visualizing the graph and considering the "human-comprehensibility". Since this requires a ground truth, is prone to the subjective understanding and is usually performed for a few random samples, it is important to apply stable evaluation metrics. TODO: One relevant accuracy metric for synthetic datasets with ground truths is the Area Under the Receiver Operating Characteristic Curve (ROC-AUC/AUC) (see Richardson et al.\cite{}). \\
\url{https://www.sciencedirect.com/science/article/pii/S2666389924001090?ref=pdf_download&fr=RR-2&rr=92785edbb946f803}
The Receiver Operating Characteristic (ROC) curve plots the False Positive Rate (FPR) on the x-axis against the True Positive Rate (TPR), across different classification thresholds. The area under the curve (AUC) is calculated for said curve, resulting in the ROC-AUC. It is important to note, that a value of $0.5$ equals random guessing, while a score of $1.0$ indicates perfect classification. \bigskip

TODO: \\
Explain TRP FPR?

Variation in perturbation approaches lie in: mask gen. alg., type of mask, objective function.

Differentiate between "interpretable" and "explainable"? Model itself provides human-understandable interpretations vs model still black box with explanations by post-hoc model.

- Other metric includes fidelity, results of taxonomy propose only using PGExplainer for Node Classification as it achieves low fidelity on Graph tasks

TODO: Perturbation pipeline?

\section{Boolean Satisfiability Problem}
We define the Boolean Satisfiability Problem (SAT) according to Guo et al.\cite{guo2023machine}[p.641]: \\
A Boolean formula is constructed from Boolean variables, that only evaluate to True (1) or False (0), and the three logic operators conjunction ($\wedge$), disjunction ($\vee$) and negation ($\neg$). SAT aims to evaluate whether there exists a variable assignment for a formula constructed of said parts so that it evaluates to True. If so, the formula is said to be satisfiable or unsatisfiable otherwise. Every propositional formula can be converted into an equivalent formula in conjunctive normal form (CNF), which consists of a conjunction of one or more clauses. These clauses must contain only disjunctions of at least one literal (a variable or its negation). In this work we consider only formulas in CNF, as NeuroSAT\cite{} assumes SAT problems to be in CNF. An example of a satisfiable formula in CNF over the set of variables $V=\{x_1,x_2\}$ is 
$$\psi(V) = (x_1) \land (\neg x_1 \lor x_2) \land (\neg x_2 \lor x_2)$$
with satisfying assignment $A:\{x_1 \mapsto 1, x_2 \mapsto 1\}$. Furthermore, SAT is $NP$-complete, meaning that if there exists a deterministic algorithm able to solve SAT in polynomial time, then such an algorithm exists for every $NP$ problem (see cook\cite{}). Current state of the art SAT solvers apply searching based methods such as Conflict Driven Clause Learning (GRASP marques silva)\cite{} or Stochastic Local Seach (TYPCIAL EXAMPLE WALKSAT: Local search strategies for satisfiability testing Profile image of Bart SelmanBart Selman)\cite{} with exponential worst-case complexity.

\subsection{Representation as Bipartite Graph}
SAT has extensively been studied in the form of graphs,
Guo et al. describe four different types of graph representations for CNF formulae with varying complexity and information compression. Since we want to minimize the loss of information for SAT we adapt the information-richest form of a literal-clause graph (LCG). 
A LCG is a bipartite graph that separates literals and clauses, with edges connecting literals to the clauses they appear in.
The resulting graph can formally be described by a biadjacency matrix $B$ of shape $l \times c$. \\
Let $A \in \mathbb{R}^{l+c \times l+c}$ be the adjacency matrix of our bipartite graph. Since for the bipartite case edges exist only between the two color classes $l$ and $c$, the adjacency matrix can be represented as:
\begin{equation}
    A(i,j) = \begin{bmatrix}
        0_{l \times l} & B \\
        B^T & 0_{c \times c}
    \end{bmatrix}
\end{equation}
where $0$ denotes a zero matrix in the shape of their subscript (see biadjacency\cite{}).

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[
        every node/.style={draw, circle, minimum size=1cm},
        node distance=1.5cm,
        scale=0.8,
    ]
        % Define Literal Nodes
        \node (x1) at (0, 0) {\(x_1\)};
        \node (notx1) at (2.5, 0) {\(\neg x_1\)};
        \node (x2) at (5, 0) {\(x_2\)};
        \node (notx2) at (7.5, 0) {\(\neg x_2\)};
        
        % Define Clause Nodes (one level above literals)
        \node[circle, draw] (C1) at (1.25, 2.5) {\(C_1\)};
        \node[circle, draw] (C2) at (3.75, 2.5) {\(C_2\)};
        \node[circle, draw] (C3) at (6.25, 2.5) {\(C_3\)};
        
        % Draw Edges (Literal → Clause)
        \draw (x1) -- (C1);
        \draw (notx1) -- (C2);
        \draw (x2) -- (C2);
        \draw (notx2) -- (C3);
        \draw (x2) -- (C3);
        
        % Draw Dotted Edges between each literal and its co mplement
        \draw[dotted] (x1) -- (notx1);
        \draw[dotted] (x2) -- (notx2);
    \end{tikzpicture}
    \caption{LCG representation of $\psi(V)$ with dashed lines representing the connection between complementary literals relevant for the message passing in GNNs.}
    \label{fig:lcg-sat}
\end{figure}

%\subsection{Incidence/Levi graph?}
%Defined in ALYAHYA et al. Concrete graphical representation of SAT? Type of bipartite graph.
%Defines edges via edge weight function! PART OF GRAPH THEORY \\
%Definition in Cimatti et al. : For clause $c$ we use $lit(c)$ and $var(c)$ to reference the %set of literals and variables in $c$ respectively. "$For a CNF formula F we write
%cla(F) for its set of clauses, lit(F)= c \in cla(F) lit(c) for its set of literals, and
%var(F)= c \in cla(F) var(c) for its set of variables.$"  Incidence graph of $\psi$ is the %bipartite graph $inc(\psi) = (V,E)$ with $V=lit(\psi) \cup cla(\psi)$. Additionally for %literal $x \in lit(\psi)$ and clause $c \in cla(\psi)$ we define $xc \in E$ if $x \in var(c)$.

\subsection{Unsatisfiable Cores}
The core of an unsatisfiable formula in CNF is a subset of the formula that is also unsatisfiable. Every unsatisfiable formula therefore is a core on its own, but can be broken down into smaller cores. The smaller a core the more significance it holds. A minimal unsatisfiable core is also referred to as a minimal unsatisfiable subset (MUS). SAT solvers like minisat\cite{} are able to compute unsatisfiable cores but do not generally provide a MUS due to high computational cost. However, several deletion-based algorithms exist for computing MUSs. Cuellar et al \cite{}

\subsection{Backbones}
Leave out for now.

\section{TODO NeuroSAT}
Machine learning approach for SAT solving using message passing neural network.
NeuroSAT: Messages are passed between clauses and literals, as well as literals and their complement. 1. Clause receives from neighboring literals 2. Literals receive from clauses and complement. \\
(Define flip function that swaps literal row with row of its negation; relevant for NeuroSAT)